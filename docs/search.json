[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "√úbung zur Vorlesung Weiterf√ºhrende Methoden der empirischen Forschung",
    "section": "",
    "text": "Vorwort\nIn dieser Veranstaltung werden wir folgende Werkzeuge verwenden:\nILIAS: die Online-Lernplattform der UzK. Sie sollten alle bereits registriert sein.\nCampuswire: die Chatplattform dient der allgemeinen Kommunikation und der Selbstorganisation des Lernens. Verwenden Sie diese, um Fragen mit Ihren Kommilitonen*innen und mir zu diskutieren. Sie sollten eine Einladungsmail zu Campuswire erhalten haben.\nZoom: die Videokonferenz-Software bleibt unser Notfall-Werkzeug, falls keine Pr√§senz m√∂glich ist."
  },
  {
    "objectID": "index.html#lernergebnisse-intended-learning-outcomes",
    "href": "index.html#lernergebnisse-intended-learning-outcomes",
    "title": "√úbung zur Vorlesung Weiterf√ºhrende Methoden der empirischen Forschung",
    "section": "Lernergebnisse (intended learning outcomes)",
    "text": "Lernergebnisse (intended learning outcomes)\n\nDatenanalyse\n\nDaten f√ºr statistische Analysen aufbereiten\nExplorative (beschreibende) Datenanalyse durchf√ºhren\nEine Regressionsanalyse durchf√ºhren\nAusgew√§hlte Methoden des maschinellen Lernens kennen und anwenden\nDaten visualisieren\nErgebnisse der Analysen reproduzierbar darstellen\n\nStatistische Methoden\n\nEin lineares Modell berechnen, die Ergebnisse darstellen und interpretieren\nDie Inferenz (Standardfehler, Konfidenzintervalle) der linearen Regression anwenden und interpretieren\nDas Bootstrapverfahren und seine Vorteile und Einschr√§nkungen kennen und interpretieren\nDie Verfahren des maschinellen Lernens \\(k\\)-means clustering und random forest erkl√§ren und interpretieren"
  },
  {
    "objectID": "index.html#was-mir-im-umgang-miteinander-wichtig-ist",
    "href": "index.html#was-mir-im-umgang-miteinander-wichtig-ist",
    "title": "√úbung zur Vorlesung Weiterf√ºhrende Methoden der empirischen Forschung",
    "section": "Was mir im Umgang miteinander wichtig ist",
    "text": "Was mir im Umgang miteinander wichtig ist\n\nP√ºnktlichkeit bei Pr√§senz- und Zoomsitzungen\nGute Vorbereitung durch Erledigen der Hausaufgaben\nRespektieren anderer Meinungen\nOffenheit gegen√ºber neuen Sichtweisen, Themen und Methoden\nGeduld mit sich selbst und den anderen üòÑ"
  },
  {
    "objectID": "index.html#sinn-und-unsinn-dieses-skripts",
    "href": "index.html#sinn-und-unsinn-dieses-skripts",
    "title": "√úbung zur Vorlesung Weiterf√ºhrende Methoden der empirischen Forschung",
    "section": "Sinn und Unsinn dieses Skripts",
    "text": "Sinn und Unsinn dieses Skripts\nDieses Skript ist ein lebendiges Begleitdokument des Kurses. Es wird laufend angepasst und aktualisiert.\nIch nutze verschiedenfarbige Bl√∂cke, um wichtige Stellen hervorzuheben:\n\nInfoblock\n\n\n\nAchtung, wichtig!\n\n\n\nDefinition\n\n\n\nLernziele"
  },
  {
    "objectID": "index.html#inspiration-quellen-und-danksagung",
    "href": "index.html#inspiration-quellen-und-danksagung",
    "title": "√úbung zur Vorlesung Weiterf√ºhrende Methoden der empirischen Forschung",
    "section": "Inspiration, Quellen und Danksagung",
    "text": "Inspiration, Quellen und Danksagung\nDieses Skript baut stark auf folgenden freien Quellen auf:\n\nr4ds: Wickham, √áetinkaya-Rundel, and Grolemund (2023)\nggplot2: Wickham (2020)\nModernDive: Ismay and Kim (2021)\nIntroduction to Modern Statistics: (IMS2021?)\n\nDen Autoren dieser B√ºcher gilt ein gro√üer Dank f√ºr Ihren Beitrag zur -Community !"
  },
  {
    "objectID": "index.html#reproduzierbarkeit",
    "href": "index.html#reproduzierbarkeit",
    "title": "√úbung zur Vorlesung Weiterf√ºhrende Methoden der empirischen Forschung",
    "section": "Reproduzierbarkeit",
    "text": "Reproduzierbarkeit\nDieses Skript wurde in RStudio mit Quarto geschrieben und in R version 4.4.2 (2024-10-31) gebaut. Folgende Pakete werden f√ºr die Beispiele und √úbungen ben√∂tigt:\n\n\n\n\npackage\nversion\nsource\n\n\n\n\ndabestr\n2023.9.12\nCRAN (R 4.3.2)\n\n\nemojifont\n0.5.5\nCRAN (R 4.2.0)\n\n\nfontawesome\n0.5.2\nCRAN (R 4.3.2)\n\n\ngapminder\n1.0.0\nCRAN (R 4.3.2)\n\n\ninfer\n1.0.7\nCRAN (R 4.4.1)\n\n\nlubridate\n1.9.3\nCRAN (R 4.3.2)\n\n\nmoderndive\n0.5.5\nCRAN (R 4.3.2)\n\n\nopenintro\n2.4.0\nCRAN (R 4.2.1)\n\n\ntidyverse\n2.0.0\nCRAN (R 4.3.2)\n\n\n\n\nDie komplette Information zur Session lautet:\n\n\nR version 4.4.2 (2024-10-31)\nPlatform: x86_64-pc-linux-gnu\nRunning under: Ubuntu 22.04.5 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/atlas/libblas.so.3.10.3 \nLAPACK: /usr/lib/x86_64-linux-gnu/atlas/liblapack.so.3.10.3;  LAPACK version 3.10.0\n\nlocale:\n [1] LC_CTYPE=de_DE.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=de_DE.UTF-8        LC_COLLATE=de_DE.UTF-8    \n [5] LC_MONETARY=de_DE.UTF-8    LC_MESSAGES=de_DE.UTF-8   \n [7] LC_PAPER=de_DE.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=de_DE.UTF-8 LC_IDENTIFICATION=C       \n\ntime zone: Europe/Berlin\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] crayon_1.5.2      vctrs_0.6.5       cli_3.6.2         knitr_1.48       \n [5] rlang_1.1.3       xfun_0.46         stringi_1.8.3     purrr_1.0.2      \n [9] generics_0.1.3    assertthat_0.2.1  jsonlite_1.8.8    glue_1.7.0       \n[13] rprojroot_2.0.4   htmltools_0.5.7   fansi_1.0.6       rmarkdown_2.25.2 \n[17] emo_0.0.0.9000    tibble_3.2.1      evaluate_0.23     fontawesome_0.5.2\n[21] fastmap_1.1.1     yaml_2.3.8        lifecycle_1.0.4   stringr_1.5.1    \n[25] compiler_4.4.2    sessioninfo_1.2.2 pkgconfig_2.0.3   htmlwidgets_1.6.2\n[29] timechange_0.2.0  rstudioapi_0.15.0 digest_0.6.33     R6_2.5.1         \n[33] utf8_1.2.4        pillar_1.9.0      magrittr_2.0.3    tools_4.4.2      \n[37] lubridate_1.9.3   desc_1.4.2       \n\n\n\nDieses Skript ist lizenziert unter Creative Commons Namensnennung - Nicht-kommerziell - Weitergabe unter gleichen Bedingungen 4.0 International.\n\n\n\n\nIsmay, Chester, and Albert Y. Kim. 2021. ModernDive: Statistical Inference via Data Science. https://moderndive.com/.\n\n\nWickham, Hadley. 2020. Ggplot2: Elegant Graphics for Data Analysis. 3rd, in progress. https://ggplot2-book.org/.\n\n\nWickham, Hadley, Mine √áetinkaya-Rundel, and Garrett Grolemund. 2023. R for Data Science (2e). https://r4ds.hadley.nz/."
  },
  {
    "objectID": "01-erste-schritte.html#was-ist",
    "href": "01-erste-schritte.html#was-ist",
    "title": "1¬† Erste Schritte in R",
    "section": "1.1 Was ist ?",
    "text": "1.1 Was ist ?\nR ist eine Programmiersprache f√ºr Datenanalyse und statistische Modellierung. Es ist frei verf√ºgbar (open source software) und neben Python einer der am meisten benutzten Programmiersprachen zur Datenanalyse und -visualisierung. R wurde von Ross Ihaka und Robert Gentleman 1996 ver√∂ffentlicht (Ihaka and Gentleman 1996). Es gibt f√ºr R eine Vielzahl von Zusatzpaketen, die die Funktionalit√§t und die Einsatzm√∂glichkeiten enorm erweitern.\nSie k√∂nnen R f√ºr Ihren Computer auf der offiziellen R-Seite https://www.r-project.org/ herunterladen und installieren. Eine kurze Anleitung finden Sie auf ILIAS, zusammen mit der Liste der Pakete, die wir in diesm Kurs brachen werden. Zus√§tzlich k√∂nnen Sie sich hier ein Video zur Installation ansehen.\nAuf der offiziellen R-Seite finden Sie auch zus√§tzliche Pakete, und zwar unter CRAN (The Comprehensive R Archive Network). Manche Pakete sind auf den CRAN-Seiten thematische in sogen. CRAN Task Views gegliedert. F√ºr den Umweltbereich sind folgende Paketsammlungen besonders relevant:\n\nEnvironmetrics: Analyse von Umweltdaten\nMultivariate: Multivariate Statistik\nSpatial: Analyse von r√§umlichen Daten\nTimeSeries: Zeitreihenanalyse\n\nZu Beginn des Kurses werden wir jedoch nicht auf Ihren lokalen Rechnern arbeiten, sondern auf den bereits eingerichteten Uni-Rechnern in den EDV-R√§umen. Daher biete ich zu diesem fr√ºhen Zeitpunkt im Kurs keine Unterst√ºtzung bei der Installation von R auf Ihren Privatrechnern. F√ºr die ganz Ungeduldigen, gibt es hier eine kurze Einleitung zur Installation."
  },
  {
    "objectID": "01-erste-schritte.html#was-ist-rstudio",
    "href": "01-erste-schritte.html#was-ist-rstudio",
    "title": "1¬† Erste Schritte in R",
    "section": "1.2 Was ist RStudio?",
    "text": "1.2 Was ist RStudio?\nRStudio Desktop ist eine Entwicklungsumgebung f√ºr R. Wichtig: RStudio wird erst nach R installiert und macht ohne R keinen Sinn. Sie k√∂nnen die open source Version kostenlos f√ºr Ihren Rechner hier herunterladen, falls Sie sich entscheiden, (sp√§ter) R auf Ihrem Rechner zu installieren. Es gibt eine live Einf√ºhrung in RStudio im Kurs. Zus√§tzlich k√∂nnen Sie hier ein Video dazu ansehen.\nDie Oberfl√§che von RStudio ist in vier Bereiche unterteilt (Abbildung¬†1.1).\n\n\n\nAbbildung¬†1.1: Aufbau von RStudio\n\n\nSie sollten auch auf Ihrem eigenen Rechner einen Ordner f√ºr die Veranstaltung anlegen und darin jeweils einen Ordner f√ºr Folien, Daten und Notebooks."
  },
  {
    "objectID": "01-erste-schritte.html#lesestoff",
    "href": "01-erste-schritte.html#lesestoff",
    "title": "1¬† Erste Schritte in R",
    "section": "1.5 Lesestoff",
    "text": "1.5 Lesestoff\nr4ds, Kapitel 4 (Wickham and Grolemund 2021)\n\n\n\n\nIhaka, Ross, and Robert Gentleman. 1996. ‚ÄúR: A Language for Data Analysis and Graphics.‚Äù Journal of Computational and Graphical Statistics 5 (3): 299‚Äì314. https://doi.org/10.1080/10618600.1996.10474713.\n\n\nKnuth, D. E. 1984. ‚ÄúLiterate Programming.‚Äù The Computer Journal 27 (2): 97‚Äì111. https://doi.org/10.1093/comjnl/27.2.97.\n\n\nWickham, Hadley, and Garrett Grolemund. 2021. R for Data Science. https://r4ds.had.co.nz/.\n\n\nXie, Yihui, J. J. Allaire, and Garrett Grolemund. 2021. R Markdown: The Definitive Guide. https://bookdown.org/yihui/rmarkdown/."
  },
  {
    "objectID": "01-erste-schritte.html#gemeinsame-aufgaben",
    "href": "01-erste-schritte.html#gemeinsame-aufgaben",
    "title": "1¬† Erste Schritte in R",
    "section": "1.4 Gemeinsame Aufgaben",
    "text": "1.4 Gemeinsame Aufgaben\n\nBitte speichern Sie Ihr Skript regelm√§√üig ab!\n\n\n1.4.1 Ars Haushaltsbuch\nDer angehende Datenanalyst Ar Stat m√∂chte dem Rat seiner Mutter folgen und ein Haushaltsbuch anlegen. Zuerst m√∂chte er sich einen √úberblick √ºber seine Ausgaben in der Uni-Mensa verschaffen und erstellt die folgende Tabelle:\n\n\nArs Mensaausgaben\n\n\nWochentag\nAusgaben (‚Ç¨)\n\n\n\n\nMontag\n2,57\n\n\nDienstag\n2,90\n\n\nMittwoch\n2,73\n\n\nDonnerstag\n3,23\n\n\nFreitag\n3,90\n\n\n\n\n\n\n\nWie viel hat Ar insgesamt in der Woche ausgegeben?\nWie gro√ü ist die Differenz zwischen dem h√∂chsten und dem niedrigsten Betrag?\nWie viel h√§tte er insgesamt ausgegeben, wenn er jeden Tag so viel gezahlt h√§tte, wie am Dienstag. Wichtig: Verwenden Sie die [], um den Betrag von Dienstag auszuw√§hlen!\n\nLeider hat Ar sich beim √úbertragen der Daten vertippt. Er hat am Dienstag seine Freundin zum Essen eingeladen und 7,95 ‚Ç¨ statt 2,90 ‚Ç¨ ausgegeben.\n\nKorrigieren Sie Ars Fehler.\nWie ver√§ndern sich die Ergebnisse aus den Teilaufgaben 1 bis 3?\n\n\n\n1.4.2 Fehlende Werte\nR kodiert fehlende Werte mit NA. Ar Stat hat am Montag der darauffolgenden Woche in der Mensa gegessen, aber vergessen die Ausgaben zu notieren.\n\n\nArs Mensaausgaben, cont.\n\n\nWochentag\nAmount spent (‚Ç¨)\n\n\n\n\nMontag, 9. M√§rz\n2,57\n\n\nDienstag, 10. M√§rz\n2,90\n\n\nMittwoch, 11. M√§rz\n2,73\n\n\nDonnerstag, 12. M√§rz\n3,23\n\n\nFreitag, 13. M√§rz\n3,90\n\n\nMontag, 16. M√§rz\nNA\n\n\n\n\n\n\n\nWie √§ndert der fehlende Wert die Berechnung der Summe?\nLesen Sie, was passiert, wenn der Datenvektor bei der Berechnung der Summe fehlende Werte enth√§lt. Rufen Sie dazu die Hilfe auf, i.e.¬†?sum.\nKorrigieren Sie die Berechnung der Summe entsprechend."
  },
  {
    "objectID": "01-erste-schritte.html#hausaufgaben",
    "href": "01-erste-schritte.html#hausaufgaben",
    "title": "1¬† Erste Schritte in R",
    "section": "1.5 Hausaufgaben",
    "text": "1.5 Hausaufgaben\n\n1.5.1 R als Taschenrechner\nR ist ein gro√üer Taschenrechner mit vielen bereits definierten Funktionen. Es gelten die √ºblichen Rechenregeln wie z.B. Punkt-vor-Strich und die Klammern.\n\nSchreiben Sie den Code, der 2 und 10 addiert\n\nDas korrekte Multiplikationszeichen in R ist *.\n\nGeben Sie den folgenden Befehl korrekt in R ein: (2 + 10) \\(\\times\\) 27\n\nBei Dezimalzahlen wird der Dezimalpunkt und nicht das Komma verwendet. Das ist wichtig zu beachten, wenn Sie sp√§ter Daten in R einlesen m√∂chten.\n\nBerechnen Sie die Summe von 2,34 und 4,98.\n\n\n\n1.5.2 Zuweisungen\nIn R arbeitet man mit Objekten. Ein Objekt kann alles M√∂gliche sein: eine Variable, Daten, Vektoren etc. Wenn also das Ergebnis einer Berechnung oder ein Datenobjekt im R-Arbeitsbereich (workspace) zur Verf√ºgung stehen soll, muss daraus ein Objekt erstellt werden.\nObjekte erstellt man, indem man ihnen Namen gibt. Diesen Vorgang nennt man Zuweisung (assignment). Im Beispiel unten wird ein Objekt, in diesem Fall ein Skalar, namens x erzeugt, mit dem Wert 42. Um den Wert von x anzuzeigen, tippen Sie x ein.\n\nx <- 42\n\n# Zeige den Wert von x\nx\n\nZuweisungen k√∂nnen in R entweder mit dem = erfolgen oder mit <-. Beide Varianten sind gleichwertig. Dabei ist allerdings Pfeilrichtung entscheidend! x <- 42 bedeutet: Die rechte Seite (Zahl 42) wird dem Objekt x zugeordnet. Wenn man die Pfeilrichtung umdreht, macht die Zuweisung keinen Sinn und man erh√§lt eine Fehlermeldung.\n\n# Sinnvolle Zuweisung\nx <- 42\n# Gleichwertige sinnvolle Zuweisung\nx = 42\n# Sinnloser Ausdruck. Fehlermeldung!\nx -> 42\n\nError in 42 <- x: ung√ºltige (do_set) linke Seite in Zuweisung\n\n\nObjektnamen k√∂nnen (fast) frei gew√§hlt werden. Sie m√ºssen mit einem Buchstaben beginnen und d√ºrfen keine Sonderzeichen enthalten. Bei l√§ngeren Namen empfiehlt sich ein _. Streng verboten sind Namen von vordefinierten Funktionen!\n\nErstellen Sie ein Objekt namens mein_objekt und weisen Sie ihm das Ergebnis der Berechnung \\(23^{2}\\) zu. Eine Potenz berechnen Sie mit ^.\n\nEine Zuweisung kann auch kompliziertere Anweisungen enthalten. Hier erstellen wir z.B. einen Vektor mithilfe der Funktion c (concatenate) und weisen das Ergebnis dem Objekt my_a zu.\n\nmy_a <- c(32, 54, 1.2, 398)\n\n\n\n1.5.3 Funktionsaufruf\nIn R gibt es eine Vielzahl von vordefinierten Funktionen. Ein Funktionsaufruf hat immer die gleiche Form: mach_das(damit) oder mach_das(damit, und_mit_dieser_einstellung). Z.B. wird die Summe auf einem Objekt mein_objekt mit sum(mein_objekt) berechnet.\n\nErstellen Sie einen Vektor mit den Zahlen 32, 54, 1,2 und 398 und weisen Sie ihn der Variablen my_a zu.\nBerechnen Sie die summe von my_a.\n\nSie k√∂nnen im √úbrigen auch Vektoren sinnvoll addieren.\n\nErstellen Sie einen Vektor my_b mit der passenden L√§nge und addieren Sie ihn zum Vektor my_a. Die Addition erfolgt elementweise.\n\nH√§ufig wollen wir f√ºr unsere Daten den Mittelwert berechnen.\n\nBerechnen Sie den Mittelwert von my_a\nBerechnen Sie die Standardabweichung von my_a.\n\n\n\n1.5.4 Objekte ansprechen\nUm das ‚ÄúInnenleben‚Äù der Objekte in R anzusprechen, gibt es verschieden M√∂glichkeiten. In diesem Tutorial konzentrieren wir uns auf Vektoren. Um die einzelnen Komponenten im Vektor anzusprechen, benutzt man eckige Klammern [ ]. Um eine bestimmte Komponente zu adressieren (anzusprechen), schreibt man die Platznummer der Komponente in die Klammer. Wenn man im Vektor my_c, z.B. die dritte Komponente extrahieren m√∂chte, dann schreibt man my_c[3]\n\nmy_c <- c(2, 45.7, pi, sqrt(23), 2^6)\nmy_c[3]\n\nWir k√∂nnen auch Vektoren erstellen, bei denen einzelne Elemente benannt sind.\n\nbenannt <- c('Koeln' = 50667, 'Berlin' = 10965, \"Stuttgart\" = 70173)\n\nElemente in solchen Vektoren kann man mit Namen in eckigen Klammern ansprechen. Die Namen m√ºssen in Anf√ºhrungszeichen geschrieben werden. Es spielt keine Rolle, ob Sie einfache oder doppelte Anf√ºhrungszeichen benutzen.\n\nFragen Sie nach dem Element Koeln im Vektor benannt.\n\n\n\n1.5.5 Ihr erster Plot\nVor allem am Anfang kann die Lernkurve in R recht flach verlaufen. Daher sollten Sie nicht vergessen, warum Sie R lernen, n√§mlich um echte Datens√§tze zu analysieren.\nAuch wenn Sie den Code unten noch nicht verstehen, kopieren Sie ihn in einen neuen R-Chunk in Ihrem Notebook und lassen Sie ihn laufen.\n\nlibrary(tidyverse)\nlibrary(gapminder)\n\ngapminder2007 <- gapminder %>% \n  filter(year == 2007)\n\nggplot(gapminder2007, aes(x = gdpPercap, y = lifeExp, color = continent, size = pop)) +\n  geom_point() +\n  scale_x_log10() +\n  labs(x = 'Bruttoinlandsprodukt pro Einwohner ($, inflationsbereinigt)', \n       y = 'Lebenserwartung bei der Geburt (Jahre)',\n       title = 'Daten von Gapminder f√ºr das Jahr 2007',\n       caption = 'http://www.gapminder.org/data/')\n\n\nWelche Daten sind in diesem Datensatz enthalten? Nutzen Sie die Hilfe, i.e.¬†?gapminder.\nWas stellen die Farben in der Abbildung dar?\nWas wird durch die Symbolgr√∂√üe dargestellt?\nWie w√ºrden Sie den Zusammenhang zwischen den Variablen Bruttoinlandsprodukt pro Einwohner ($, inflationsbereinigt) und Lebenserwartung bei der Geburt (Jahre) beschreiben?"
  },
  {
    "objectID": "01-erste-schritte.html#ihre-arbeit-einreichen",
    "href": "01-erste-schritte.html#ihre-arbeit-einreichen",
    "title": "1¬† Erste Schritte in R",
    "section": "1.6 Ihre Arbeit einreichen",
    "text": "1.6 Ihre Arbeit einreichen\n\nSpeichern Sie Ihr Notebook ab.\nLaden Sie Ihre .Rmd Datei in ILIAS hoch. Beachten Sie die Frist!\nSie erhalten die Musterl√∂sung nach dem Hochladen."
  },
  {
    "objectID": "01-erste-schritte.html#lesestoff-1",
    "href": "01-erste-schritte.html#lesestoff-1",
    "title": "1¬† Erste Schritte in R",
    "section": "1.7 Lesestoff",
    "text": "1.7 Lesestoff\nr4ds, Kapitel 4 (Wickham and Grolemund 2021)\n\n\n\n\nIhaka, Ross, and Robert Gentleman. 1996. ‚ÄúR: A Language for Data Analysis and Graphics.‚Äù Journal of Computational and Graphical Statistics 5 (3): 299‚Äì314. https://doi.org/10.1080/10618600.1996.10474713.\n\n\nIsmay, Chester, and Albert Y. Kim. 2021. ModernDive: Statistical Inference via Data Science. https://moderndive.com/.\n\n\nWickham, Hadley, and Garrett Grolemund. 2021. R for Data Science. https://r4ds.had.co.nz/."
  },
  {
    "objectID": "02-rmarkdown.html#warum-reproduzierbarkeit-in-der-forschung-wichtig-ist",
    "href": "02-rmarkdown.html#warum-reproduzierbarkeit-in-der-forschung-wichtig-ist",
    "title": "2¬† R Markdown f√ºr reproduzierbare Forschung",
    "section": "2.1 Warum Reproduzierbarkeit in der Forschung wichtig ist",
    "text": "2.1 Warum Reproduzierbarkeit in der Forschung wichtig ist\nAls Motivation f√ºr dieses Thema empfehle ich das Video von Prof.¬†Roger Peng der John Hopkins Bloogmerg School of Public Health."
  },
  {
    "objectID": "02-rmarkdown.html#literate-programming-idee-von-donald-knuth",
    "href": "02-rmarkdown.html#literate-programming-idee-von-donald-knuth",
    "title": "2¬† R Markdown f√ºr reproduzierbare Forschung",
    "section": "2.2 Literate Programming Idee von Donald Knuth",
    "text": "2.2 Literate Programming Idee von Donald Knuth\nDie Idee, dass man den Code und die dazugeh√∂rige Interpretation (Text, Bericht etc.) nicht voneinander trennen sollte, geht auf Knuth (1984) zur√ºck. Mit Literate Programming meinte Knuth, dass Programme auch nichts anderes wie literarische Werke sind. Er setzte den Fokus darauf, mit Programmen menschlichen Benutzern zu erkl√§ren, was man den Computer machen lassen m√∂chte. Also weg vom computer- hin zum mensch-zentrierten Zugang. So wird Programmieren und in unserem Fall die Datenanalyse verst√§ndlich und vor allem reproduzierbar.\nLeider ist es in unserer modernen Forschungslandschaft immer noch nicht Standard. Das Trennen von Analyseergebnissen und Berichten (Forschungsartikeln) sorgt f√ºr viele (unentdeckte und unn√∂tige) Fehler und Frust."
  },
  {
    "objectID": "02-rmarkdown.html#reproduzierbare-berichte-mit-r-markdown",
    "href": "02-rmarkdown.html#reproduzierbare-berichte-mit-r-markdown",
    "title": "2¬† R Markdown f√ºr reproduzierbare Forschung",
    "section": "2.3 Reproduzierbare Berichte mit R Markdown",
    "text": "2.3 Reproduzierbare Berichte mit R Markdown\nR hat sein eigenes System von reproduzierbaren Berichten, genannt R Markdown (Xie, Allaire, and Grolemund 2021). Es ist benutzerfreundlich und erm√∂glicht unterschiedliche Formate von Berichten, wie HTML-Dokumente, PDF-Dateien, Pr√§sentationsfolien usw.\nEs wird Sie vielleicht √ºberraschen, aber das Skript, das Sie gerade lesen, ist nichts anderes als ein ‚Äúliterarisch‚Äù programmiertes Buch in R Bookdown (Xie, Allaire, and Grolemund 2021), einem R-Paket speziell f√ºr lange R Markdown-Dokumente.\nWir werden vor allem mit R Notebooks arbeiten, die eine gute Interaktion zwischen dem geschriebenen Text und dem R-Code erm√∂glichen. Das Notebook kann sowohl in ein HTML-Dokument als auch in PDF oder Word als endg√ºltiges Dokument umgewandelt werden. Diesen Prozess nennt man knit."
  },
  {
    "objectID": "02-rmarkdown.html#ein-neues-r-notebook-erstellen",
    "href": "02-rmarkdown.html#ein-neues-r-notebook-erstellen",
    "title": "2¬† R Markdown f√ºr reproduzierbare Forschung",
    "section": "2.4 Ein neues R Notebook erstellen",
    "text": "2.4 Ein neues R Notebook erstellen\nUm ein neues R Notebook zu erstellen, klicken Sie das kleine gr√ºne Plus oben links und w√§hlen Sie R Notebook aus. Sie k√∂nnen es erst einmal bei untitled belassen (Abbildung¬†2.1).\n\n\n\nAbbildung¬†2.1: Neues R Notebook anlegen\n\n\nWenn Sie ein neues Notebook erstellen, enth√§lt das Template etwas Code. Lesen Sie sich das ruhig noch einmal durch, da es ein paar hilfreiche Tastenk√ºrzel und Tipps. Danach k√∂nnen Sie den Text unterhalb des Headers l√∂schen."
  },
  {
    "objectID": "02-rmarkdown.html#sec-header",
    "href": "02-rmarkdown.html#sec-header",
    "title": "2¬† R Markdown f√ºr reproduzierbare Forschung",
    "section": "2.5 Der Header eines Notebooks",
    "text": "2.5 Der Header eines Notebooks\nEin R Notebook (und jedes andere R Markdown Dokument) besteht aus einem Header (Kopf) und dem eigentlichen Text und Code. Der Header hat dabei ein bestimmtes Layout, auf das Sie unbedingt achten m√ºssen (Rechtschreibung!). Der Header ist immer zwischen drei Minuszeichen --- eingeschlossen. Bei komplizierteren Headern gibt es auch Einr√ºckungen (mit der Tab-Taste), die auch Bedeutung haben (s. weiterf√ºhrende Literatur). Wir bleiben bei einem einfachen Header ohne Einr√ºckungen (Abbildung¬†2.2).\nUm einen neuen R-Chunk hinzuzuf√ºgen, klicken Sie auf das kleine gr√ºne C+ oben rechts oder verwenden Sie das Tastenk√ºrzel Str+Alt+i.\n\n\n\nAbbildung¬†2.2: Einen neuen R Chunk hinzuf√ºgen\n\n\nText kann einfach unterhalb des Headers und au√üerhalb der Chunks getippt werden. Die wichtigsten Layoutelemente f√ºr den Text finden Sie hier. R Markdown unterst√ºtzt mathematische Notation in Latex-Stil. Eine Einf√ºhrung in Latex w√ºrde an dieser Stelle aber zu weit f√ºhren.\nDas R Notebook hat den Vorteil, dass man √ºber den Button Preview oben in der Leiste sofort die Ergebnisse anzeigen lassen kann. Sie m√ºssen also nicht knitten. Falls Sie es doch m√∂chten, klicken Sie auf das kleine Dreieck neben dem Preview und suchen Sie sich ein Output-Format aus. Ein einmal ‚Äúgeknittetes‚Äù Notebook ist kein Notebook mehr (kein Preview). Damit es wieder zum Nobebook wird, m√ºssen Sie im Header output: html_notebbok einstellen (Abbildung¬†2.2)."
  },
  {
    "objectID": "02-rmarkdown.html#wichtigste-regeln-f√ºr-reproduzierbarkeit",
    "href": "02-rmarkdown.html#wichtigste-regeln-f√ºr-reproduzierbarkeit",
    "title": "2¬† R Markdown f√ºr reproduzierbare Forschung",
    "section": "2.6 Wichtigste Regeln f√ºr Reproduzierbarkeit",
    "text": "2.6 Wichtigste Regeln f√ºr Reproduzierbarkeit\nEin weiteres Video von Prof.¬†Peng widmet sich den wichtigsten Regeln f√ºr Reproduzierbarkeit."
  },
  {
    "objectID": "02-rmarkdown.html#lesestoff",
    "href": "02-rmarkdown.html#lesestoff",
    "title": "2¬† R Markdown f√ºr reproduzierbare Forschung",
    "section": "2.7 Lesestoff",
    "text": "2.7 Lesestoff\nIntro zu Kapitel 2 (Basics), Kapitel 3.2.1 und 3.2.2 in Xie, Allaire, and Grolemund (2021)"
  },
  {
    "objectID": "02-rmarkdown.html#weiterf√ºhrende-literatur",
    "href": "02-rmarkdown.html#weiterf√ºhrende-literatur",
    "title": "2¬† R Markdown f√ºr reproduzierbare Forschung",
    "section": "2.8 Weiterf√ºhrende Literatur",
    "text": "2.8 Weiterf√ºhrende Literatur\nr4ds, Kapitel 27 (Wickham and Grolemund 2021)"
  },
  {
    "objectID": "02-rmarkdown.html#aufgaben",
    "href": "02-rmarkdown.html#aufgaben",
    "title": "2¬† R Markdown f√ºr reproduzierbare Forschung",
    "section": "2.9 Aufgaben",
    "text": "2.9 Aufgaben\n\n2.9.1 Erstes Notebook\n\nErstellen Sie ein R Notebook.\nF√ºgen Sie Layoutelemente hinzu:\n\n√úberschrift\nUnter√ºberschrift\nkursiver Text\nein Exponent: R2\nein Mathematikelement: \\(x^2\\)\neine Liste\n\n\nNutzen Sie die unter Kapitel¬†2.5 verlinkte Liste der Layoutelemente.\n\n\n2.9.2 Erste Schritte als Notebook\n\nEditieren Sie das R Notebook der ersten Session.\nGliedern Sie Ihr Notebook mit passenden Layoutelementen.\nF√ºgen Sie mehr Erkl√§rungstext zu den einzelnen Abschnitten.\n\n\n\n\n\nKnuth, D. E. 1984. ‚ÄúLiterate Programming.‚Äù The Computer Journal 27 (2): 97‚Äì111. https://doi.org/10.1093/comjnl/27.2.97.\n\n\nWickham, Hadley, and Garrett Grolemund. 2021. R for Data Science. https://r4ds.had.co.nz/.\n\n\nXie, Yihui, J. J. Allaire, and Garrett Grolemund. 2021. R Markdown: The Definitive Guide. https://bookdown.org/yihui/rmarkdown/."
  },
  {
    "objectID": "03-ggplot.html#aufbau-eines-darstellungsbefehls",
    "href": "03-ggplot.html#aufbau-eines-darstellungsbefehls",
    "title": "2¬† Einf√ºhrung in die Darstellung von Daten",
    "section": "2.1 Aufbau eines Darstellungsbefehls",
    "text": "2.1 Aufbau eines Darstellungsbefehls\nDas Paket ggplot2 ist ein sehr m√§chtiges Visualisierungswerkzeug. Der Name steht f√ºr ‚Äúthe grammar of graphics‚Äù. Es ist Teil der Paketsammlung tidyverse, √ºber die Sie in Kapitel (explorative-datenanalyse?) mehr lernen werden. In ggplot2 baut man seine Grafik mithilfe von verschiedenen Funktion Schritt f√ºr Schritt wie einen (grammatikalisch korrekten) Satz auf. In aller K√ºrze bedeutet das:\n\nEine statistische Grafik ist eine Zuordnung (mapping) von Variablen in einem Datensatz (data) zu (√§sthetischen) Attributen (aes) von geometrischen Objekten (geom).\n\nWir m√ºssen R also f√ºr die Darstellung von Daten Folgendes mitteilen:\n\ndata: der Datensatz, der die Variablen enth√§lt, die wir darstellen m√∂chten.\naes: (√§sthetische) Attribute f√ºr die geometrischen Objekte, die dargestellt werden sollen. Diese Attribute sind, z.B. die x und y Koordinaten, Farbe, Form und Gr√∂√üe der geometrischen Objekte\ngeom: geometrische Objekte, die dargestellt werden sollen, z.B. Punkte, Linien, Boxen, Balken/S√§ulen etc.\n\nWir spielen das am Beispiel des Datensatzes gapminder durch, den Sie im Paket gapminder finden. Wir laden zun√§chst die n√∂tigen Pakete.\n\nlibrary(tidyverse)\nlibrary(gapminder)\n\n\n\nSehen Sie die bedeutung der einzlenen Variablen im Datensatz gapminder in der Hilfe nach. Tippen Sie dazu ?gapminder in der Konsole oder in einem Chunk und lassen Sie den Code ausf√ºhren.\n\n\nAnschlie√üend filtern wir den Datensatz gapminder, um nur die Daten aus dem Jahr 2007 zu behalten. Der Code filter(year == 2007) bedeutet, dass wir nur die Zeilen aus dem Datensatz behalten wollen, in denen in der Variable year 2007 steht.\n\ngapminder2007 <- gapminder %>% \n  filter(year == 2007)\n\nWir √ºberzeugen uns davon, dass es geklappt hat üòÑ. Bl√§ttern Sie durch den Datensatz und √ºberpr√ºfen Sie die Werte in der Variablen year.\n\ngapminder2007"
  },
  {
    "objectID": "03-ggplot.html#sec-scatter",
    "href": "03-ggplot.html#sec-scatter",
    "title": "2¬† Einf√ºhrung in die Darstellung von Daten",
    "section": "2.2 Streudiagramm",
    "text": "2.2 Streudiagramm\nEin typischer Befehl zur Visualisierung eines Streudiagramms w√ºrde so aussehen:\n\nggplot(data = gapminder2007, \n       mapping = aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point()\n\n\n\n\nIn Worten k√∂nnte man es vielleicht wie folgt umschreiben:\n\nNimm den Datensatz gapminder2007 (data = gapminder2007) und\nordne folgende Attribute zu:\n\nauf die x-Achse die Variable gdpPercap (x = gdpPercap) (Bruttoinlandsprodukt)\nauf die y-Achse die Variable lifeExp (y = lifeExp) (Lebenserwartung)\nf√§rbe ein mithilfe der Variablen continent (color = continent).\n\nStelle das Ganze als geometrisches Objekt Punkte dar (geom_point())\n\nSie sehen, dass diese Zuordnungen klar nach einer Legende verlangen, die dann auch automatisch erstellt wird. Merke: color innerhalb der Funktion aes() erstellt die Legende automatisch.\nDie Anweisungen zur Visualisierung in ggplot2 werden mit einem + verbunden. Man kann (und in diesem Fall soll) weitere Anweisungen geben. Z. B. sind die Beschriftungen der beiden Achsen so nichtssagend und m√ºssen verbessert werden. Wir h√§ngen mit einem +-Zeichen weitere Befehle hinzu:\n\nggplot(data = gapminder2007, \n       mapping = aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point() + \n  labs(x = 'Bruttoinlandsprodukt pro Einwohner (US$, inflationsbereinigt)',\n       y = 'Lebenserwartung bei der Geburt (Jahre)',\n       color = 'Kontinent',\n       title = 'Daten von Gapminder f√ºr das Jahr 2007',\n       caption = 'http://www.gapminder.org/data/')"
  },
  {
    "objectID": "03-ggplot.html#weitere-geoms",
    "href": "03-ggplot.html#weitere-geoms",
    "title": "2¬† Einf√ºhrung in die Darstellung von Daten",
    "section": "2.3 Weitere geoms",
    "text": "2.3 Weitere geoms\nDas geom_point() produziert ein Streudiagramm auch XY-Diagramm (scatter plot). Weiter wichtige Grafiktypen sind\n\ngeom_line(): Linien\ngeom_bar(): Balken"
  },
  {
    "objectID": "03-ggplot.html#sec-line",
    "href": "03-ggplot.html#sec-line",
    "title": "2¬† Einf√ºhrung in die Darstellung von Daten",
    "section": "2.4 Liniendiagramm",
    "text": "2.4 Liniendiagramm\nEs ergibt wenig Sinn, die obere Grafik mit Linien darzustellen. Allerdings eignen sich Linien ausgezeichnet, um einen zeitlichen Verlauf zu visualisieren. Daher filtern wir aus dem Datensatz gapminder die Zeitreihen f√ºr Frankreich und Deutschland heraus. Weil wir jetzt zwei L√§nder haben m√∂chten, muss beim Filtern ein Vektor mit L√§ndernamen angegeben werden und statt == der Operator %in%. Wir werden sp√§ter noch ausf√ºhrlich auf diese Operatoren zur√ºckkommen.\n\nfrance_germany <- gapminder %>% \n  filter(country %in% c('France', 'Germany'))\n\n\nggplot(data = france_germany, \n       mapping = aes(x = year, y = gdpPercap, color = country)) +\n  geom_line()\n\n\n\n\n\n\nBeschriften Sie die Grafik (Achsen, Titel, Legende etc.)."
  },
  {
    "objectID": "03-ggplot.html#balkendiagramm",
    "href": "03-ggplot.html#balkendiagramm",
    "title": "2¬† Einf√ºhrung in die Darstellung von Daten",
    "section": "2.5 Balkendiagramm",
    "text": "2.5 Balkendiagramm\nWie viele L√§nder gibt es pro Kontinent im Jahr 2007? Das Balkendiagramm z√§hlt f√ºr uns die Eintr√§ge im Datensatz zusammen. Es stellt also dieselben Daten dar, die eine H√§ufigkeitstabelle enthalten w√ºrde.\n\nggplot(data = gapminder2007, \n       mapping = aes(x = continent)) +\n  geom_bar()\n\n\n\n\n\n\nBeschriften Sie die Grafik (Achsen, Titel, Legende etc.)."
  },
  {
    "objectID": "03-ggplot.html#lesestoff",
    "href": "03-ggplot.html#lesestoff",
    "title": "2¬† Einf√ºhrung in die Darstellung von Daten",
    "section": "2.6 Lesestoff",
    "text": "2.6 Lesestoff\nKapitel 2.1 in Ismay and Kim (2021)"
  },
  {
    "objectID": "03-ggplot.html#aufgaben",
    "href": "03-ggplot.html#aufgaben",
    "title": "2¬† Einf√ºhrung in die Darstellung von Daten",
    "section": "2.7 Aufgaben",
    "text": "2.7 Aufgaben\n\n2.7.1 Grafik interpretieren\nVor allem am Anfang kann die Lernkurve in R recht flach verlaufen. Daher sollten Sie nicht vergessen, warum Sie R lernen, n√§mlich um echte Datens√§tze zu analysieren.\nAuch wenn Sie den Code unten noch nicht verstehen, kopieren Sie ihn in einen neuen R-Chunk in Ihrem Notebook und lassen Sie ihn laufen.\n\nlibrary(tidyverse)\nlibrary(gapminder)\n\ngapminder2007 <- gapminder %>% \n  filter(year == 2007)\n\nggplot(gapminder2007, aes(x = gdpPercap, y = lifeExp, color = continent, size = pop)) +\n  geom_point() +\n  scale_x_log10() +\n  labs(x = 'Bruttoinlandsprodukt pro Einwohner ($, inflationsbereinigt)', \n       y = 'Lebenserwartung bei der Geburt (Jahre)',\n       title = 'Daten von Gapminder f√ºr das Jahr 2007',\n       caption = 'http://www.gapminder.org/data/')\n\n\nWelche Daten sind in diesem Datensatz enthalten? Nutzen Sie die Hilfe, i.e.¬†?gapminder.\nWas stellen die Farben in der Abbildung dar?\nWas wird durch die Symbolgr√∂√üe dargestellt?\nWie w√ºrden Sie den Zusammenhang zwischen den Variablen Bruttoinlandsprodukt pro Einwohner ($, inflationsbereinigt) und Lebenserwartung bei der Geburt (Jahre) beschreiben?\n\n\n\n2.7.2 Darstellung von gro√üen Zahlen\nWir ver√§ndern die obere Grafik so, dass die Symbole nach der Gr√∂√üe der Einwohnerzahl skaliert werden. Dazu benutzen wir ein neues Argument in der Funktion aes(size = pop):\n\nggplot(data = gapminder2007, \n       mapping = aes(x = gdpPercap, y = lifeExp, color = continent, size = pop)) +\n  geom_point() + \n  labs(x = 'Bruttoinlandsprodukt pro Einwohner (US$, inflationsbereinigt)',\n       y = 'Lebenserwartung bei der Geburt (Jahre)',\n       color = 'Kontinent',\n       title = 'Daten von Gapminder f√ºr das Jahr 2007',\n       caption = 'http://www.gapminder.org/data/')\n\n\n\n\nDie Einwohnerzahlen sind sehr gro√ü. Daher stellt R sie in der sogen. wissenschaftlichen Notation dar. Dabei steht z. B. e+08 f√ºr \\(10^8\\). Das hei√üt 2.5e+08 sind 250000000 Einwohner.\nBeschriften Sie die Legende f√ºr die Gr√∂√üe der Symbole richtig, indem Sie size = 'Einwohnerzahl' in der Funktion labs() hinzuf√ºgen."
  },
  {
    "objectID": "03-ggplot.html#ihre-arbeit-einreichen",
    "href": "03-ggplot.html#ihre-arbeit-einreichen",
    "title": "2¬† Einf√ºhrung in die Darstellung von Daten",
    "section": "2.8 Ihre Arbeit einreichen",
    "text": "2.8 Ihre Arbeit einreichen\n\nSpeichern Sie Ihr Notebook ab.\nLaden Sie Ihre .Rmd Datei in ILIAS hoch. Beachten Sie die Frist!\nSie erhalten die Musterl√∂sung nach dem Hochladen.\n\n\n\n\n\nIsmay, Chester, and Albert Y. Kim. 2021. ModernDive: Statistical Inference via Data Science. https://moderndive.com/."
  },
  {
    "objectID": "04-einlesen.html#daten-aus-textdateien-in-r-einlesen",
    "href": "04-einlesen.html#daten-aus-textdateien-in-r-einlesen",
    "title": "3¬† Daten in R einlesen und aus R speichern",
    "section": "3.1 Daten aus Textdateien in R einlesen",
    "text": "3.1 Daten aus Textdateien in R einlesen\nUm Daten aus Textdateien (z.B. aus .csv, .txt, .dat) in R zu importieren (i.e.¬†einzulesen) werden wir die Bibliothek readr aus tidyverse benutzen. Wir laden erst einmal tidyverse.\n\nlibrary(tidyverse)\n\nWir gehen davon aus, dass die Daten im Ordner Daten gespeichert sind. Falls Ihre Daten an einem anderen Ort abgelegt sind, m√ºssen Sie den Pfad beim Einlesen entsprechend anpassen.\nUm die Daten zu laden, gibt es in der Bibliothek readr verschiedene Funktionen, die alle mit read_ beginnen. Die allgemeinste davon ist read_delim. Darin kann man explizit einstellen, mit welchem Zeichen (z. B. Komma, Strichpunkt etc.) die einzelnen Spalten in der zu importierenden Datei getrennt sind. In der Datei, die wir einlesen, ist das Trennungszeichen ;. Das m√ºssen Sie aber bei jeder Datei, die Sie einlesen, nachsehen.\n\ncar_numbers <- read_delim(file = 'Daten/autos_2022-11-06.csv', delim = ';')\n\nRows: 76 Columns: 4\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \";\"\nchr  (2): geo, unit\ndbl  (1): values\ndate (1): time\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nEin kurzer Blick auf den Datensatz, den Sie aus der ersten Sitzung der Vorlesung erkennen sollten üòÑ. Es sind die Daten zur Mobilit√§t in Europa aus eurostat, heruntergeladen am 06.11.2022 und vorgefiltert. Die Daten beinhalten die Anzhal der ‚ÄúPersonenkraftwagen je 1 000 Einwohner‚Äù, online Datencode: ROAD_EQS_CARHAB.\n\ncar_numbers\n\n\n\n  \n\n\n\nDas Ergebnis des Einlesens mit read_ Funktionen ist immer ein tibble."
  },
  {
    "objectID": "04-einlesen.html#einzelne-variablen-ansprechen",
    "href": "04-einlesen.html#einzelne-variablen-ansprechen",
    "title": "3¬† Daten in R einlesen und aus R speichern",
    "section": "3.2 Einzelne Variablen ansprechen",
    "text": "3.2 Einzelne Variablen ansprechen\nJede Variable hat einen Namen. Man kann diesen nutzen, um die Variable anzusprechen. Z. B. k√∂nnten wir die Variable geo so ansprechen:\n\ncar_numbers$geo\n\n [1] \"Albania\"         \"Albania\"         \"Austria\"         \"Austria\"        \n [5] \"Belgium\"         \"Belgium\"         \"Bulgaria\"        \"Bulgaria\"       \n [9] \"Croatia\"         \"Croatia\"         \"Cyprus\"          \"Cyprus\"         \n[13] \"Czechia\"         \"Czechia\"         \"Denmark\"         \"Denmark\"        \n[17] \"Estonia\"         \"Estonia\"         \"Finland\"         \"Finland\"        \n[21] \"France\"          \"France\"          \"Germany\"         \"Germany\"        \n[25] \"Greece\"          \"Greece\"          \"Hungary\"         \"Hungary\"        \n[29] \"Iceland\"         \"Iceland\"         \"Ireland\"         \"Ireland\"        \n[33] \"Italy\"           \"Italy\"           \"Kosovo\"          \"Kosovo\"         \n[37] \"Latvia\"          \"Latvia\"          \"Liechtenstein\"   \"Liechtenstein\"  \n[41] \"Lithuania\"       \"Lithuania\"       \"Luxembourg\"      \"Luxembourg\"     \n[45] \"Malta\"           \"Malta\"           \"Montenegro\"      \"Montenegro\"     \n[49] \"Netherlands\"     \"Netherlands\"     \"North Macedonia\" \"North Macedonia\"\n[53] \"Norway\"          \"Norway\"          \"Poland\"          \"Poland\"         \n[57] \"Portugal\"        \"Portugal\"        \"Romania\"         \"Romania\"        \n[61] \"Serbia\"          \"Serbia\"          \"Slovakia\"        \"Slovakia\"       \n[65] \"Slovenia\"        \"Slovenia\"        \"Spain\"           \"Spain\"          \n[69] \"Sweden\"          \"Sweden\"          \"Switzerland\"     \"Switzerland\"    \n[73] \"T√ºrkiye\"         \"T√ºrkiye\"         \"United Kingdom\"  \"United Kingdom\" \n\n\nSie sehen, dass die Darstellung jetzt anders aussieht, weil eine einzelne Variable ein Vektor ist und kein tibble. Vektoren werden (durchnummeriert) ausgegeben und wir sehen alle 76 Eintr√§ge (L√§nder) nacheinander in der Reihenfolge ihres Erscheinens in der Variablen geo."
  },
  {
    "objectID": "04-einlesen.html#ansprechen-von-spalten-zeilen-und-zellen-in-einem-tibble",
    "href": "04-einlesen.html#ansprechen-von-spalten-zeilen-und-zellen-in-einem-tibble",
    "title": "3¬† Daten in R einlesen und aus R speichern",
    "section": "3.3 Ansprechen von Spalten, Zeilen und Zellen in einem tibble",
    "text": "3.3 Ansprechen von Spalten, Zeilen und Zellen in einem tibble\nEin tibble ist ein zwei-dimensionales Objekt: Es hat Zeilen (erste Dimension) und Spalten (zweite Dimension). Um so ein Objekt richtig anzusprechen, erweitern wir unsere Notation mit den eckigen Klammern. Jetzt brauchen wir n√§mlich zwei Indizes: einen Index f√ºr die Zeile und einen Index f√ºr die Spalte eines Eintrags. Wenn wir z. B. den dritten Eintrag in der ersten Spalte (Variable geo) sehen wollen, schreiben wir:\n\ncar_numbers[3, 1]\n\n\n\n  \n\n\n\nEs handelt sich um √ñsterreich. Wir k√∂nnen auch ganze Spalten (Variablen) ansprechen. Daf√ºr wird der erste Index (f√ºr Zeilen) weggelassen. Nichts (oder ein Leerzeichen) signalisieren R, dass alle Eintr√§ge gemeint sind. So k√∂nnen wir die erste Spalte wie folgt ansprechen:\n\ncar_numbers[, 1]\n\n\n\n  \n\n\n\nBeim Ansprechen ganzer Zeilen ist es √§hnlich. Wir lassen den Index f√ºr die Spalte weg. Um die erste Zeile anzusprechen, schreiben wir:\n\ncar_numbers[1,]\n\n\n\n  \n\n\n\nSie sollten einen wichtigen Unterschied zwischen der $-Notation und dem Ansprechen in eckigen Klammern bemerken: Die $-Notation gibt einen Vektor zur√ºck. Wenn Sie ein tibble mit eckigen Klammern ansprechen, ist die Antwort ein tibble."
  },
  {
    "objectID": "04-einlesen.html#ein-tibble-erstellen",
    "href": "04-einlesen.html#ein-tibble-erstellen",
    "title": "3¬† Daten in R einlesen und aus R speichern",
    "section": "3.4 Ein tibble erstellen",
    "text": "3.4 Ein tibble erstellen\nUm ein tibble zu erstellen, nutzen wir die Funktion tibble() und z√§hlen auf, welche Variablen wir dort haben m√∂chten.\n\ncar_numbers_short <- tibble(Land = car_numbers$geo, Zeit = car_numbers$time)\n\nIn dem Datensatz car_numbers_short haben wir jetzt die beiden Variablen geo und time aus dem Datensatz car_numbers als tibble abgespeichert."
  },
  {
    "objectID": "04-einlesen.html#daten-aus-r-speichern",
    "href": "04-einlesen.html#daten-aus-r-speichern",
    "title": "3¬† Daten in R einlesen und aus R speichern",
    "section": "3.5 Daten aus R speichern",
    "text": "3.5 Daten aus R speichern\nWir speichern dieses tibble als Textdatei. Daf√ºr nutzen wir die Funktion write_delim(), die ebenfalls in der Bibliothek readr in tidyverse vorhanden ist. Achten Sie darauf, dass write_delim() nur tibble speichern kann. Wenn Sie einen Vektor (eine einzelne Variable) abspeichern m√∂chten, dann wandeln Sie diesen zuerst in ein tibble um.\n\nwrite_delim(x = car_numbers_short, file = 'Daten/geo.csv', delim = ';')"
  },
  {
    "objectID": "04-einlesen.html#lesestoff",
    "href": "04-einlesen.html#lesestoff",
    "title": "3¬† Daten in R einlesen und aus R speichern",
    "section": "3.6 Lesestoff",
    "text": "3.6 Lesestoff\nKapitel 4.1 in Ismay and Kim (2021)"
  },
  {
    "objectID": "04-einlesen.html#aufgaben",
    "href": "04-einlesen.html#aufgaben",
    "title": "3¬† Daten in R einlesen und aus R speichern",
    "section": "3.7 Aufgaben",
    "text": "3.7 Aufgaben\nBearbeiten Sie die eigenst√§ndigen √úbungen Lab01 und Lab02.\n\n\n\n\n\n\n\n\nIsmay, Chester, and Albert Y. Kim. 2021. ModernDive: Statistical Inference via Data Science. https://moderndive.com/."
  },
  {
    "objectID": "04-einlesen.html#die-umfrage-aus-der-ersten-sitzung",
    "href": "04-einlesen.html#die-umfrage-aus-der-ersten-sitzung",
    "title": "3¬† Daten in R einlesen und aus R speichern",
    "section": "3.8 Die Umfrage aus der ersten Sitzung",
    "text": "3.8 Die Umfrage aus der ersten Sitzung\nLesen Sie die Datei ‚ÄòUmfrage_2022_kurz.csv‚Äô ein. Sie enth√§lt die Umfrageergebnisse aus der ersten Session der Vorlesung zur Frage ‚ÄòHaben Sie schon mal einen Statistikkurs besucht?‚Äô\n\nWie viele Eintr√§ge enth√§lt der Datensatz?\nWie viele Variablen enth√§lt der Datensatz?\nSind die Variablen numerisch oder kategorial?\nErkl√§ren Sie jede Variable. Welche Information enth√§lt sie?\nStellen Sie die Antworten auf die Frage als Balkendiagramm dar. Es soll wie folgt aussehen:\n\n\n\n\n\n\n\nWie viele Teilnehmende haben bereits einen Statistikkurs besucht (ungef√§hr)?"
  },
  {
    "objectID": "04-einlesen.html#ihre-arbeit-einreichen",
    "href": "04-einlesen.html#ihre-arbeit-einreichen",
    "title": "3¬† Daten in R einlesen und aus R speichern",
    "section": "3.9 Ihre Arbeit einreichen",
    "text": "3.9 Ihre Arbeit einreichen\n\nSpeichern Sie Ihr Notebook ab.\nLaden Sie Ihre .Rmd Datei in ILIAS hoch. Beachten Sie die Frist!\nSie erhalten die Musterl√∂sung nach dem Hochladen.\n\n\n\n\n\nIsmay, Chester, and Albert Y. Kim. 2021. ModernDive: Statistical Inference via Data Science. https://moderndive.com/."
  },
  {
    "objectID": "30-lab-02-intro-to-data.html#erste-schritte",
    "href": "30-lab-02-intro-to-data.html#erste-schritte",
    "title": "8¬† Lab 02: P√ºnktlichkeit von Fl√ºgen",
    "section": "8.1 Erste Schritte",
    "text": "8.1 Erste Schritte\n\n8.1.1 Pakete laden\nIn dieser √úbung werden wir die Daten mithilfe der Paketsammlung tidyverse untersuchen und visualisieren. Die Daten befinden sich im Begleitpaket f√ºr OpenIntro-√úbungen, openintro.\nLassen Sie uns die Pakete laden.\n\nlibrary(tidyverse)\nlibrary(openintro)\n\n\n\n8.1.2 Erstellen eines reproduzierbaren Berichts\nDenken Sie daran, dass wir R Markdown verwenden werden, um reproduzierbare Berichte zu erstellen. Gehen Sie in RStudio zu New File -> R Markdown‚Ä¶ W√§hlen Sie dann From Template und w√§hlen Sie dann Lab Report for OpenIntro Statistics Labs aus der Liste der Vorlagen. Oder verfahren Sie so, wie wir es in den √úbungen gelernt haben New File -> R Notebook‚Ä¶ Beide Varianten sind in Ordnung. Wenn Sie die Variante mit R Markdown w√§hlen, gibt es keinen Button ‚ÄúPreview‚Äù, sondern Sie m√ºssen das Dokument ‚Äúknitten‚Äù √ºber den Button mit dem Wollkn√§uel.\nSehen Sie sich das folgende Video an, in dem beschrieben wird, wie Sie mit der Erstellung dieser Berichte f√ºr dieses und alle zuk√ºnftigen Labs beginnen k√∂nnen:\nGrundlegendes zu R Markdown mit einer OpenIntro-√úbung \n\n\n8.1.3 Die Daten\nDas Bureau of Transportation Statistics (BTS) ist eine Statistikbeh√∂rde, die zur Research and Innovative Technology Administration (RITA) geh√∂rt. Wie der Name schon sagt, sammelt das BTS Verkehrsdaten und stellt sie zur Verf√ºgung, wie z. B. die Flugdaten, mit denen wir in diesem Labor arbeiten werden.\nAls Erstes werden wir uns den Datensatz nycflights ansehen. Geben Sie Folgendes in Ihre Konsole ein, um die Daten zu laden:\n\ndata(nycflights)\n\nDer Datensatz nycflights, der in Ihrem Arbeitsbereich angezeigt wird, ist eine Datenmatrix oder Datentabelle, wobei jede Zeile eine Beobachtung und jede Spalte eine Variable darstellt. In R wird dieses Datenformat als Dataframe bezeichnet, ein Begriff, der in den √úbungen immer wieder verwendet wird. Bei diesem Datensatz ist jede Beobachtung ein einzelner Flug.\nUm die Namen der Variablen anzuzeigen, geben Sie den Befehl\n\nnames(nycflights)\n\nDies gibt die Namen der Variablen in diesem Datenrahmen zur√ºck. Das Codebuch (Beschreibung der Variablen) kann √ºber die Hilfedatei abgerufen werden:\n\n?nycflights\n\nEine der Variablen bezieht sich auf die Fluggesellschaft des Fluges, die nach folgendem System kodiert wird.\n\ncarrier (Fluggesellschaft): Zweibuchstabiges K√ºrzel der Fluggesellschaft.\n\n9E: Endeavor Air Inc.\nAA: American Airlines Inc.\nAS: Alaska Airlines Inc.\nB6: JetBlue Airways\nDL: Delta Air Lines Inc.\nEV: ExpressJet Fluggesellschaften Inc.\nF9: Frontier Airlines Inc.\nFL: AirTran Airways Corporation\nHA: Hawaiian Airlines Inc.\nMQ: Envoy Air\nOO: SkyWest Airlines Inc.\nUA: United Air Lines Inc.\nUS: US Airways Inc.\nVX: Virgin America\nWN: Southwest Airlines Co.\nYV: Mesa Airlines Inc.\n\n\nDenken Sie daran, dass Sie die Funktion glipmse() nutzen k√∂nnen, um einen √úberblick √ºber die Daten zu erhalten und somit deren Inhalt besser zu verstehen.\n\nglimpse(nycflights)\n\nDer Datensatz nycflights ist eine riesige Fundgrube an Informationen. Lassen Sie uns √ºber einige Fragen nachdenken, die wir mit diesen Daten beantworten wollen:\n\nWie versp√§tet waren die Fl√ºge nach Los Angeles?\nWie unterscheiden sich die Abflugversp√§tungen je nach Monat?\nWelcher der drei gro√üen Flugh√§fen in New York hat den besten Prozentsatz an p√ºnktlichen Abfl√ºgen?"
  },
  {
    "objectID": "30-lab-02-intro-to-data.html#analyse",
    "href": "30-lab-02-intro-to-data.html#analyse",
    "title": "8¬† Lab 02: P√ºnktlichkeit von Fl√ºgen",
    "section": "8.2 Analyse",
    "text": "8.2 Analyse\n\n8.2.1 Bericht\nUm Ihre Analyse in einem reproduzierbaren Bericht festzuhalten, k√∂nnen Sie die allgemeine Vorlage f√ºr Berichte aus dem Paket openintro anpassen. Sehen Sie sich das Video oben an, um zu erfahren, wie das geht.\n\n\n8.2.2 Abflugversp√§tungen\nBeginnen wir damit, die Verteilung der Abflugversp√§tungen aller Fl√ºge mit einem Histogramm zu untersuchen.\n\nggplot(data = nycflights, aes(x = dep_delay)) +\n  geom_histogram()\n\nMit dieser Funktion wird die Variable dep_delay aus dem Dataframe nycflights auf der \\(x\\)-Achse dargestellt. Sie definiert auch ein geom (kurz f√ºr geometrisches Objekt), das die Art der Darstellung beschreibt, die Sie erzeugen werden.\nHistogramme eignen sich im Allgemeinen sehr gut, um die Form der Verteilung einer einzelnen numerischen Variablen zu sehen, aber diese Form kann sich √§ndern, je nachdem, wie die Daten auf die verschiedenen Bins aufgeteilt sind. Sie k√∂nnen die zu verwendende Bin-Breite einfach festlegen:\n\nggplot(data = nycflights, aes(x = dep_delay)) +\n  geom_histogram(binwidth = 15)\n\n\nggplot(data = nycflights, aes(x = dep_delay)) +\n  geom_histogram(binwidth = 150)\n\n\n\nSchauen Sie sich diese drei Histogramme genau an. Wie lassen sie sich vergleichen? Sind in einem Histogramm Merkmale zu erkennen, die in einem anderen verdeckt sind?\n\n\nWenn Sie nur die Versp√§tungen von Fl√ºgen nach Los Angeles anzeigen m√∂chten, m√ºssen Sie zun√§chst die Daten nach Fl√ºgen mit diesem Ziel filter()n (dest == \"LAX\") und dann ein Histogramm der Abflugversp√§tungen nur dieser Fl√ºge erstellen.\n\nlax_flights <- nycflights %>%\n  filter(dest == \"LAX\")\nggplot(data = lax_flights, aes(x = dep_delay)) +\n  geom_histogram()\n\nLassen Sie uns diese beiden Befehle entschl√ºsseln (OK, es sieht vielleicht nach vier Zeilen aus, aber die ersten beiden physischen Codezeilen sind tats√§chlich Teil desselben Befehls. Es ist √ºblich, nach %>% einen Zeilenumbruch einzuf√ºgen, um die Lesbarkeit zu verbessern).\n\nBefehl 1: Nehmen Sie den Dataframe nycflights, filter()n Sie nach Fl√ºgen zum LAX und speichern Sie das Ergebnis als neuen Datenrahmen namens lax_flights.\n\n== bedeutet ‚Äúwenn es gleich ist mit‚Äù.\nLAX steht in Anf√ºhrungszeichen, da es sich um eine Zeichenkette handelt.\n\nBefehl 2: Im Grunde derselbe ggplot-Aufruf wie bei der Erstellung eines Histogramms, nur dass hier das kleinere Dataframe f√ºr Fl√ºge mit Ziel LAX anstelle aller Fl√ºge verwendet wird.\n\n\nLogische Operatoren: Das Filtern nach bestimmten Beobachtungen (z. B. Fl√ºge von einem bestimmten Flughafen) ist in Dataframes oft von Interesse, wenn wir Beobachtungen mit bestimmten Merkmalsauspr√§gungen getrennt vom Rest der Daten untersuchen m√∂chten. Zu diesem Zweck k√∂nnen Sie die Filterfunktion und eine Reihe von logischen Operatoren verwenden. Die am h√§ufigsten verwendeten logischen Operatoren f√ºr die Datenanalyse sind die folgenden:\n\n== bedeutet ‚Äúgleich‚Äù\n!= bedeutet ‚Äúnicht gleich‚Äù\n> oder < bedeutet ‚Äúgr√∂√üer als‚Äù oder ‚Äúkleiner als‚Äù.\n>= oder <= bedeutet ‚Äúgr√∂√üer als oder gleich‚Äù oder ‚Äúkleiner als oder gleich‚Äù.\n\n\nSie k√∂nnen auch numerische Zusammenfassungen f√ºr diese Fl√ºge erhalten:\n\nlax_flights %>%\n  summarise(mean_dd   = mean(dep_delay), \n            median_dd = median(dep_delay), \n            n         = n())\n\nBeachten Sie, dass Sie in der Funktion summarise() eine Liste mit drei verschiedenen numerischen Zusammenfassungen erstellt haben, an denen Sie interessiert waren. Die Namen dieser Elemente sind benutzerdefiniert, wie mean_dd, median_dd, n, und Sie k√∂nnen diese Namen nach Belieben anpassen (verwenden Sie nur keine Leerzeichen in Ihren Namen). F√ºr die Berechnung dieser zusammenfassenden Statistiken m√ºssen Sie auch die Funktionsaufrufe kennen. Beachten Sie, dass n() den Stichprobenumfang angibt.\n\nZusammenfassende Statistiken aka statistische Lage- und Streuma√üe: Einige n√ºtzliche Funktionsaufrufe f√ºr zusammenfassende Statistiken f√ºr eine einzelne numerische Variable sind wie folgt:\n\nMittelwert: mean()\nMedian: median()\nStandardabweichung: sd()\nVarianz: var()\nInterquartilabstand: IQR()\nKleinster Wert: min()\nGr√∂√üter Wert: max()\n\nBeachten Sie, dass jede dieser Funktionen einen einzelnen Vektor als Argument annimmt und einen einzelnen Wert zur√ºckgibt.\n\nSie k√∂nnen auch nach mehreren Kriterien filtern. Angenommen, Sie sind an Fl√ºgen nach San Francisco (SFO) im Februar interessiert:\n\nsfo_feb_flights <- nycflights %>%\n  filter(dest == \"SFO\", month == 2)\n\nBeachten Sie, dass Sie die Bedingungen durch Kommas trennen k√∂nnen, wenn Sie Fl√ºge sowohl nach SFO als auch im Februar suchen. Wenn Sie entweder an Fl√ºgen nach SFO oder an Fl√ºgen im Februar interessiert sind, k√∂nnen Sie das | anstelle des Kommas verwenden.\n\n\nErstellen Sie ein neues Dataframe, das Fl√ºge nach SFO im Februar enth√§lt, und speichern Sie diesen Datenrahmen als sfo_feb_flights. Wie viele Fl√ºge erf√ºllen diese Kriterien?\nBeschreiben Sie die Verteilung der Ankunftsversp√§tungen arr_delay dieser Fl√ºge anhand eines Histogramms und geeigneter zusammenfassender Statistiken. Tipp: Die von Ihnen verwendete zusammenfassende Statistik sollte von der Form der Verteilung abh√§ngen.\n\n\nEine weitere n√ºtzliche Methode ist die schnelle Berechnung von zusammenfassenden Statistiken f√ºr verschiedene Gruppen in Ihrem Dataframe. Wir k√∂nnen den obigen Befehl etwa mit der Funktion group_by() modifizieren, um die gleiche zusammenfassende Statistik f√ºr jeden Herkunftsflughafen zu erhalten:\n\nsfo_feb_flights %>%\n  group_by(origin) %>%\n  summarise(median_dd = median(dep_delay), iqr_dd = IQR(dep_delay), n_flights = n())\n\nHier haben wir die Daten zun√§chst nach Herkunft gruppiert und dann die zusammenfassenden Statistiken berechnet.\n\n\nBerechnen Sie den Median und den Interquartilsabstand f√ºr arr_delays der Fl√ºge im Datenrahmen sfo_feb_flights, gruppiert nach Fluggesellschaft. Welche Fluggesellschaft hat Ankunftsversp√§tungen mit der gr√∂√üten Variabilit√§t?"
  },
  {
    "objectID": "30-lab-02-intro-to-data.html#abflugversp√§tungen-nach-monaten",
    "href": "30-lab-02-intro-to-data.html#abflugversp√§tungen-nach-monaten",
    "title": "8¬† Lab 02: P√ºnktlichkeit von Fl√ºgen",
    "section": "8.3 Abflugversp√§tungen nach Monaten",
    "text": "8.3 Abflugversp√§tungen nach Monaten\nIn welchem Monat w√ºrden Sie die h√∂chste durchschnittliche Versp√§tung bei Abfl√ºgen von einem New Yorker Flughafen erwarten?\nLassen Sie uns √ºberlegen, wie Sie diese Frage beantworten k√∂nnen:\n\nBerechnen Sie zun√§chst die monatlichen Durchschnittswerte f√ºr Abflugversp√§tungen. Mit der neuen Sprache, die Sie gerade lernen, k√∂nnten Sie\n\ngroup_by() nach Monaten, dann\ndie durchschnittlichen Abflugversp√§tungen zusammenfassen mit summarise().\n\nDann k√∂nnten Sie diese durchschnittlichen Versp√§tungen in absteigender Reihenfolge mit arrange()anordnen\n\n\nnycflights %>%\n  group_by(month) %>%\n  summarise(mean_dd = mean(dep_delay)) %>%\n  arrange(desc(mean_dd))\n\n\n\nAngenommen, Sie m√∂gen keine Versp√§tungen bei der Abreise und m√∂chten Ihre Reise in einem Monat planen, der Ihre m√∂gliche Versp√§tung bei der Abreise aus New York minimiert. Eine M√∂glichkeit ist, den Monat mit dem geringsten Mittelwerten der Abflugversp√§tung zu w√§hlen. Eine andere M√∂glichkeit ist, den Monat mit dem geringsten Median der Abflugversp√§tung zu w√§hlen. Was sind die Vor- und Nachteile dieser beiden M√∂glichkeiten?\n\n\n\n8.3.1 P√ºnktliche Abflugrate f√ºr NYC-Flugh√§fen\nAngenommen, Sie fliegen von New York City aus und m√∂chten wissen, welcher der drei gro√üen Flugh√§fen in New York City die beste P√ºnktlichkeitsrate bei abgehenden Fl√ºgen aufweist. Nehmen wir weiter an, dass f√ºr Sie ein Flug, der weniger als 5 Minuten Versp√§tung hat, grunds√§tzlich ‚Äúp√ºnktlich‚Äù (‚Äúon time‚Äù) ist. Sie betrachten jeden Flug, der mehr als 5 Minuten Versp√§tung hat, als ‚Äúversp√§tet‚Äù (‚Äúdelayed‚Äù).\nUm festzustellen, welcher Flughafen die beste P√ºnktlichkeitsquote hat, k√∂nnen Sie\n\nzun√§chst jeden Flug als ‚Äúon time‚Äù oder ‚Äúdelayed‚Äù einstufen,\ndann die Fl√ºge nach Herkunftsflughafen gruppieren,\ndann die Rate der p√ºnktlichen Abfl√ºge f√ºr jeden Herkunftsflughafen berechnen,\nund schlie√ülich die Flugh√§fen in absteigender Reihenfolge nach dem Prozentsatz der p√ºnktlichen Abfl√ºge ordnen.\n\nBeginnen wir mit der Klassifizierung der einzelnen Fl√ºge als ‚Äúon time‚Äù oder ‚Äúdelayed‚Äù, indem wir mit der Funktion mutate() eine neue Variable erstellen.\n\nnycflights <- nycflights %>%\n  mutate(dep_type = ifelse(dep_delay < 5, \"on time\", \"delayed\"))\n\nDas erste Argument in der Funktion mutate() ist der Name der neuen Variable, die wir erstellen wollen, in diesem Fall dep_type. Wenn dep_delay < 5 ist, klassifizieren wir den Flug als ‚Äúon time‚Äù, wenn nicht, als ‚Äúdelayed‚Äù, d.¬†h. wenn der Flug 5 oder mehr Minuten versp√§tet ist.\nBeachten Sie, dass wir auch das Dataframe nycflights mit der neuen Version dieses Dataframes √ºberschreiben, der die neue Variable dep_type enth√§lt.\nAlle √ºbrigen Schritte k√∂nnen wir in einem einzigen Code-Chunk erledigen:\n\nnycflights %>%\n  group_by(origin) %>%\n  summarise(ot_dep_rate = sum(dep_type == \"on time\") / n()) %>%\n  arrange(desc(ot_dep_rate))\n\n\n\nWenn Sie einen Flughafen nur aufgrund des prozentualen Anteils der Abfl√ºge in der Zeit ausw√§hlen w√ºrden, welchen Flughafen in NYC w√ºrden Sie dann w√§hlen?\n\n\nSie k√∂nnen auch die Verteilung der p√ºnktlichen Abflugrate auf die drei Flugh√§fen mithilfe eines Balkendiagramms visualisieren.\n\nggplot(data = nycflights, aes(x = origin, fill = dep_type)) +\n  geom_bar()"
  },
  {
    "objectID": "30-lab-02-intro-to-data.html#weitere-√ºbungen",
    "href": "30-lab-02-intro-to-data.html#weitere-√ºbungen",
    "title": "8¬† Lab 02: P√ºnktlichkeit von Fl√ºgen",
    "section": "8.4 Weitere √úbungen",
    "text": "8.4 Weitere √úbungen\n\n\n√Ñndern Sie das Dataframe so, dass es eine neue Variable enth√§lt, die die Durchschnittsgeschwindigkeit, avg_speed, die das Flugzeug bei jedem Flug zur√ºckgelegt hat (in mph), angibt. Tipp: Die Durchschnittsgeschwindigkeit kann als Entfernung geteilt durch die Anzahl der Flugstunden berechnet werden, und beachten Sie, dass die Flugzeit air_time in Minuten angegeben wird.\nErstellen Sie ein Streudiagramm von der Durchschnittsgeschwindigkeit avg_speed und Entfernung distance. Beschreiben Sie die Beziehung zwischen Durchschnittsgeschwindigkeit und Entfernung. Tipp: Verwenden Sie geom_point().\nBauen Sie die folgende Darstellung nach. Tipp: Das dargestellte Dataframe enth√§lt nur Fl√ºge von American Airlines, Delta Airlines und United Airlines, und die Punkte sind nach Fluggesellschaft carrier eingef√§rbt (colored). Ermitteln Sie nach dem Plotten (grob) den Grenzwert f√ºr Abflugversp√§tungen, bei dem Sie noch erwarten k√∂nnen, Ihr Ziel rechtzeitig zu erreichen."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Literatur",
    "section": "",
    "text": "√áetinkaya-Rundel, Mine, and Johanna Hardin. n.d. Introduction to\nModern Statistics. https://openintro-ims.netlify.app/.\n\n\nFahrmeir, L., T. Kneib, and S. Lang. 2009. Regression.\nSpringer. http://link.springer.com/book/10.1007/978-3-642-01837-4.\n\n\nIhaka, Ross, and Robert Gentleman. 1996. ‚ÄúR: A\nLanguage for Data Analysis and\nGraphics.‚Äù Journal of Computational and\nGraphical Statistics 5 (3): 299‚Äì314. https://doi.org/10.1080/10618600.1996.10474713.\n\n\nIsmay, Chester, and Albert Y. Kim. 2021. ModernDive:\nStatistical Inference via Data Science.\nhttps://moderndive.com/.\n\n\nKnuth, D. E. 1984. ‚ÄúLiterate Programming.‚Äù\nThe Computer Journal 27 (2): 97‚Äì111. https://doi.org/10.1093/comjnl/27.2.97.\n\n\nWickham, Hadley. 2020. Ggplot2: Elegant Graphics for\nData Analysis. 3rd, in progress. https://ggplot2-book.org/.\n\n\nWickham, Hadley, Mine √áetinkaya-Rundel, and Garrett Grolemund. 2023.\nR for Data Science (2e). https://r4ds.hadley.nz/.\n\n\nXie, Yihui, J. J. Allaire, and Garrett Grolemund. 2021. R\nMarkdown: The Definitive Guide. https://bookdown.org/yihui/rmarkdown/.\n\n\nZuur, A. F., E. Ieno, and E. Meesters. 2009. A Beginner‚Äôs Guide to\nR. Springer."
  },
  {
    "objectID": "100-aufgabensammlung.html#erste-schritte",
    "href": "100-aufgabensammlung.html#erste-schritte",
    "title": "Appendix A ‚Äî Aufgabensammlung",
    "section": "A.1 Erste Schritte",
    "text": "A.1 Erste Schritte\n\nA.1.1 Morphometrische Messungen an V√∂geln\nIn einer Studie wurden 1100 Spitzschwanzammer (Ammodramus caudacutus) vermessen. Wir nutzen einen Teil des Datensatzes (Zuur, Ieno, and Meesters 2009). Die gemessenen Variablen sind Fluegel, Fuss (Tarsus), Kopf, Gewicht. Leider git die Datenquelle die Messeinheiten nicht an. Die Daten sind wie folgt:\n\n\n\n\n\nFluegel\nFuss\nKopf\nGewicht\n\n\n\n\n59.0\n22.3\n31.2\n9.5\n\n\n55.0\n19.7\n30.4\n13.8\n\n\n53.5\n20.8\n30.6\n14.8\n\n\n55.0\n20.3\n30.3\n15.2\n\n\n52.5\n20.8\n30.3\n15.5\n\n\n57.5\n21.5\n30.8\n15.6\n\n\n53.0\n20.6\n32.5\n15.6\n\n\n55.0\n21.5\nNA\n15.7\n\n\n\n\n\n\n\n\nErstellen Sie jede Variable einzeln mithilfe der Funktion c().\nWie viele V√∂gel sind in der Tabelle zu finden. Nutzen Sie dazu die Funktion length(). Sehen Sie in der Hilfe nach, wie man diese benutzt.\nF√ºhren Sie alle Variablen zu einem einzelnen Datenobjekt, einem tibble zusammen mithilfe der Funktion tibble() aus dem R-Paket tibble."
  },
  {
    "objectID": "100-aufgabensammlung.html#einf√ºhrung-in-die-darstellung-von-daten",
    "href": "100-aufgabensammlung.html#einf√ºhrung-in-die-darstellung-von-daten",
    "title": "Appendix A ‚Äî Aufgabensammlung",
    "section": "A.2 Einf√ºhrung in die Darstellung von Daten",
    "text": "A.2 Einf√ºhrung in die Darstellung von Daten\n\nA.2.1 Pinguine\n\nLaden Sie die Bibliotheken tidyverse und palmerpenguins mithilfe der Funktion library().\nLaden Sie den Datensatz penguins mithilfe der Funktion data().\nSehen Sie sich den Datensatz an.\nPlotten Sie ein Streudiagramm der Variablen Flossenl√§nge flipper_length_mm auf der \\(x\\)-Achse und der Variablen K√∂rpergewicht body_mass_g auf der \\(y\\)-Achse.\nBeschriften Sie die Grafik sinnvoll.\nF√§rben Sie die Punkte je nach Art unterschiedlich ein mithilfe der Variablen species.\n\nSie sollten die gleiche (bis auf die Farbauswahl) Grafik erhalten, wie in der Vorlesung ü§ì."
  },
  {
    "objectID": "100-aufgabensammlung.html#daten-in-r-einlesen-und-aus-r-speichern",
    "href": "100-aufgabensammlung.html#daten-in-r-einlesen-und-aus-r-speichern",
    "title": "Appendix A ‚Äî Aufgabensammlung",
    "section": "A.3 Daten in R einlesen und aus R speichern",
    "text": "A.3 Daten in R einlesen und aus R speichern\n\nA.3.1 Politbarometer 2021: Einlesen von Fremdformaten\nEs gibt viele verschiedene Statistikpakete (z. B. SAS, SPSS, Stata), die mit grafischen Oberfl√§chen arbeiten. Da die Analysen darin nicht reproducible sind (weil mit der Maus zusammengeklickt), empfehlen wir diese nicht. Dennoch gibt es manchmal interessante Datens√§tze, die in den Formaten dieser Statistikpakete vorliegen. ACHTUNG: Diese Aufgabe ist anspruchsvoll!\nIn dieser √úbung lernen Sie das Paket haven kennen, dass solche Formate einlesen kann. Haven ist Teil von tidyverse, muss aber extra installiert und geladen werden.\n\nLaden Sie die Bibliotheken tidyverse und haven.\n\nWir besch√§ftigen uns mit dem Datensatz ‚ÄúPolitbarometer 2021‚Äù. Die Politbarometer kennen Sie bestimmt aus dem ZDF. Das sind Telefonumfragen, die seit 1977 etwa monatlich von der Forschungsgruppe Wahlen f√ºr das ZDF durchgef√ºhrt werden. Wir sehen uns die Daten aus dem Jahr 2021 an. Sie sind f√ºr Lehre und Forschung frei. Sie m√ºssen Sie jedoch selbst herunterladen, die Nutzungsbedingungen lesen und ihnen zustimmen. Die Daten gibt es hier: http://dx.doi.org/10.4232/1.13909.\n\nLaden Sie unter ‚ÄúDownloads‚Äù (rechts oben) den Datensatz ‚ÄúZA7856_v1-0-0.dta.zip Stata (Dataset) 1.9 MB‚Äù herunter. Daf√ºr werden Sie sich einmalig (und kostenlos) anmelden m√ºssen.\n\nDas ist ein komprimierter Datensatz des Statistikpakets Stata. Speichern Sie den Datensatz in Ihrem ‚ÄúDaten‚Äù-Ordner und entpacken Sie ihn dort. Es wird ein Ordner namens ZA7856_v1-0-0.dta erstellt, in dem Sie die Datei ‚ÄúZA7856_v1-0-0.dta‚Äù finden. Das ist der eigentliche Datensatz.\n\nDatensatz einlesen mit der Funktion read_dta(). Passen Sie den Pfad zur Datei an, da ich f√ºr die √úbung eine andere Verzeichnisstruktur habe!\n\n\ngesis <- read_dta('Daten/ZA7856_v1-0-0.dta/ZA7856_v1-0-0.dta')\n\n\nWie viele Beobachtungen und Variablen enth√§lt der Datensatz?\nDie Variablennamen sind nichtssagend. Um den Datensatz zu verstehen, laden Sie auf der GESIS-Seite das Codebook herunter (rechts oben bei Downloads). Die Variablennamen sind in der ‚ÄúTabelle 1: Variablenkorrespondenzliste Politbarometer 2021‚Äù gelistet.\nWir werden gemeinsam die Variablen richtig umbenennen und die kategorialen Variablen zu Faktoren √§ndern. Gehen Sie durch den Code Zeile f√ºr Zeile durch und erkl√§ren Sie, was dieser macht.\n\n\ngesis_short <- gesis %>% \n  rename(Befragtennummer = V2,\n         Erhebungsmonat = V4,\n         Erhebungswoche = V5,\n         Bundesland = V6,\n         Erhebungsgebiet = V7,\n         Einwohner = V8,\n         Polit_interesse = V124) %>%\n  mutate(Erhebungsmonat = as_factor(Erhebungsmonat),\n         Erhebungswoche = as_factor(Erhebungswoche),\n         Bundesland = as_factor(Bundesland),\n         Erhebungsgebiet = as_factor(Erhebungsgebiet),\n         Einwohner = as_factor(Einwohner),\n         Polit_interesse = as_factor(Polit_interesse)\n         ) %>% \n  select(Befragtennummer,\n         Erhebungsmonat,\n         Erhebungswoche,\n         Bundesland,\n         Erhebungsgebiet,\n         Einwohner,\n         Polit_interesse)\n\n\nWie hat sich der Typ der kategorialen Variablen im Datensatz gesis_short gegen√ºber dem urspr√ºnglichen Datensatz gesis ver√§ndert?\nSpeichern Sie den neuen Datensatz gesis_short mit write_delim() ab.\n\nLink zu fiete.ai f√ºr Feedback"
  },
  {
    "objectID": "100-aufgabensammlung.html#exploration-von-kategorialen-daten",
    "href": "100-aufgabensammlung.html#exploration-von-kategorialen-daten",
    "title": "Appendix A ‚Äî Aufgabensammlung",
    "section": "A.4 Exploration von kategorialen Daten",
    "text": "A.4 Exploration von kategorialen Daten\n\nA.4.1 Politbarometer 2021: Das Interesse f√ºr Politik\nWir analysieren den Datensatz, den Sie in der vorherigen √úbung geladen und vorbereitet haben.\n\nLaden Sie nun den kurzen Datensatz gesis_short mit der passenden Bibliothek ein. Sie m√ºssen vorher nat√ºrlich diese Bibliothek mit library() laden.\n\n\nUntersuchen Sie den Datensatz nach dem Laden. Wie sind die kategorialen Variablen kodiert (chr odr fct)? Warum? Sehen Sie in der Hilfe von read_delim nach.\nWir m√ºssen nach dem Einlesen die kategorialen Variablen erneut in Faktoren umwandeln. Diese Information geht durch das Speichern mit write_delim() und das erneute Einlesen mit read_delim() verloren. Wandeln Sie die Variable Bundesland in einen Faktor um. Wenn Sie mit der Funktion as_fcator() arbeiten, ist die Reihenfolge der Merkmalsauspr√§gungen (der unterschiedlichen Werte einer kategorialen Variablen) standardm√§√üig so, wie diese im Datensatz erscheinen. Das ist f√ºr die Bundesl√§nder ausreichend.\nWie viele Personen wurden pro Bundesland im Politbarometer im Jahr 2021 befragt?\nWir wollen nun wissen, wie das Politikinteresse in den Bundesl√§ndern ausgepr√§gt ist. Daf√ºr sehen wir uns die Antworten auf die Frage ‚ÄúWie stark interessieren Sie sich f√ºr Politik, ‚Ä¶‚Äù. Die Antworten sind in der Variablen Polit_Interesse enthalten. Wie haben die Befragten abgestimmt?\nDie Reihenfolge der Merkmalsauspr√§gungen ist unlogisch. Das m√ºssen wir √§ndern. Bei dieser Variablen gibt es eine logische Reihenfolge: Sehr stark, stark, etwas, kaum, gar nicht, KA. Letzteres steht f√ºr keine Angabe. Nutzen Sie den folgenden Code, um die Variable Polit_interesse in einen Faktor mit richtiger Reihenfolge der Merkmalsauspr√§gungen umzuwandeln.\n\n\ngesis_short <- gesis_short %>% \n  mutate(gesis_short <- gesis_short %>% \n  mutate(Polit_interesse = factor(Polit_interesse, levels = c('Sehr stark', 'stark', 'etwas', 'kaum', 'gar nicht', 'KA'))))\n\nWiederholen Sie nun die Aufgabe 5.\n\nVergleichen Sie die Antworten zwischen den Bundesl√§ndern. Ist das Interesse der B√ºrger √§hnlich? Warum ist das schwer zu beantworten?\nWir pirschen uns an die relativen H√§ufigkeiten heran. Was macht der nachfolgende Code. Sehen Sie gegebenenfalls in der Hilfe nach.\n\n\ngesis_short %>% \n  count(Bundesland, Polit_interesse) %>% \n  pivot_wider(names_from = Bundesland, values_from = n)\n\nDer n√§chste Schritt ist es, die relativen H√§ufigkeiten (Anteile) f√ºr jedes Bundesland auszurechnen, um die obige Frage zu beantworten. Erkl√§ren Sie, was der nachfolgende Code macht:\n\ngesis_short %>% \n  count(Bundesland, Polit_interesse) %>% \n  group_by(Bundesland) %>%\n  mutate(Anteil = n / sum(n)) %>% \n  select(-n) %>% \n  pivot_wider(names_from = Bundesland, values_from = Anteil)\n\nZur√ºck zu unserer Frage: Ist das Interesse der B√ºrger in allen Bundesl√§ndern √§hnlich?\n\nBeantworten Sie die Frage jetzt auch grafisch, indem Sie ein Balkendiagramm plotten. Es soll so aussehen:\n\n\n\n\n\n\nDaf√ºr k√∂nnen Sie folgende Code-Fragmente erg√§nzen:\n\nggplot(data = ___, mapping = aes(y = ___, fill = ___)) +\n  geom_bar(position = position_fill(reverse = TRUE)) +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +\n  labs(___)\n\nWas macht geom_bar(position = position_fill(reverse = TRUE))?\nLink zu fiete.ai f√ºr Feedback"
  },
  {
    "objectID": "100-aufgabensammlung.html#exploration-von-numerischen-daten",
    "href": "100-aufgabensammlung.html#exploration-von-numerischen-daten",
    "title": "Appendix A ‚Äî Aufgabensammlung",
    "section": "A.5 Exploration von numerischen Daten",
    "text": "A.5 Exploration von numerischen Daten\n\nA.5.1 Umweltdaten entlang der d√§nischen K√ºste\nDie Datei ‚ÄúTemperatur.csv‚Äù aus (Zuur2009a?) enth√§lt Messungen von Temperatur, Salinit√§t und Chlorophyll a an 31 Orten entlang der d√§nischen K√ºste. Der Datensatz kann hier heruntergeladen werden. Sie bekommen ihn aber bereits √ºber ILIAS gestellt. Die Daten stammen vom d√§nischen Institut RIKZ (Monitoringprogramm MWTL: Monitoring Waterstaatkundige Toestand des Lands). Die Messungen wurden zwischen 1990 und 2005 durchgef√ºhrt, mit einer H√§ufigkeit von 0‚Äì4 mal pro Monat je nach Jahreszeit.\n\nLesen Sie den Datensatz ‚ÄúTemperatur.csv‚Äù (auf ILIAS) ein.\nKonvertieren Sie die Spalte Date in ein richtiges Datumsformat und plotten Sie die Temperaturen pro Station (facet_wrap()) als Zeitreihen.\nBerechnen Sie die Anzahl der Messwerte, Monatsmittelwerte der Temperatur f√ºr alle Stationen, sowie die Standardabweichungen. Tipp: innerhalb von summarize() m√ºssen Sie n = n() schreiben, um die Anzahl der Messwerte zu erhalten.\nStellen Sie die Monatsmittel der Temperatur als Linien dar. Tipp: Um die Monate mit ihren Namen darzustellen, nutzen Sie den folgenden Code scale_x_discrete(limits = as_factor(1:12), labels = month.abb). H√§ngen Sie ihn mit einem + an. Was macht dieser Code?\nBeschriften Sie die Grafik sinnvoll.\nF√ºgen Sie die Standardabweichungen als Band hinzu.\n\n\n\nA.5.2 Quantile\nWir besch√§ftigen uns mit dem Datensatz possum im Paket openintro.\n\nLaden Sie die Biblothek und anschlie√üend den Datensatz.\nBerechnen Sie\n\n\nDas 1. Quartil\nDas 3. Quartil\nDen Median\n\nDer K√∂rper- und Kopfl√§ngen.\n\nStellen Sie die K√∂rper- und Kopfl√§ngen als Boxplots nebeneinander dar. Nutzen Sie dazu die Bibliothek patchwork.\nStellen Sie die beiden Variablen als Streudiagramm dar (K√∂rperl√§ngen auf die \\(x\\)-Achse).\nBerechnen Sie den linearen Korrelationskoeffizienten mit der Funktion cor()."
  },
  {
    "objectID": "100-aufgabensammlung.html#umgang-mit-der-normalverteilung",
    "href": "100-aufgabensammlung.html#umgang-mit-der-normalverteilung",
    "title": "Appendix A ‚Äî Aufgabensammlung",
    "section": "A.6 Umgang mit der Normalverteilung",
    "text": "A.6 Umgang mit der Normalverteilung\n\nA.6.1 Simulieren von Daten aus einer Normalverteilung\n\nSimulieren Sie 1000 Werte aus der Standardnormalverteilung. Nutzen Sie dazu die Funktion rnorm() und stellen Sie die Daten als Histogramm dar. Tipp: Wandeln Sie die Daten in ein tibble um.\nDie Funktion dnorm berechnet den Wert der Wahrscheinlichkeitsdichte \\(f(x)\\), also einen Punkt auf der Glockenkurve. Berechnen Sie diesen Wert f√ºr \\(x = 0.3\\) f√ºr die Standardnormalverteilung.\nDie Funktion dnorm kann man dazu nutzen, um die theoretische Normalverteilung √ºber die simulierten Daten aus Aufgabe 1 zu plotten. Nutzen Sie dazu die Funktionen geom_density() und geom_function(). Diese Aufgabe machen wir gemeinsam.\n√úberpr√ºfen Sie, dass der Bereich \\(\\pm\\) 1.96 Standardabweichungen in einer Normalverteilung 95% der Werte enth√§lt. Zeichnen Sie den Bereich richtig ein."
  },
  {
    "objectID": "100-aufgabensammlung.html#mittelwert-der-studiendauer-in-werdeschlau",
    "href": "100-aufgabensammlung.html#mittelwert-der-studiendauer-in-werdeschlau",
    "title": "Appendix A ‚Äî Aufgabensammlung",
    "section": "A.7 Mittelwert der Studiendauer in Werdeschlau",
    "text": "A.7 Mittelwert der Studiendauer in Werdeschlau\nDie Studentenvertretung in Werdeschlau m√∂chte wissen, wie hoch im Schnitt die Studiendauer an der Uni Werdeschlau betr√§gt.\nF√ºhren Sie eine Befragung von 100 zuf√§llig ausgew√§hlten Studierenden durch. Sch√§tzen Sie aus diesen Daten die Studiendauer und geben Sie ein 95%-Konfidenzintervall an. Berechnen Sie dieses Konfidenzintervall\n\nmit Bootstrap\nmithilfe der Normalverteilung. Der Standardfehler des Mittelwerts sei 0.06 Jahre.\n\nVergleichen Sie die beiden Konfidenzintervalle."
  },
  {
    "objectID": "100-aufgabensammlung.html#umgang-mit-der-t-verteilung",
    "href": "100-aufgabensammlung.html#umgang-mit-der-t-verteilung",
    "title": "Appendix A ‚Äî Aufgabensammlung",
    "section": "A.8 Umgang mit der \\(t\\)-Verteilung",
    "text": "A.8 Umgang mit der \\(t\\)-Verteilung\n\nFinden Sie den kritischen Wert \\(t^*_{2}\\) f√ºr das 95%-Konfidenzintervall Nutzen Sie dazu die Funktion qt().\nPlotten Sie die dazugeh√∂rige Verteilung mit normTail() und markieren Sie den Bereich, der 95% aller Werte enth√§lt.\nVergleichen Sie die mit dem kritischen Wert f√ºr eine \\(t\\)-Verteilung mit 18 Freiheitsgraden."
  },
  {
    "objectID": "100-aufgabensammlung.html#mitttelwert-der-laufzeiten-beim-cherrys-blossom-race",
    "href": "100-aufgabensammlung.html#mitttelwert-der-laufzeiten-beim-cherrys-blossom-race",
    "title": "Appendix A ‚Äî Aufgabensammlung",
    "section": "A.9 Mitttelwert der Laufzeiten beim Cherrys Blossom Race",
    "text": "A.9 Mitttelwert der Laufzeiten beim Cherrys Blossom Race\nBeim Cherrys Blossom Race laufen die Teilnehmer ein 10-Meilen Rennen. Wie hoch ist die mittlere Laufzeit (mit 95%-Konfidenzintervall) im Jahr 2017? Der Datensatz run17 enth√§lt die Daten.\n\nFiltern Sie zuerst nach event == '10 Mile', da der Datensatz mehrere Rennen enth√§lt (Hilfe lesen!).\nZiehen Sie eine Zufallsstichprobe von 100 L√§ufern und rechnen Sie die Laufzeit net_sec in Minuten um.\n√úberpr√ºfen Sie die Anforderungen an die Daten. Welches Modell d√ºrfen Sie nutzen?\nBerechnen Sie die Punktsch√§tzung und das Konfidenzintervall."
  },
  {
    "objectID": "100-aufgabensammlung.html#mitttelwert-der-laufzeiten-beim-cherrys-blossom-race-mit-infer",
    "href": "100-aufgabensammlung.html#mitttelwert-der-laufzeiten-beim-cherrys-blossom-race-mit-infer",
    "title": "Appendix A ‚Äî Aufgabensammlung",
    "section": "A.10 Mitttelwert der Laufzeiten beim Cherrys Blossom Race ‚Äì mit infer",
    "text": "A.10 Mitttelwert der Laufzeiten beim Cherrys Blossom Race ‚Äì mit infer\nL√∂sen Sie die obige Aufgabe mit dem Paket infer."
  },
  {
    "objectID": "100-aufgabensammlung.html#t-test-f√ºr-den-mittelwert",
    "href": "100-aufgabensammlung.html#t-test-f√ºr-den-mittelwert",
    "title": "Appendix A ‚Äî Aufgabensammlung",
    "section": "A.11 \\(t\\)-Test f√ºr den Mittelwert",
    "text": "A.11 \\(t\\)-Test f√ºr den Mittelwert\nWird der typische US-L√§ufer mit der Zeit schneller oder langsamer? Wir betrachten diese Frage im Kontext des Cherrys Blossom Race, einem 10-Meilen-Lauf in Washington, DC, der jedes Fr√ºhjahr stattfindet. Die Durchschnittszeit aller L√§ufer, die den Kirschbl√ºtenlauf im Jahr 2016 beendeten, betrug 93.29 Minuten (93 Minuten und etwa 17 Sekunden). Anhand der Daten von 100 Teilnehmern des Kirschbl√ºtenlaufs 2017 m√∂chten wir feststellen, ob die L√§ufer bei diesem Lauf schneller oder langsamer werden, oder ob es keine Ver√§nderungen gibt.\nL√∂sen Sie die Aufgabe mit infer.\n\nA.11.1 Bodenverdichtung\nSchwere landwirtschaftliche Maschinen k√∂nnen beim Bearbeiten des Bodens zu Bodenverdichtung f√ºhren. In einem randomisierten Design wurden zuf√§llig Parzellen auf einem sonst homogenen Feld mit einer schweren Maschine bearbeitet (compacted). Auf allen Parzellen wurde danach die Lagerungsdichte bestimmt. Aus langj√§hrigen Messungen ist ist der Mittelwert des unverdichteten Bodens bekannt und betr√§gt 1.3 [g/cm¬≥]. Die Lagerungsdichte (auch Trockenrohdichte) ist ein Ma√ü f√ºr Bodenstruktur und gibt das Verh√§ltnis der Trockenmasse eines Bodens zu seinem Volumen. Sie wird h√§ufig in [g/cm¬≥] gemessen und kann als ein Indikator f√ºr Bodenverdichtung genutzt werden. Eine Erh√∂hung der Lagerungsdichte ist ein Indikator f√ºr Verdichtung. Der Datensatz ist in der Datei ‚Äúbd_compaction_simple.csv‚Äù gespeichert.\n\n√úberpr√ºfen Sie, ob sich die Lagerungsdichte auf den bearbeiteten Feldern erh√∂ht hat."
  },
  {
    "objectID": "25-lab-01-intro-to-r.html#die-entwicklungsumgebung-rstudio",
    "href": "25-lab-01-intro-to-r.html#die-entwicklungsumgebung-rstudio",
    "title": "7¬† Lab 01: Einf√ºhrung in R und RStudio",
    "section": "7.1 Die Entwicklungsumgebung RStudio",
    "text": "7.1 Die Entwicklungsumgebung RStudio\nZiel dieser √úbung ist es, Sie mit R und RStudio vertraut zu machen, die Sie im Laufe des Kurses sowohl zum Erlernen der im Kurs besprochenen statistischen Konzepte als auch zur Analyse realer Daten und zum Ziehen fundierter Schlussfolgerungen verwenden werden. Der Unterschied zwischen R und RStudio ist folgender: R ist der Name der Programmiersprache selbst und RStudio ist eine praktische Schnittstelle f√ºr die Arbeit mit R. Genauer nennt man die Software RStudio eine integrierte Entwicklungsumgebung (IDE, von englisch integrated development environment).\nIm Laufe der √úbungen werden Sie ermutigt, √ºber das hinauszugehen, was die √úbungen vorgeben; die Bereitschaft zum Experimentieren wird Sie zu einem/einer viel besseren Programmierer*in machen! Bevor wir jedoch so weit sind, m√ºssen Sie einige Grundkenntnisse in der Sprache R erwerben. Zuerst werden wir die grundlegenden Bausteine von R und RStudio erkunden: die Entwicklungsumgebung RStudio, das Laden von Daten und grundlegende Befehle f√ºr die Arbeit mit Daten in R.\nFahren Sie fort und starten Sie RStudio. Sie sollten ein Fenster sehen, das wie in Abbildung¬†7.1 aussieht.\n\n\n\nAbbildung¬†7.1: Die Entwicklungsumgebung RStudio\n\n\nDas Panel unten links ist der Ort, an dem R arbeitet. Dieser Bereich wird Konsole genannt. Jedes Mal, wenn Sie RStudio starten, erscheint oben in der Konsole derselbe Text, der Ihnen die Version von R angibt, die Sie gerade ausf√ºhren. Unterhalb dieser Information befindet sich die Eingabeaufforderung, die durch das Symbol > gekennzeichnet ist. Wie der Name schon sagt, ist dieser Prompt eigentlich eine Aufforderung: eine Aufforderung zu einem Befehl. Urspr√ºnglich ging es bei der Interaktion mit R nur darum, Befehle einzugeben und die Ausgabe zu interpretieren. Diese Befehle und ihre Syntax haben sich im Laufe der Jahrzehnte (im wahrsten Sinne des Wortes) weiterentwickelt und bieten nun eine f√ºr viele Benutzer recht nat√ºrliche M√∂glichkeit, auf Daten zuzugreifen und statistische Berechnungen zu organisieren, zu beschreiben und aufzurufen.\nDas Feld oben rechts enth√§lt Ihre Arbeitsumgebung (Environment) sowie eine Aufzeichnung (History) der Befehle, die Sie zuvor eingegeben haben.\nDas Feld unten rechts enth√§lt Registerkarten zum Durchsuchen der Files (Dateien) in Ihrem Projektordner, zum Zugriff auf Help (Hilfedateien) f√ºr R-Funktionen, zum Installieren und Verwalten von Packages (R-Paketen) und f√ºr Plots (Visualisierungen). Standardm√§√üig werden alle von Ihnen erstellten Datenvisualisierungen direkt unter dem Code angezeigt, mit dem Sie sie erstellt haben. Wenn Sie m√∂chten, dass Ihre Darstellungen auf der Registerkarte Plots erscheinen, m√ºssen Sie Ihre globalen Optionen √§ndern.\n\n7.1.1 R-Pakete\nR ist eine Open-Source-Programmiersprache, was bedeutet, dass Benutzer Pakete beisteuern k√∂nnen, die uns das Leben leichter machen, und wir k√∂nnen sie kostenlos nutzen. F√ºr diese √úbung und viele andere in der Zukunft werden wir die folgenden Pakete verwenden:\n\nDas tidyverse ‚ÄúDach‚Äù-Paket, das eine Reihe von vielen verschiedenen R-Paketen enth√§lt: f√ºr Datenverarbeitung und Datenvisualisierung\nDas openintro R-Paket: f√ºr Daten und benutzerdefinierte Funktionen mit den OpenIntro-Ressourcen\n\nKlicken Sie in der unteren rechten Ecke auf die Registerkarte Packages. Geben Sie den Namen jedes dieser Pakete (tidyverse, openintro) in das Suchfeld ein, um zu sehen, ob sie installiert wurden. Wenn diese Pakete bei der Eingabe ihres Namens nicht angezeigt werden, installieren Sie sie, indem Sie die folgenden zwei Codezeilen kopieren und einf√ºgen oder in die Konsole eingeben. Achten Sie darauf, dass Sie nach jeder Codezeile die Eingabetaste dr√ºcken. Achtung, bitte denken Sie an die Anf√ºhrungszeichen um den Namen des R-Pakets!\n\ninstall.packages(\"tidyverse\")\ninstall.packages(\"openintro\")\n\nNachdem Sie Enter/Return gedr√ºckt haben, beginnt ein Textstrom, der den Prozess beschreibt, den R durchl√§uft, um das Paket von der Quelle zu installieren, die Sie bei der Installation von R ausgew√§hlt haben. Wenn Sie bei der Installation von R nicht aufgefordert wurden, einen Server f√ºr das Herunterladen von Paketen auszuw√§hlen, kann RStudio Sie auffordern, einen Server auszuw√§hlen, von dem das Paket heruntergeladen werden soll; jeder von ihnen wird funktionieren.\nSie m√ºssen Pakete nur einmal installieren, aber Sie m√ºssen sie jedes Mal laden, wenn Sie RStudio neu starten. Wir laden die Pakete mit der Funktion library. Kopieren Sie die folgenden zwei Zeilen und f√ºgen Sie sie in einen neuen Chunk ein. Um die Pakete tidyverse und openintro in Ihre Arbeitsumgebung zu laden, f√ºhren Sie den Code aus.\n\nlibrary(tidyverse)\nlibrary(openintro)\n\nSie k√∂nnen den obigen Code ausf√ºhren, indem Sie:\n\nden Cursor auf die Zeile setzen und Strg-Enter oder Cmd-Enter dr√ºcken\nden Cursor auf die Zeile setzen und die Schaltfl√§che ‚ÄúRun‚Äù in der oberen rechten Ecke der R Markdown-Datei dr√ºcken, oder\nauf den gr√ºnen Pfeil in der oberen rechten Ecke des Codeabschnitts klicken.\n\nWir haben uns f√ºr das tidyverse-Paket entschieden, weil es aus einer Reihe von Paketen besteht, die f√ºr verschiedene Aspekte der Arbeit mit Daten erforderlich sind, vom Laden von Daten √ºber die Verarbeitung von Daten bis hin zur Visualisierung und Analyse von Daten. Au√üerdem haben diese Pakete eine gemeinsame Philosophie und sind so konzipiert, dass sie zusammenarbeiten. Sie k√∂nnen mehr √ºber die Pakete im tidyverse unter tidyverse.org erfahren.\n\n\n7.1.2 Erstellen eines reproduzierbaren Berichts\nWir werden R Markdown verwenden, um reproduzierbare Berichte zu erstellen. Wie und warum Sie das machen sollen, haben Sie bereits in Kapitel Kapitel¬†1 gelernt."
  },
  {
    "objectID": "01-erste-schritte.html#warum-reproduzierbarkeit-in-der-forschung-wichtig-ist",
    "href": "01-erste-schritte.html#warum-reproduzierbarkeit-in-der-forschung-wichtig-ist",
    "title": "1¬† Erste Schritte in R",
    "section": "1.3 Warum Reproduzierbarkeit in der Forschung wichtig ist",
    "text": "1.3 Warum Reproduzierbarkeit in der Forschung wichtig ist\nAls Motivation f√ºr dieses Thema empfehle ich das Video von Prof.¬†Roger Peng der John Hopkins Bloogmerg School of Public Health."
  },
  {
    "objectID": "01-erste-schritte.html#literate-programming-idee-von-donald-knuth",
    "href": "01-erste-schritte.html#literate-programming-idee-von-donald-knuth",
    "title": "1¬† Erste Schritte in R",
    "section": "1.4 Literate Programming Idee von Donald Knuth",
    "text": "1.4 Literate Programming Idee von Donald Knuth\nDie Idee, dass man den Code und die dazugeh√∂rige Interpretation (Text, Bericht etc.) nicht voneinander trennen sollte, geht auf Knuth (1984) zur√ºck. Mit Literate Programming meinte Knuth, dass Programme auch nichts anderes wie literarische Werke sind. Er setzte den Fokus darauf, mit Programmen menschlichen Benutzern zu erkl√§ren, was man den Computer machen lassen m√∂chte. Also weg vom computer- hin zum mensch-zentrierten Zugang. So wird Programmieren und in unserem Fall die Datenanalyse verst√§ndlich und vor allem reproduzierbar.\nLeider ist es in unserer modernen Forschungslandschaft immer noch nicht Standard. Das Trennen von Analyseergebnissen und Berichten (Forschungsartikeln) sorgt f√ºr viele (unentdeckte und unn√∂tige) Fehler und Frust."
  },
  {
    "objectID": "01-erste-schritte.html#reproduzierbare-berichte-mit-r-markdown",
    "href": "01-erste-schritte.html#reproduzierbare-berichte-mit-r-markdown",
    "title": "1¬† Erste Schritte in R",
    "section": "1.5 Reproduzierbare Berichte mit R Markdown",
    "text": "1.5 Reproduzierbare Berichte mit R Markdown\nR hat sein eigenes System von reproduzierbaren Berichten, genannt R Markdown (Xie, Allaire, and Grolemund 2021). Es ist benutzerfreundlich und erm√∂glicht unterschiedliche Formate von Berichten, wie HTML-Dokumente, PDF-Dateien, Pr√§sentationsfolien usw.\nEs wird Sie vielleicht √ºberraschen, aber das Skript, das Sie gerade lesen, ist nichts anderes als ein ‚Äúliterarisch‚Äù programmiertes Buch in R Bookdown (Xie, Allaire, and Grolemund 2021), einem R-Paket speziell f√ºr lange R Markdown-Dokumente.\nWir werden vor allem mit R Notebooks arbeiten, die eine gute Interaktion zwischen dem geschriebenen Text und dem R-Code erm√∂glichen. Das Notebook kann sowohl in ein HTML-Dokument als auch in PDF oder Word als endg√ºltiges Dokument umgewandelt werden. Diesen Prozess nennt man knit."
  },
  {
    "objectID": "01-erste-schritte.html#ein-neues-r-notebook-erstellen",
    "href": "01-erste-schritte.html#ein-neues-r-notebook-erstellen",
    "title": "1¬† Erste Schritte in R",
    "section": "1.6 Ein neues R Notebook erstellen",
    "text": "1.6 Ein neues R Notebook erstellen\nUm ein neues R Notebook zu erstellen, klicken Sie das kleine gr√ºne Plus oben links und w√§hlen Sie R Notebook aus. Sie k√∂nnen es erst einmal bei untitled belassen (Abbildung¬†2.1).\n\n\n\nAbbildung¬†1.2: Neues R Notebook anlegen\n\n\nWenn Sie ein neues Notebook erstellen, enth√§lt das Template etwas Code. Lesen Sie sich das ruhig noch einmal durch, da es ein paar hilfreiche Tastenk√ºrzel und Tipps. Danach k√∂nnen Sie den Text unterhalb des Headers l√∂schen."
  },
  {
    "objectID": "01-erste-schritte.html#sec-header",
    "href": "01-erste-schritte.html#sec-header",
    "title": "1¬† Erste Schritte in R",
    "section": "1.4 Der Header eines Notebooks",
    "text": "1.4 Der Header eines Notebooks\nEin R Notebook (und jedes andere R Markdown Dokument) besteht aus einem Header (Kopf) und dem eigentlichen Text und Code. Der Header hat dabei ein bestimmtes Layout, auf das Sie unbedingt achten m√ºssen (Rechtschreibung!). Der Header ist immer zwischen drei Minuszeichen --- eingeschlossen. Bei komplizierteren Headern gibt es auch Einr√ºckungen (mit der Tab-Taste), die auch Bedeutung haben (s. weiterf√ºhrende Literatur). Wir bleiben bei einem einfachen Header ohne Einr√ºckungen (Abbildung¬†1.3).\nUm einen neuen R-Chunk hinzuzuf√ºgen, klicken Sie auf das kleine gr√ºne C+ oben rechts oder verwenden Sie das Tastenk√ºrzel Str+Alt+i.\n\n\n\nAbbildung¬†1.3: Einen neuen R Chunk hinzuf√ºgen\n\n\nText kann einfach unterhalb des Headers und au√üerhalb der Chunks getippt werden. Die wichtigsten Layoutelemente f√ºr den Text finden Sie hier. R Markdown unterst√ºtzt mathematische Notation in Latex-Stil. Eine Einf√ºhrung in Latex w√ºrde an dieser Stelle aber zu weit f√ºhren.\nDas R Notebook hat den Vorteil, dass man √ºber den Button Preview oben in der Leiste sofort die Ergebnisse anzeigen lassen kann. Sie m√ºssen also nicht knitten. Falls Sie es doch m√∂chten, klicken Sie auf das kleine Dreieck neben dem Preview und suchen Sie sich ein Output-Format aus. Ein einmal ‚Äúgeknittetes‚Äù Notebook ist kein Notebook mehr (kein Preview). Damit es wieder zum Nobebook wird, m√ºssen Sie im Header output: html_notebbok einstellen (Abbildung¬†1.3).\n\n1.4.1 Wichtigste Regeln f√ºr Reproduzierbarkeit\nEin weiteres Video von Prof.¬†Peng widmet sich den wichtigsten Regeln f√ºr Reproduzierbarkeit."
  },
  {
    "objectID": "01-erste-schritte.html#wichtigste-regeln-f√ºr-reproduzierbarkeit",
    "href": "01-erste-schritte.html#wichtigste-regeln-f√ºr-reproduzierbarkeit",
    "title": "1¬† Erste Schritte in R",
    "section": "1.8 Wichtigste Regeln f√ºr Reproduzierbarkeit",
    "text": "1.8 Wichtigste Regeln f√ºr Reproduzierbarkeit\nEin weiteres Video von Prof.¬†Peng widmet sich den wichtigsten Regeln f√ºr Reproduzierbarkeit.\n\nBitte speichern Sie Ihr Skript regelm√§√üig ab!\n\n\nBeachten Sie die Deadline f√ºr das Hochladen der Hausaufgaben!"
  },
  {
    "objectID": "01-erste-schritte.html#reproduzierbare-berichte-in-r",
    "href": "01-erste-schritte.html#reproduzierbare-berichte-in-r",
    "title": "1¬† Erste Schritte in R",
    "section": "1.3 Reproduzierbare Berichte in R",
    "text": "1.3 Reproduzierbare Berichte in R\n\n1.3.1 Warum Reproduzierbarkeit in der Forschung wichtig ist\nAls Motivation f√ºr dieses Thema empfehle ich das Video von Prof.¬†Roger Peng der John Hopkins Bloogmerg School of Public Health.\n\n\n1.3.2 Literate Programming Idee von Donald Knuth\nDie Idee, dass man den Code und die dazugeh√∂rige Interpretation (Text, Bericht etc.) nicht voneinander trennen sollte, geht auf Knuth (1984) zur√ºck. Mit Literate Programming meinte Knuth, dass Programme auch nichts anderes wie literarische Werke sind. Er setzte den Fokus darauf, mit Programmen menschlichen Benutzern zu erkl√§ren, was man den Computer machen lassen m√∂chte. Also weg vom computer- hin zum mensch-zentrierten Zugang. So wird Programmieren und in unserem Fall die Datenanalyse verst√§ndlich und vor allem reproduzierbar.\nLeider ist es in unserer modernen Forschungslandschaft immer noch nicht Standard. Das Trennen von Analyseergebnissen und Berichten (Forschungsartikeln) sorgt f√ºr viele (unentdeckte und unn√∂tige) Fehler und Frust.\n\n\n1.3.3 Reproduzierbare Berichte mit R Markdown\nR hat sein eigenes System von reproduzierbaren Berichten, genannt R Markdown (Xie, Allaire, and Grolemund 2021). Es ist benutzerfreundlich und erm√∂glicht unterschiedliche Formate von Berichten, wie HTML-Dokumente, PDF-Dateien, Pr√§sentationsfolien usw.\nEs wird Sie vielleicht √ºberraschen, aber das Skript, das Sie gerade lesen, ist nichts anderes als ein ‚Äúliterarisch‚Äù programmiertes Buch in R Bookdown (Xie, Allaire, and Grolemund 2021), einem R-Paket speziell f√ºr lange R Markdown-Dokumente.\nWir werden vor allem mit R Notebooks arbeiten, die eine gute Interaktion zwischen dem geschriebenen Text und dem R-Code erm√∂glichen. Das Notebook kann sowohl in ein HTML-Dokument als auch in PDF oder Word als endg√ºltiges Dokument umgewandelt werden. Diesen Prozess nennt man knit.\n\n\n1.3.4 Ein neues R Notebook erstellen\nUm ein neues R Notebook zu erstellen, klicken Sie das kleine gr√ºne Plus oben links und w√§hlen Sie R Notebook aus. Sie k√∂nnen es erst einmal bei untitled belassen (Abbildung¬†1.2).\n\n\n\nAbbildung¬†1.2: Neues R Notebook anlegen\n\n\nWenn Sie ein neues Notebook erstellen, enth√§lt das Template etwas Code. Lesen Sie sich das ruhig noch einmal durch, da es ein paar hilfreiche Tastenk√ºrzel und Tipps. Danach k√∂nnen Sie den Text unterhalb des Headers l√∂schen."
  },
  {
    "objectID": "01-erste-schritte.html#aufgaben",
    "href": "01-erste-schritte.html#aufgaben",
    "title": "1¬† Erste Schritte in R",
    "section": "1.5 Aufgaben",
    "text": "1.5 Aufgaben\nWenn Sie bereits Erfahrung mit R haben, dann bearbeiten Sie direkt das Lab 01: Einf√ºhrung in R in Kapitel¬†7. Falls R f√ºr Sie komplett neu ist, arbeiten Sie zuerst die Kapitel Kapitel¬†2 und Kapitel¬†3 durch und bearbeiten Sie dann das Lab 01: Einf√ºhrung in R in Kapitel¬†7.\n\nBitte speichern Sie Ihre Arbeit regelm√§√üig ab!"
  },
  {
    "objectID": "01-erste-schritte.html#weiterf√ºhrende-literatur",
    "href": "01-erste-schritte.html#weiterf√ºhrende-literatur",
    "title": "1¬† Erste Schritte in R",
    "section": "1.7 Weiterf√ºhrende Literatur",
    "text": "1.7 Weiterf√ºhrende Literatur\n\nr4ds, Kapitel 27 R for Data Science, 1. Auflage.\nWenn Sie RMarkdaown bereits kennen und gerne weiter lernen m√∂chte, empfehle ich Quatro. Ein Einstieg empfehlen sich die Kapitel 29 und 30 in r4ds (Wickham, √áetinkaya-Rundel, and Grolemund 2023), 2. Auflage.\n\n\n\n\n\nIhaka, Ross, and Robert Gentleman. 1996. ‚ÄúR: A Language for Data Analysis and Graphics.‚Äù Journal of Computational and Graphical Statistics 5 (3): 299‚Äì314. https://doi.org/10.1080/10618600.1996.10474713.\n\n\nKnuth, D. E. 1984. ‚ÄúLiterate Programming.‚Äù The Computer Journal 27 (2): 97‚Äì111. https://doi.org/10.1093/comjnl/27.2.97.\n\n\nWickham, Hadley, Mine √áetinkaya-Rundel, and Garrett Grolemund. 2023. R for Data Science (2e). https://r4ds.hadley.nz/.\n\n\nXie, Yihui, J. J. Allaire, and Garrett Grolemund. 2021. R Markdown: The Definitive Guide. https://bookdown.org/yihui/rmarkdown/."
  },
  {
    "objectID": "03-ggplot.html#weitere-darstellungsm√∂glichkeiten-mit-geom_xxx",
    "href": "03-ggplot.html#weitere-darstellungsm√∂glichkeiten-mit-geom_xxx",
    "title": "2¬† Einf√ºhrung in die Darstellung von Daten",
    "section": "2.3 Weitere Darstellungsm√∂glichkeiten mit geom_XXX",
    "text": "2.3 Weitere Darstellungsm√∂glichkeiten mit geom_XXX\nDas geom_point() produziert ein Streudiagramm auch XY-Diagramm (scatter plot). Weiter wichtige Grafiktypen sind\n\ngeom_line(): Linien\ngeom_bar(): Balken"
  },
  {
    "objectID": "25-lab-01-intro-to-r.html#dr.-arbuthnots-baptism-records",
    "href": "25-lab-01-intro-to-r.html#dr.-arbuthnots-baptism-records",
    "title": "4¬† Lab 01: Einf√ºhrung in R und RStudio",
    "section": "4.2 Dr.¬†Arbuthnot‚Äôs Baptism Records",
    "text": "4.2 Dr.¬†Arbuthnot‚Äôs Baptism Records\nWerfen wir zun√§chst einen Blick auf die Daten.\n\narbuthnot\n\n\n\n  \n\n\n\nAuch hier k√∂nnen Sie den obigen Code ausf√ºhren, indem Sie:\n\nden Cursor auf die Zeile setzen und Strg-Enter oder Cmd-Enter dr√ºcken\nden Cursor auf die Zeile setzen und die Schaltfl√§che ‚ÄúAusf√ºhren‚Äù in der oberen rechten Ecke der R Markdown-Datei dr√ºcken, oder\ndurch Klicken auf den gr√ºnen Pfeil in der oberen rechten Ecke des Codeabschnitts\n\nDie einzige Codezeile in diesem Codechunk weist R an, einige Daten zu laden: die Arbuthnot-Taufzahlen f√ºr Jungen und M√§dchen. Sie sollten sehen, dass die Registerkarte Umgebung in der oberen rechten Ecke des RStudio-Fensters nun einen Datensatz namens ‚ÄúArbuthnot‚Äù mit 82 Beobachtungen f√ºr 3 Variablen auflistet. Wenn Sie mit R arbeiten, werden Sie Objekte f√ºr eine Vielzahl von Zwecken erstellen. Manchmal laden Sie die Objekte in Ihren Arbeitsbereich, indem Sie ein Paket laden, wie wir es hier getan haben, aber manchmal erstellen Sie selbst Objekte als Nebenprodukt eines Berechnungsprozesses, f√ºr eine Analyse, die Sie durchgef√ºhrt haben, oder f√ºr eine Visualisierung, die Sie erstellt haben.\nDer Arbuthnot-Datensatz geht auf die Arbeit von Dr.¬†John Arbuthnot zur√ºck, einem Arzt, Schriftsteller und Mathematiker aus dem 18. Jahrhundert. Er interessierte sich f√ºr das Verh√§ltnis zwischen neugeborenen Jungen und neugeborenen M√§dchen und sammelte daher die Taufeintr√§ge f√ºr in London geborene Kinder f√ºr jedes Jahr zwischen 1629 und 1710. Auch hier k√∂nnen wir die Daten anzeigen, indem wir den unten stehenden Code ausf√ºhren oder den Namen des Datensatzes in die Konsole eingeben. Achten Sie auf die Schreibweise und Gro√üschreibung! R‚Äù unterscheidet Gro√ü- und Kleinschreibung. Wenn Sie also versehentlich ‚ÄúArbuthnot‚Äù eingeben, meldet R‚Äù, dass das Objekt nicht gefunden werden kann.\n\narbuthnot\n\n\n\n  \n\n\n\nDieser Befehl zeigt die Daten f√ºr uns an, allerdings ist das Drucken des gesamten Datensatzes in der Konsole nicht sehr n√ºtzlich. Ein Vorteil von RStudio ist, dass es √ºber einen eingebauten Datenbetrachter verf√ºgt. Auf der Registerkarte Umgebung (im oberen rechten Bereich) werden die Objekte in Ihrer Umgebung aufgelistet. Wenn Sie auf den Namen arbuthnot klicken, √∂ffnet sich ein Data Viewer Reiter neben Ihrer R Markdown Datei, der eine alternative Anzeige des Datensatzes bietet. Diese Anzeige sollte sich √§hnlich anf√ºhlen wie die Anzeige von Daten in Excel, wo Sie durch den Datensatz bl√§ttern k√∂nnen, um ihn zu pr√ºfen. Im Gegensatz zu Excel k√∂nnen Sie die Daten auf dieser Registerkarte jedoch nicht bearbeiten. Wenn Sie mit der Ansicht der Daten fertig sind, k√∂nnen Sie diese Registerkarte schlie√üen, indem Sie auf das ‚Äúx‚Äù in der oberen linken Ecke klicken.\nWenn Sie sich die Daten ansehen, sollten Sie vier Zahlenspalten und 82 Zeilen sehen. Jede Zeile steht f√ºr ein anderes Jahr, in dem Arbuthnot Daten gesammelt hat. Der erste Eintrag in jeder Zeile ist die Zeilennummer (ein Index, mit dem wir bei Bedarf auf die Daten einzelner Jahre zugreifen k√∂nnen), der zweite ist das Jahr, und der dritte und vierte sind die Anzahl der in diesem Jahr getauften Jungen bzw. M√§dchen. Verwenden Sie die Bildlaufleiste auf der rechten Seite des Konsolenfensters, um den gesamten Datensatz zu betrachten."
  },
  {
    "objectID": "25-lab-01-intro-to-r.html#taufaufzeichnungen-von-dr.-arbuthnot",
    "href": "25-lab-01-intro-to-r.html#taufaufzeichnungen-von-dr.-arbuthnot",
    "title": "7¬† Lab 01: Einf√ºhrung in R und RStudio",
    "section": "7.2 Taufaufzeichnungen von Dr.¬†Arbuthnot",
    "text": "7.2 Taufaufzeichnungen von Dr.¬†Arbuthnot\nWir laden den Datensatz arbuthnot aus dem Paket openintro.\n\ndata(arbuthnot)\n\nDie einzige Codezeile in diesem Code-Chunk weist R an, einige Daten zu laden: die Arbuthnot-Taufzahlen f√ºr Jungen und M√§dchen. Sie sollten sehen, dass die Registerkarte Environment in der oberen rechten Ecke des RStudio-Fensters nun einen Datensatz namens ‚ÄúArbuthnot‚Äù mit 82 Beobachtungen f√ºr 3 Variablen auflistet. Wenn Sie mit R arbeiten, werden Sie Objekte f√ºr eine Vielzahl von Zwecken erstellen. Manchmal laden Sie die Objekte in Ihren Arbeitsbereich, indem Sie ein Paket laden, wie wir es hier getan haben, aber manchmal erstellen Sie selbst Objekte als Nebenprodukt eines Berechnungsprozesses, f√ºr eine Analyse, die Sie durchgef√ºhrt haben, oder f√ºr eine Visualisierung, die Sie erstellt haben. Wie Sie Daten aus einer Textdatei einlesen, erfahren Sie in Kapitel Kapitel¬†3.\nDer Arbuthnot-Datensatz geht auf die Arbeit von Dr.¬†John Arbuthnot zur√ºck, einem Arzt, Schriftsteller und Mathematiker aus dem 18. Jahrhundert. Er interessierte sich f√ºr das Verh√§ltnis zwischen neugeborenen Jungen und neugeborenen M√§dchen und sammelte daher die Taufeintr√§ge f√ºr in London geborene Kinder f√ºr jedes Jahr zwischen 1629 und 1710. Auch hier k√∂nnen wir die Daten anzeigen, indem wir den unten stehenden Code ausf√ºhren oder den Namen des Datensatzes in die Konsole eingeben. Achten Sie auf die Schreibweise und Gro√üschreibung! R unterscheidet Gro√ü- und Kleinschreibung. Wenn Sie also versehentlich ‚ÄúArbuthnot‚Äù eingeben, meldet R, dass das Objekt nicht gefunden werden kann.\n\narbuthnot\n\n\n\n  \n\n\n\nDer Befehl arbuthnot (also der Name des Datensatzes) zeigt die Daten f√ºr uns an. Sie k√∂nnen im R Markdown durch den Datensatz bl√§ttern, wenn sie unter dem Datensatz auf ‚ÄúNext‚Äù klicken. Alternativ k√∂nnen Sie den Datensatz im Datenbetrachter (im Lesemodus) ansehen. Auf der Registerkarte Environment (im oberen rechten Bereich) werden die Objekte in Ihrer Umgebung aufgelistet. Wenn Sie auf den Namen arbuthnot klicken, √∂ffnet sich ein Data Viewer Reiter neben Ihrer R Markdown-Datei, der eine alternative Anzeige des Datensatzes bietet. Diese Anzeige sollte sich √§hnlich anf√ºhlen wie die Anzeige von Daten in Excel, wo Sie durch den Datensatz bl√§ttern k√∂nnen, um ihn zu pr√ºfen. Im Gegensatz zu Excel k√∂nnen Sie die Daten auf dieser Registerkarte jedoch nicht bearbeiten. Wenn Sie mit der Ansicht der Daten fertig sind, k√∂nnen Sie diese Registerkarte schlie√üen, indem Sie auf das ‚Äúx‚Äù in der oberen linken Ecke klicken.\nWenn Sie sich die Daten ansehen, sollten Sie vier Zahlenspalten und 82 Zeilen sehen. Jede Zeile steht f√ºr ein anderes Jahr, in dem Arbuthnot Daten gesammelt hat. Der erste Eintrag in jeder Zeile ist die Zeilennummer (ein Index, mit dem wir bei Bedarf auf die Daten einzelner Jahre zugreifen k√∂nnen), der zweite ist das Jahr, und der dritte und vierte sind die Anzahl der in diesem Jahr getauften Jungen bzw. M√§dchen.\nBeachten Sie, dass die Zeilennummern in der ersten Spalte nicht zu den Daten von Arbuthnot geh√∂ren. R f√ºgt diese Zeilennummern als Teil des Ausdrucks hinzu, damit Sie visuelle Vergleiche anstellen k√∂nnen. Man kann sie sich als den Index vorstellen, den man auf der linken Seite eines Tabellenblatts sieht. In der Tat ist der Vergleich der Daten mit einer Tabellenkalkulation im Allgemeinen hilfreich. R hat die Daten von Arbuthnot in einem Objekt gespeichert, das einer Tabellenkalkulation oder einer Tabelle √§hnelt und das R einen Dataframe nennt.\nSie k√∂nnen die Dimensionen dieses Dataframes sowie die Namen der Variablen und die ersten paar Beobachtungen sehen, indem Sie den Namen des Datensatzes aufrufen oder alternativ in die Funktion glimpse() einf√ºgen, wie unten gezeigt:\n\nglimpse(arbuthnot)\n\nRows: 82\nColumns: 3\n$ year  <int> 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1639‚Ä¶\n$ boys  <int> 5218, 4858, 4422, 4994, 5158, 5035, 5106, 4917, 4703, 5359, 5366‚Ä¶\n$ girls <int> 4683, 4457, 4102, 4590, 4839, 4820, 4928, 4605, 4457, 4952, 4784‚Ä¶\n\n\nWir k√∂nnen sehen, dass es 82 Beobachtungen und 3 Variablen in diesem Datensatz gibt. Die Namen der Variablen sind year, boys und girls. An dieser Stelle werden Sie vielleicht bemerken, dass viele der Befehle in R sehr wie Funktionen aus dem Mathematikunterricht aussehen; das hei√üt, der Aufruf von R-Befehlen bedeutet, dass man einer Funktion eine Anzahl von Eingaben (die sogenannten Argumente) gibt, die die Funktion verwendet, um eine Ausgabe zu erzeugen. Der Befehl glimpse() zum Beispiel nimmt ein einziges Argument, den Namen eines Dataframes, und erzeugt eine Anzeige des Datensatzes als Ausgabe."
  },
  {
    "objectID": "25-lab-01-intro-to-r.html#explorative-analyse",
    "href": "25-lab-01-intro-to-r.html#explorative-analyse",
    "title": "7¬† Lab 01: Einf√ºhrung in R und RStudio",
    "section": "7.3 Explorative Analyse",
    "text": "7.3 Explorative Analyse\nBeginnen wir damit, die Daten ein wenig genauer zu untersuchen. Wir k√∂nnen auf die Daten in einer einzelnen Spalte eines Dataframes zugreifen, indem wir die Spalte mit einem ‚Äú$‚Äù extrahieren. Der folgende Code extrahiert die Spalte boys aus dem Dataframe ‚ÄúArbuthnot‚Äù.\n\narbuthnot$boys\n\n [1] 5218 4858 4422 4994 5158 5035 5106 4917 4703 5359 5366 5518 5470 5460 4793\n[16] 4107 4047 3768 3796 3363 3079 2890 3231 3220 3196 3441 3655 3668 3396 3157\n[31] 3209 3724 4748 5216 5411 6041 5114 4678 5616 6073 6506 6278 6449 6443 6073\n[46] 6113 6058 6552 6423 6568 6247 6548 6822 6909 7577 7575 7484 7575 7737 7487\n[61] 7604 7909 7662 7602 7676 6985 7263 7632 8062 8426 7911 7578 8102 8031 7765\n[76] 6113 8366 7952 8379 8239 7840 7640\n\n\nDieser Befehl zeigt nur die Anzahl der Jungen an, die jedes Jahr getauft werden. R interpretiert das ‚Äú$‚Äù so, dass es sagt: ‚ÄúGehe zu dem Dataframe, der vor mir kommt, und finde die Variable, die nach mir kommt.‚Äù\n\n\nWelchen Befehl w√ºrden Sie verwenden, um nur die Anzahl der getauften M√§dchen zu extrahieren? Probieren Sie es in der Konsole aus!\n\n\nBeachten Sie, dass die Art und Weise, wie R diese Daten ausgibt, unterschiedlich ist. Als wir uns den kompletten Dataframes angesehen haben, sahen wir 82 Zeilen, eine in jeder Zeile der Anzeige. Diese Daten wurden aus dem Dataframe extrahiert, sodass sie nicht mehr in einer Tabelle mit anderen Variablen strukturiert sind. Stattdessen werden diese Daten direkt nacheinander angezeigt. Objekte, die auf diese Weise ausgedruckt werden, nennt man Vektoren; √§hnlich wie die Vektoren, die Sie aus dem Mathematikunterricht kennen, stellen Vektoren eine Liste von Zahlen dar. R hat Zahlen in [Klammern] auf der linken Seite des Ausdrucks hinzugef√ºgt, um die Position jedes Eintrags innerhalb des Vektors anzugeben. Zum Beispiel folgt 5218 auf [1], was bedeutet, dass 5218 der erste Eintrag im Vektor ist. Wenn ‚Äú43‚Äù am Anfang einer Zeile angezeigt wird, bedeutet dies, dass die erste Zahl in dieser Zeile dem 43. Eintrag in diesem Vektor entspricht.\n\n7.3.1 Datenvisualisierung\nR verf√ºgt √ºber einige leistungsstarke Funktionen zur Erstellung von Grafiken. Mit dem folgenden Code k√∂nnen wir eine einfache Darstellung der Anzahl der getauften M√§dchen pro Jahr erstellen:\n\nggplot(data = arbuthnot, aes(x = year, y = girls)) + \n  geom_point()\n\n\n\n\nIn diesem Code verwenden wir die Funktion ggplot(), um ein Diagramm zu erstellen. Wenn Sie diesen Codeabschnitt ausf√ºhren, wird ein Diagramm unterhalb des Codeabschnitts angezeigt. Das R Markdown-Dokument zeigt die Darstellung unterhalb des Codes an, mit dem sie erzeugt wurde.\nDer obige Befehl sieht ebenfalls wie eine mathematische Funktion aus. Diesmal ben√∂tigt die Funktion jedoch mehrere Eingaben (Argumente), die durch Kommata getrennt sind.\nMit ggplot():\n\nDas erste Argument ist immer der Name des Datensatzes, den Sie zum Plotten verwenden m√∂chten.\nAls N√§chstes geben Sie die Variablen aus dem Datensatz an, die den verschiedenen √§sthetischen Elementen der Darstellung, wie der \\(x\\)- und der \\(y\\)-Achse, zugeordnet werden sollen.\n\nDiese Befehle erstellen ein leeres Diagramm mit den Variablen, die Sie den \\(x\\)- und \\(y\\)-Achsen zugewiesen haben. Als N√§chstes m√ºssen Sie ggplot() mitteilen, welche Art von Visualisierung Sie der leeren Vorlage hinzuf√ºgen m√∂chten. Sie f√ºgen eine weitere Ebene zu ggplot() hinzu, indem Sie:\n\nein ‚Äú+‚Äù am Ende der Zeile hinzuf√ºgen, um anzuzeigen, dass Sie eine Ebene hinzuf√ºgen\ndann das geometrische Objekt angeben, das zur Erstellung des Plots verwendet werden soll.\n\nDa wir ein Streudiagramm erstellen wollen, verwenden wir geom_point(). Damit wird ggplot() mitgeteilt, dass jeder Datenpunkt durch einen Punkt im Diagramm dargestellt werden soll. Wenn Sie das obige Diagramm mit einem Liniendiagramm anstelle eines Streudiagramms darstellen wollten, w√ºrden Sie geom_point() durch geom_line() ersetzen. Dies weist ggplot() an, eine Linie von jeder Beobachtung zur n√§chsten Beobachtung zu zeichnen (sequenziell).\n\nggplot(data = arbuthnot, aes(x = year, y = girls)) +\n  geom_line()\n\n\n\n\nVerwenden Sie das Diagramm, um die folgende Frage zu beantworten:\n\n\nGibt es einen offensichtlichen Trend in der Zahl der getauften M√§dchen im Laufe der Jahre? Wie w√ºrden Sie ihn beschreiben? Um sicherzustellen, dass Ihr Bericht umfassend ist, sollten Sie den Code, der zur Erstellung der Grafik erforderlich ist, sowie Ihre schriftliche Interpretation beif√ºgen.\n\n\nSie fragen sich vielleicht, woher Sie die Syntax f√ºr die Funktion ggplot() kennen sollen. Zum Gl√ºck dokumentiert R alle seine Funktionen ausf√ºhrlich. Um zu erfahren, was eine Funktion tut und wie man sie benutzt (z. B. die Argumente der Funktion), geben Sie einfach ein Fragezeichen gefolgt von dem Namen der Funktion, die Sie interessiert, in die Konsole ein. Geben Sie Folgendes in Ihre Konsole ein:\n\n?ggplot\n\nBeachten Sie, dass die Hilfedatei in den Vordergrund r√ºckt und die Darstellung im unteren rechten Bereich ersetzt. Sie k√∂nnen zwischen den Registerkarten hin- und herschalten, indem Sie auf ihre Namen klicken.\n\n\n7.3.2 R als gro√üer Taschenrechner\nNehmen wir nun an, wir m√∂chten die Gesamtzahl der Taufen darstellen. Um dies zu berechnen, k√∂nnten wir R als einen gro√üen Taschenrechner verwenden. Dazu k√∂nnen wir mathematische Ausdr√ºcke wie die folgende Berechnung in die Konsole eintippen.\n\n5218 + 4683\n\n[1] 9901\n\n\nDiese Berechnung w√ºrde uns die Gesamtzahl der Taufen im Jahr 1629 liefern. Wir k√∂nnten diese Berechnung dann f√ºr jedes Jahr einmal wiederholen. Das w√ºrde wahrscheinlich eine Weile dauern, aber zum Gl√ºck gibt es einen schnelleren Weg! Wenn wir den Vektor der Taufen f√ºr Jungen zu dem der M√§dchen addieren, kann R jede dieser Summen gleichzeitig berechnen.\n\narbuthnot$boys + arbuthnot$girls\n\n [1]  9901  9315  8524  9584  9997  9855 10034  9522  9160 10311 10150 10850\n[13] 10670 10370  9410  8104  7966  7163  7332  6544  5825  5612  6071  6128\n[25]  6155  6620  7004  7050  6685  6170  5990  6971  8855 10019 10292 11722\n[37]  9972  8997 10938 11633 12335 11997 12510 12563 11895 11851 11775 12399\n[49] 12626 12601 12288 12847 13355 13653 14735 14702 14730 14694 14951 14588\n[61] 14771 15211 15054 14918 15159 13632 13976 14861 15829 16052 15363 14639\n[73] 15616 15687 15448 11851 16145 15369 16066 15862 15220 14928\n\n\nWas Sie sehen, ist eine Liste von 82 Zahlen. Diese Zahlen erscheinen als Liste, weil wir mit Vektoren und nicht mit einem Dataframe arbeiten. Jede Zahl steht f√ºr die Summe der Anzahl der Jungen und M√§dchen, die in diesem Jahr getauft wurden. Sie k√∂nnen einen Blick auf die ersten Zeilen der Spalten boys und girls werfen, um zu sehen, ob die Berechnung richtig ist.\n\n\n7.3.3 Hinzuf√ºgen einer neuen Variable zum Dataframe\nWir m√∂chten diesen neuen Vektor der Gesamtzahl der Taufen verwenden, um einige Diagramme zu erstellen, daher m√∂chten wir ihn als permanente Spalte in unserem Dataframe speichern. Dies k√∂nnen wir mit dem folgenden Code tun:\n\narbuthnot <- arbuthnot %>%\n  mutate(total = boys + girls)\n\nDieser Code besteht aus vielen neuen Teilen, die wir nun aufschl√ºsseln wollen. In der ersten Zeile tun wir zwei Dinge: (1) wir f√ºgen eine neue Spalte total zu diesem aktualisierten Dataframe hinzu, und (2) wir √ºberschreiben das vorhandenen Dataframe mit einem aktualisierten Dataframe, das die neue Spalte total enth√§lt. Wir k√∂nnen diese beiden Schritte mit dem Operator piping (%>%) miteinander verkn√ºpfen. Der Pipe-Operator nimmt die Ausgabe des vorherigen Ausdrucks und leitet sie in das erste Argument des n√§chsten Ausdrucks ein.\nUm unsere Analogie mit mathematischen Funktionen fortzusetzen, ist x %>% f(y) gleichbedeutend mit f(x, y). Die Verbindung von arbuthnot und mutate(total = boys + girls) mit dem Pipe-Operator ist dasselbe wie die Eingabe von mutate(arbuthnot, total = boys + girls), wobei arbuthnot das erste Argument der Funktion mutate() wird.\n\nEine Anmerkung zum Piping: Beachten Sie, dass wir diese beiden Codezeilen wie folgt lesen k√∂nnen:\n‚ÄúNehmen Sie den Datensatz‚Äùarbuthnot‚Äù und pipen Sie ihn in die Funktion ‚Äúmutate‚Äù. Ver√§ndern Sie (mutate) den arbuthnot-Datensatz, indem Sie eine neue Variable namens total erstellen, die die Summe der Variablen namens boys und girls ist. Weisen Sie dann den resultierenden Datensatz dem Objekt mit dem Namen arbuthnot zu, d.¬†h. √ºberschreiben Sie den alten arbuthnot-Datensatz mit dem neuen, der die neue Variable enth√§lt.‚Äù\nDies ist gleichbedeutend mit dem Durchgehen jeder Zeile und dem Aufsummieren der Anzahl der Jungen und M√§dchen f√ºr dieses Jahr und dem Aufzeichnen dieses Wertes in einer neuen Spalte mit dem Namen total.\n\n\nWo ist die neue Variable? Wenn Sie √Ñnderungen an Variablen in Ihrem Datensatz vornehmen, rufen Sie ihn erneut durch die Eingabe des Datensatznamens. Die neue Variable wird am Ende des Datensatzes hinzugef√ºgt.\n\nSie werden sehen, dass es jetzt eine neue Spalte namens total gibt, die an das Dataframe angeheftet wurde. Das spezielle Symbol <- f√ºhrt eine Zuweisung durch, indem es die Ausgabe der Piping-Operationen nimmt und sie in einem Objekt in Ihrer Umgebung speichert. In diesem Fall haben Sie bereits ein Objekt mit dem Namen arbuthnot in Ihrer Umgebung, also aktualisiert dieser Befehl diesen Datensatz mit der neuen mutierten Spalte.\nMit dem folgenden Code k√∂nnen Sie ein Liniendiagramm der Gesamtzahl der Taufen pro Jahr erstellen:\n\nggplot(data = arbuthnot, aes(x = year, y = total)) + \n  geom_line()\n\n\n\n\nIn √§hnlicher Weise kann man, wenn man die Gesamtzahl der Taufen f√ºr Jungen und M√§dchen im Jahr 1629 kennt, das Verh√§ltnis zwischen der Zahl der Jungen und der Zahl der getauften M√§dchen mit dem folgenden Code berechnen:\n\n5218 / 4683\n\n[1] 1.114243\n\n\nAlternativ k√∂nnten Sie dieses Verh√§ltnis f√ºr jedes Jahr berechnen, indem Sie auf die vollst√§ndigen Spalten boys und girls einwirken und diese Berechnungen dann in einer neuen Variablen mit dem Namen boy_to_girl_ratio speichern:\n\narbuthnot <- arbuthnot %>%\n  mutate(boy_to_girl_ratio = boys / girls)\n\nSie k√∂nnen auch den Anteil der Neugeborenen im Jahr 1629, die Jungen sind, mit dem folgenden Code berechnen:\n\n5218 / (5218 + 4683)\n\n[1] 0.5270175\n\n\nSie k√∂nnen diesen Wert auch f√ºr alle Jahre gleichzeitig berechnen und ihn als neue Variable mit dem Namen boy_ratio zum Datensatz hinzuf√ºgen:\n\narbuthnot <- arbuthnot %>%\n  mutate(boy_ratio = boys / total)\n\nBeachte, dass wir nicht durch boys + girls dividieren, sondern die Variable total verwenden, die wir zuvor in unseren Berechnungen erstellt haben!\n\n\nErstellen Sie nun eine Grafik des Anteils der geborenen Jungen √ºber die Zeit. Was sehen Sie?\n\n\n\nTipp: Wenn Sie die Pfeiltasten nach oben und unten in der Konsole benutzen, k√∂nnen Sie durch Ihre vorherigen Befehle bl√§ttern, Ihre sogenannte Befehlshistorie. Sie k√∂nnen auch auf Ihre Befehlshistorie zugreifen, indem Sie auf die Registerkarte ‚ÄúHistory‚Äù in der oberen rechten Leiste klicken. Dies kann Ihnen in Zukunft viel Tipparbeit ersparen.\n\nZus√§tzlich zu den einfachen mathematischen Operatoren wie Subtraktion und Division k√∂nnen Sie R auffordern, Vergleiche durchzuf√ºhren, z. B. gr√∂√üer als, >, kleiner als, <, und Gleichheit, ==. Mit dem folgenden Code k√∂nnen wir unter anderem eine neue Variable namens more_boys erstellen, die uns sagt, ob die Anzahl der Geburten von Jungen die der M√§dchen in jedem Jahr √ºbersteigt:\n\narbuthnot <- arbuthnot %>%\n  mutate(more_boys = boys > girls)\n\nDieser Befehl f√ºgt dem Dataframe arbuthnot eine neue Variable hinzu, die entweder den Wert TRUE enth√§lt, wenn es in diesem Jahr mehr Jungen als M√§dchen gab, oder FALSE, wenn dies nicht der Fall war (die Antwort mag Sie √ºberraschen). Diese Variable enth√§lt eine andere Art von Daten als die, die wir bisher kennengelernt haben. Alle anderen Spalten im Dataframe arbuthnot haben numerische Werte (das Jahr, die Anzahl der Jungen und M√§dchen). Hier haben wir R gebeten, logische Daten zu erstellen, also Daten, deren Werte entweder TRUE oder FALSE sind. Im Allgemeinen werden bei der Datenanalyse viele verschiedene Datentypen verwendet, und ein Grund f√ºr die Verwendung von R ist, dass es in der Lage ist, viele dieser Datentypen darzustellen und mit ihnen zu rechnen."
  },
  {
    "objectID": "25-lab-01-intro-to-r.html#mehr-√ºbungen",
    "href": "25-lab-01-intro-to-r.html#mehr-√ºbungen",
    "title": "7¬† Lab 01: Einf√ºhrung in R und RStudio",
    "section": "7.4 Mehr √úbungen",
    "text": "7.4 Mehr √úbungen\nAuf den vorangegangenen Seiten haben Sie einige der Anzeigen und vorl√§ufigen Analysen von Arbuthnots Taufdaten nachgebildet. Ihre Aufgabe besteht darin, diese Schritte zu wiederholen, allerdings f√ºr die heutigen Geburtsdaten in den Vereinigten Staaten. Die Daten sind in einem Datenrahmen mit dem Namen present gespeichert.\nUm die Minimal- und Maximalwerte der Spalten zu ermitteln, k√∂nnen Sie die Funktionen min() und max() innerhalb eines summarize()-Aufrufs verwenden, √ºber den Sie im Verlaufe des Kurses mehr erfahren werden.\nHier ist ein Beispiel daf√ºr, wie man die minimale und maximale Anzahl der Geburten von Jungen in einem Jahr ermitteln kann:\n\narbuthnot %>%\n  summarize(min = min(boys),\n            max = max(boys)\n            )\n\n\n\n  \n\n\n\nBeantworten Sie die folgenden Fragen mit dem Datensatz present:\n\n\nWelche Jahre sind in diesem Datensatz enthalten? Welche Dimensionen hat das Dataframe? Wie lauten die Namen der Variablen (Spalten)?\nWie lassen sich diese Z√§hlungen mit denen von Arbuthnot vergleichen? Sind sie von √§hnlicher Gr√∂√üenordnung?\nErstellen Sie ein Diagramm, das den Anteil der geborenen Jungen im Laufe der Zeit darstellt. Was sehen Sie? Trifft Arbuthnots Beobachtung, dass Jungen in gr√∂√üerem Umfang als M√§dchen geboren werden, in den Vereinigten Staaten zu? F√ºgen Sie die Grafik in Ihre Antwort ein. Hinweis: Sie sollten in der Lage sein, Ihren Code aus der obigen Aufgabe wiederzuverwenden, ersetzen Sie einfach den Namen des Dataframes.\nIn welchem Jahr gab es die h√∂chste Gesamtzahl an Geburten in den Vereinigten Staaten? Tipp: Berechnen Sie zun√§chst die Gesamtzahlen und speichern Sie sie als neue Variable. Sortieren Sie dann Ihren Datensatz in absteigender Reihenfolge nach der Spalte total. Sie k√∂nnen dies interaktiv in der Datenanzeige tun, indem Sie auf die Pfeile neben den Variablennamen klicken. Um das sortierte Ergebnis in Ihren Bericht aufzunehmen, m√ºssen Sie zwei neue Funktionen verwenden. Zuerst verwenden wir arrange(), um die Variable zu sortieren. Dann k√∂nnen wir die Daten mit einer anderen Funktion, desc(), in absteigender Reihenfolge anordnen. Der Beispielcode ist unten angegeben.\n\n\n\npresent %>%\n  arrange(desc(total))\n\nDiese Daten stammen aus Berichten der Centers for Disease Control. Sie k√∂nnen mehr √ºber sie erfahren, indem Sie die Hilfedatei mit dem Befehl ?present aufrufen."
  },
  {
    "objectID": "25-lab-01-intro-to-r.html#ressourcen-zum-erlernen-von-r-und-zum-arbeiten-in-rstudio",
    "href": "25-lab-01-intro-to-r.html#ressourcen-zum-erlernen-von-r-und-zum-arbeiten-in-rstudio",
    "title": "7¬† Lab 01: Einf√ºhrung in R und RStudio",
    "section": "7.5 Ressourcen zum Erlernen von R und zum Arbeiten in RStudio",
    "text": "7.5 Ressourcen zum Erlernen von R und zum Arbeiten in RStudio\nDas war eine kurze Einf√ºhrung in R und RStudio, aber wir werden Ihnen im weiteren Verlauf des Kurses weitere Funktionen und ein umfassenderes Gef√ºhl f√ºr die Sprache vermitteln.\nIn diesem Kurs werden wir die R-Pakete aus dem tidyverse verwenden. Das Buch [R For Data Science] (https://r4ds.hadley.nz/) von Wickham et al.¬†ist eine fantastische Quelle f√ºr die Datenanalyse in R mit tidyverse. Wenn Sie nach R-Code suchen, stellen Sie sicher, dass Sie auch diese Paketnamen in Ihre Suchanfrage aufnehmen. Suchen Sie zum Beispiel nicht nach ‚Äúscatterplot in R‚Äù, sondern nach ‚Äúscatterplot in R with the tidyverse‚Äù.\nDiese Unterlagen k√∂nnen sich im Laufe des Semesters als n√ºtzlich erweisen:\n\nRMarkdown Cheatsheet\nCheatsheet zur Datentransformation\nCheatsheet zur Datenvisualisierung\n\nBeachten Sie, dass einige der Codes auf diesen Cheatsheets f√ºr diesen Kurs zu fortgeschritten sein k√∂nnten. Der Gro√üteil davon wird jedoch im Laufe des Semesters n√ºtzlich sein."
  },
  {
    "objectID": "04-einlesen.html#ansprechen-von-spalten-zeilen-und-zellen-in-einem-dataframe-tibble",
    "href": "04-einlesen.html#ansprechen-von-spalten-zeilen-und-zellen-in-einem-dataframe-tibble",
    "title": "3¬† Daten in R einlesen und aus R speichern",
    "section": "3.3 Ansprechen von Spalten, Zeilen und Zellen in einem Dataframe (tibble)",
    "text": "3.3 Ansprechen von Spalten, Zeilen und Zellen in einem Dataframe (tibble)\nEin tibble ist ein tabellen√§hnliches Objekt, ein Dataframe. Es ist zwei-dimensional: Es hat Zeilen (erste Dimension) und Spalten (zweite Dimension). Um so ein Objekt richtig anzusprechen, erweitern wir unsere Notation mit den eckigen Klammern. Jetzt brauchen wir n√§mlich zwei Indizes: einen Index f√ºr die Zeile und einen Index f√ºr die Spalte eines Eintrags. Wenn wir z. B. den dritten Eintrag in der ersten Spalte (Variable geo) sehen wollen, schreiben wir:\n\ncar_numbers[3, 1]\n\n\n\n  \n\n\n\nEs handelt sich um √ñsterreich. Wir k√∂nnen auch ganze Spalten (Variablen) ansprechen. Daf√ºr wird der erste Index (f√ºr Zeilen) weggelassen. Nichts (oder ein Leerzeichen) signalisieren R, dass alle Eintr√§ge gemeint sind. So k√∂nnen wir die erste Spalte wie folgt ansprechen:\n\ncar_numbers[, 1]\n\n\n\n  \n\n\n\nBeim Ansprechen ganzer Zeilen ist es √§hnlich. Wir lassen den Index f√ºr die Spalte weg. Um die erste Zeile anzusprechen, schreiben wir:\n\ncar_numbers[1,]\n\n\n\n  \n\n\n\nSie sollten einen wichtigen Unterschied zwischen der $-Notation und dem Ansprechen in eckigen Klammern bemerken: Die $-Notation gibt einen Vektor zur√ºck. Wenn Sie ein tibble mit eckigen Klammern ansprechen, ist die Antwort ein tibble."
  },
  {
    "objectID": "11-regression.html",
    "href": "11-regression.html",
    "title": "(PART) Teil III: Statistische Modellierung",
    "section": "",
    "text": "Lineare Regression\nIn diesem Kapitel werden wir in die statistische Modellierung einsteigen. Bisher haben Sie gelernt, wie man mithilfe von modernen Resamplingverfahren oder Simulationen Hypothesentests durchf√ºhrt und Konfidenzintervalle berechnet. Wir werden in sp√§teren Kapiteln auch f√ºr die Modellierung Bootstrap verwenden.\nEs gibt im Wesentlichen zwei Gr√ºnde, warum man modelliert.\nWir werden uns in diesem Kurs nur mit dem explikativen (erkl√§renden) Modellieren besch√§ftigen."
  },
  {
    "objectID": "11-regression.html#begriff-regression",
    "href": "11-regression.html#begriff-regression",
    "title": "5¬† Lineare Regression",
    "section": "5.1 Begriff Regression",
    "text": "5.1 Begriff Regression\nWoher kommt der Begriff Regression? Diesen pr√§gte Sir Francis Galton (1822-1911) (Fahrmeir, Kneib, and Lang 2009). Galton interessierte sich unter anderem f√ºr den Zusammenhang zwischen der durchschnittlichen K√∂rpergr√∂√üe der Eltern und der K√∂rpergr√∂√üe ihrer erwachsenen Kinder. Leider war er nicht nur einer der V√§ter der Statistik, sondern auch ein Rassist.\nGalton stellte fest, dass Kinder von unterdurchschnittlich kleinen Eltern eher gr√∂√üer waren und umgekehrt, Kinder von √ºberdurchschnittlich gro√üen Eltern eher kleiner waren. Diesen Effekt nannte er Regression (R√ºckkehr) zur Mitte."
  },
  {
    "objectID": "11-regression.html#idee-der-regression",
    "href": "11-regression.html#idee-der-regression",
    "title": "5¬† Lineare Regression",
    "section": "5.2 Idee der Regression",
    "text": "5.2 Idee der Regression\nDie Regression ist ein Modell, dass einen Zusammenhang zwischen Variablen analysiert. Wenn dieser Zusammenhang linear ist, dann nennt man das Modell lineare Regression. Wir werden uns ausschlie√ülich mit solchen linearen Modellen besch√§ftigen.\nDie lineare Regression untersucht also den linearen Zusammenhang zwischen den sogen. erkl√§renden Variablen und der Zielvariablen. Im historischen Beispiel von Galton gab es nur eine erkl√§rende Variable, n√§mlich die Durchschnittsgr√∂√üe der Eltern. Die Zielvariable war die zu erwartende Gr√∂√üe der Kinder. Es ging also nicht darum, die exakte Gr√∂√üe eines bestimmten Kindes zu berechnen, sondern den Einfluss der Durchschnittsgr√∂√üe der Eltern auf die zu erwartende Gr√∂√üe der Kinder. Es ging also um den systematischen Einfluss, nicht um bestimmte Eltern-Kind-Paare. Diese waren nur Stichproben. Sp√§testens hier sollte es klingeln, denn die Gr√∂√üe der Kinder ist somit eine Zufallsvariable.\nDie Zielvariable muss nicht immer stetig wie die K√∂rpergr√∂√üe sein. Sie kann bin√§r, kategorial oder eine Z√§hlvariable sein. Auch die erkl√§renden Variablen k√∂nnen stetig, bin√§r oder kategorial sein. Das macht die Regessionsmodelle sehr divers. Wir werden uns im Wesentlichen mit numerischen Zielvariablen besch√§ftigen.\nWir k√∂nnen somit die Regression so zusammenfassen:\n\nDie Regression ist ein Modell der Form\n\\[y = f(X) + \\varepsilon\\]\n\n\\(y\\): Zielvariable\n\\(f\\): Art des Zusammenhangs\n\\(X\\): Pr√§diktoren (erkl√§rende Variablen auch Kovariablen)\n\\(\\varepsilon\\): Fehlerterm\n\nWenn:\n\n\\(f\\) linear ist (Einfluss der Pr√§diktoren addiert sich), spricht man von linearer Regression\n\\(X\\) nur ein Pr√§diktor ist, spricht man von einfacher Regression, sonst von multipler Regression\n\nModellkomponenten:\n\n\\(f(X)\\): systematische oder deterministische Komponente\n\\(\\varepsilon\\): stochastische Komponente (St√∂rgr√∂√üe, Fehlerterm)\n\n\nEs geht bei der Regression also darum, die systematische Komponente zu modellieren. Der Zusammenhang zwischen Pr√§diktoren und der Zielvariablen ist nie exakt, es gibt also einen Fehlerterm. Die Zielgr√∂√üe ist eine Zufallsvariable, deren Verteilung von den Pr√§diktoren abh√§ngt."
  },
  {
    "objectID": "11-regression.html#einfache-lineare-regression",
    "href": "11-regression.html#einfache-lineare-regression",
    "title": "5¬† Lineare Regression",
    "section": "5.3 Einfache lineare Regression",
    "text": "5.3 Einfache lineare Regression\nBei einer einfachen linearen Regression gibt es nur einen Pr√§diktor. Der Zusammenhang zwischen der Zielvariablen und diesem Pr√§diktor ist linear. Somit hat das Model die Form einer Geraden. Eine Gerade kann man ja mithilfe des \\(y\\)-Achsenabschnitts und der Steigung beschreiben. Und genauso sieht das einfache lineare Regressionsmodell aus.\n\nGegeben sind Datenpaare: \\((y_i,x_i), \\quad i=1,\\dots,n\\) zu metrischen Variablen \\(y\\) und \\(x\\).\nDas Modell \\[y_i=\\beta_0 + \\beta_1x_i + \\varepsilon_i, \\qquad i=1,\\dots,n.\\] hei√üt einfaches lineares Regressionsmodell, wenn die Fehler \\(\\varepsilon_1,\\dots, \\varepsilon_n\\) unabh√§ngig und identisch verteilt sind (iid) mit\n\\[\\mathrm{E}(\\varepsilon_i) = 0, \\qquad \\mathrm{Var}(\\varepsilon_i)=\\sigma^2.\\] Wenn zus√§tzlich gilt \\[\\varepsilon_i \\sim N(0,\\sigma^2)\\] d.¬†h. die Residuen normalverteilt sind, sprechen wir von klassischer Normalregression.\n\\(\\beta_0\\) hei√üt \\(y\\)-Achsenabschnitt und \\(\\beta_1\\) Steigung des Modells.\n\n\\(\\varepsilon_i\\) steht f√ºr Fehler, die wir im Modell machen. Das sind die Unterschiede, genannt Residuen, zwischen dem, was das Modell in dem systematischen Teil (Geradengleichung) \\(\\beta_0 + \\beta_1x_i\\) ausrechnet und dem tats√§chlich gemessenen Wert \\(y_i\\).\n\\(\\mathrm{E}\\) steht f√ºr Erwartungswert. So nennt man den theoretischen Mittelwert einer Zufallsvariablen. Und \\(\\mathrm{Var}\\) steht f√ºr Varianz. Beim einfachen linearen Regressionsmodell nimmt man also an, dass die Fehler im Mittel Null sind. Sie werden nat√ºrlich nie alle Null sein, sondern sie werden variieren. Der Fehlerterm ist also eine Zufallsvariable, dessen Varianz fest sein soll. Eine feste Varianz nennt man Homoskedastizit√§t und die Fehler entsprechend homoskedastisch. Eine Varianz, die schwankt, bezeichnet man als Heteroskedastizit√§t. Das bedeutet unter anderem, dass die Fehler f√ºr kleine und gro√üe Werte im Modell √§hnlich sein m√ºssen. Um auf Galtons Beispiel zur√ºckzukommen, das Modell soll sowohl die Gr√∂√üe der gro√üen als auch der kleinen Kinder gleich gut erkl√§ren."
  },
  {
    "objectID": "11-regression.html#beispiel-zusammenhang-zwischen-der-anreisezeit-und-der-arbeitszeit-in-der-bibliothek",
    "href": "11-regression.html#beispiel-zusammenhang-zwischen-der-anreisezeit-und-der-arbeitszeit-in-der-bibliothek",
    "title": "5¬† Lineare Regression",
    "section": "5.4 Beispiel: Zusammenhang zwischen der Anreisezeit und der Arbeitszeit in der Bibliothek",
    "text": "5.4 Beispiel: Zusammenhang zwischen der Anreisezeit und der Arbeitszeit in der Bibliothek\nAls Beispiel f√ºr eine einfache lineare Regression nutzen wir simulierte Daten. An der (kleinen) Universit√§t Werdeschlau m√∂chte die Studierendenvertretung wissen, ob sich eine Station zum Ausleihen von Fahrr√§dern lohnen w√ºrde. Dazu befragen sie die Studierenden, wie lange sie zur Uni fahren. Zudem wollen Sie wissen, ob die Anreisezeit und die Zeit, die die Studierenden pro Woche in der Bibliothek verbringen, zusammen h√§ngen.\nZun√§chst laden wir die Bibliotheken. Die Bibliothek kntir ben√∂tigen wir f√ºr das Layouten der Tabellen.\n\nlibrary(tidyverse)\nlibrary(infer)\nlibrary(moderndive)\nlibrary(knitr)\n\nWir generieren unsere Grundgesamtheit. Das sind alle 12000 Studierende von der Uni Werdeschlau. Wir erstellen uns in diesem Beispiel unsere Grundgesamtheit aus der Gleichverteilung. Die Regeln dazu sind absolut frei erfunden. Die meisten Studierenden sind zwischen 5 und 40 Minuten unterwegs; 20% jedoch haben eine l√§ngere Anreise zwischen 60 und 120 Minuten.\nWir setzen geschlecht, wohnort, verkehrsmittel, anreise und zeit_bib zu einer Datenmatrix (tibble) zusammen und nennen das Objekt grundgesamtheit.\n\nset.seed(123)\n\nstudent_id <- 1:12000\n  \nanreise <- c(runif(n = 12000 * 0.8, min = 5, max = 40),\n             runif(n = 12000 * 0.2, min = 60, max = 120))\n\ngeschlecht <- sample(c('m', 'w'), size = 12000, replace = TRUE)\n\nwohnort <- sapply(anreise, function(x) {\n  if(x < 30) 'stadt'\n  else 'land'\n})\n\nverkehrsmittel <- sapply(anreise, function(x) {\n  if(x <= 10) 'zu_fuss'\n  else if(x > 10 & x <= 15) sample(c('zu_fuss', 'fahrrad'), size = 1)\n  else if(x > 15 & x <= 45) sample(c('bus', 'fahrrad', 'auto'), size = 1)\n  else sample(c('bus', 'auto'), size = 1)\n})\n\nzeit_bib <- 5 * 60 - 0.7 * anreise + rnorm(length(anreise), 0, 20)\n\ngrundgesamtheit <- tibble(student_id, geschlecht, wohnort, verkehrsmittel, anreise, zeit_bib)\n\ndatatable(grundgesamtheit, options = list(scrollX = T)) %>%\n  formatRound(c('zeit_bib', 'anreise'), 1)\n\n\n\n\n\n\nIn der Realit√§t werden nat√ºrlich nicht alle 12000 Studierende befragt (wer hat schon so viele Kapazit√§ten?), sondern eine zuf√§llige Stichprobe erhoben, also eine Teilmenge der Grundgesamtheit. Wir simulieren die zuf√§llige Befragung von 200 Studierenden.\n\nset.seed(345)\n\nbefragung_size <- 200\n\nbefragung <- rep_sample_n(grundgesamtheit, size = befragung_size, replace = FALSE, reps = 1)\n\ndatatable(befragung, options = list(scrollX = T)) %>%\n  formatRound(c('zeit_bib', 'anreise'), 1)\n\n\n\n\n\n\n\n5.4.1 Modell anpassen\nWir unterstellen einen linearen Zusammenhang zwischen zeit_bib und anreise und passen ein lineares Modell an. Dazu nutzen wir die Funktion lm(). Sie ben√∂tigt die Zielvariable und den Pr√§diktor, die Sie mit einer Tilde verbinden. Das ist die sogen. formula (Formel, so √§hnlich wie eine Matheformel). Die Tilde hatten wir schon so √§hnlich bei der Bibliothek infer benutzt. Au√üerdem m√ºssen wir noch den Datensatz, in dem die Variablen zu finden sind, benennen.\n\nlin_mod <- lm(zeit_bib ~ anreise, data = befragung)\n\n\n\n5.4.2 Modellergebnisse ansehen\nDie Struktur eines solchen linearen Modellobjekts ist richtig kompliziert. Daher gibt es verschiedene Methoden, um aus diesem Objekt sinnvolle Information zu entnehmen.\n\nstr(lin_mod)\n\nList of 12\n $ coefficients : Named num [1:2] 302.094 -0.766\n  ..- attr(*, \"names\")= chr [1:2] \"(Intercept)\" \"anreise\"\n $ residuals    : Named num [1:200] 2.55 -15.31 -21.32 42.64 -21.19 ...\n  ..- attr(*, \"names\")= chr [1:200] \"1\" \"2\" \"3\" \"4\" ...\n $ effects      : Named num [1:200] -3903 -312.5 -24.2 42.7 -21.2 ...\n  ..- attr(*, \"names\")= chr [1:200] \"(Intercept)\" \"anreise\" \"\" \"\" ...\n $ rank         : int 2\n $ fitted.values: Named num [1:200] 297 293 220 283 281 ...\n  ..- attr(*, \"names\")= chr [1:200] \"1\" \"2\" \"3\" \"4\" ...\n $ assign       : int [1:2] 0 1\n $ qr           :List of 5\n  ..$ qr   : num [1:200, 1:2] -14.1421 0.0707 0.0707 0.0707 0.0707 ...\n  .. ..- attr(*, \"dimnames\")=List of 2\n  .. .. ..$ : chr [1:200] \"1\" \"2\" \"3\" \"4\" ...\n  .. .. ..$ : chr [1:2] \"(Intercept)\" \"anreise\"\n  .. ..- attr(*, \"assign\")= int [1:2] 0 1\n  ..$ qraux: num [1:2] 1.07 1.05\n  ..$ pivot: int [1:2] 1 2\n  ..$ tol  : num 1e-07\n  ..$ rank : int 2\n  ..- attr(*, \"class\")= chr \"qr\"\n $ df.residual  : int 198\n $ xlevels      : Named list()\n $ call         : language lm(formula = zeit_bib ~ anreise, data = befragung)\n $ terms        :Classes 'terms', 'formula'  language zeit_bib ~ anreise\n  .. ..- attr(*, \"variables\")= language list(zeit_bib, anreise)\n  .. ..- attr(*, \"factors\")= int [1:2, 1] 0 1\n  .. .. ..- attr(*, \"dimnames\")=List of 2\n  .. .. .. ..$ : chr [1:2] \"zeit_bib\" \"anreise\"\n  .. .. .. ..$ : chr \"anreise\"\n  .. ..- attr(*, \"term.labels\")= chr \"anreise\"\n  .. ..- attr(*, \"order\")= int 1\n  .. ..- attr(*, \"intercept\")= int 1\n  .. ..- attr(*, \"response\")= int 1\n  .. ..- attr(*, \".Environment\")=<environment: R_GlobalEnv> \n  .. ..- attr(*, \"predvars\")= language list(zeit_bib, anreise)\n  .. ..- attr(*, \"dataClasses\")= Named chr [1:2] \"numeric\" \"numeric\"\n  .. .. ..- attr(*, \"names\")= chr [1:2] \"zeit_bib\" \"anreise\"\n $ model        :'data.frame':  200 obs. of  2 variables:\n  ..$ zeit_bib: num [1:200] 299 278 199 326 259 ...\n  ..$ anreise : num [1:200] 7.06 11.34 106.81 24.97 28.11 ...\n  ..- attr(*, \"terms\")=Classes 'terms', 'formula'  language zeit_bib ~ anreise\n  .. .. ..- attr(*, \"variables\")= language list(zeit_bib, anreise)\n  .. .. ..- attr(*, \"factors\")= int [1:2, 1] 0 1\n  .. .. .. ..- attr(*, \"dimnames\")=List of 2\n  .. .. .. .. ..$ : chr [1:2] \"zeit_bib\" \"anreise\"\n  .. .. .. .. ..$ : chr \"anreise\"\n  .. .. ..- attr(*, \"term.labels\")= chr \"anreise\"\n  .. .. ..- attr(*, \"order\")= int 1\n  .. .. ..- attr(*, \"intercept\")= int 1\n  .. .. ..- attr(*, \"response\")= int 1\n  .. .. ..- attr(*, \".Environment\")=<environment: R_GlobalEnv> \n  .. .. ..- attr(*, \"predvars\")= language list(zeit_bib, anreise)\n  .. .. ..- attr(*, \"dataClasses\")= Named chr [1:2] \"numeric\" \"numeric\"\n  .. .. .. ..- attr(*, \"names\")= chr [1:2] \"zeit_bib\" \"anreise\"\n - attr(*, \"class\")= chr \"lm\"\n\n\nAls Erstes sehen wir uns die Zusammenfassung des Modells an. Die nicht tidy-Form enth√§lt sehr viel Information, die man am Anfang gar nicht braucht. Und sie gl√§nzt mit vielen Signifikanz-Sternchen, die wir am liebsten gleich verbannen w√ºrden.\n\nsummary(lin_mod)\n\n\nCall:\nlm(formula = zeit_bib ~ anreise, data = befragung)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-60.060 -14.063   0.836  15.662  64.151 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 302.09377    2.28190  132.39   <2e-16 ***\nanreise      -0.76627    0.05112  -14.99   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 20.85 on 198 degrees of freedom\nMultiple R-squared:  0.5316,    Adjusted R-squared:  0.5292 \nF-statistic: 224.7 on 1 and 198 DF,  p-value: < 2.2e-16\n\n\nDaher empfehle ich die tidy-Form. Wir nutzen die Funktion get_regression_table aus der Bibliothek moderndive, die intern auf die Bibliothek broom zugreift (https://cran.r-project.org/web/packages/broom/vignettes/broom.html). broom hilft, die Ausgabe des linearen Modells in eine tidy-Form zu konvertieren. Die Funktion kable() aus der Bibliothek knitr layoutet die Tabelle.\n\nget_regression_table(lin_mod) %>% kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd_error\nstatistic\np_value\nlower_ci\nupper_ci\n\n\n\n\nintercept\n302.094\n2.282\n132.387\n0\n297.594\n306.594\n\n\nanreise\n-0.766\n0.051\n-14.990\n0\n-0.867\n-0.665\n\n\n\n\n\nSie sehen in der ersten Spalte (Intercept) und anreise. Das sind der \\(y\\)-Achsenabschnitt \\(\\beta_0\\) und die Steigung \\(\\beta_1\\) des Modells. Das hei√üt, unser Modell lautet ausgeschrieben:\n\\[\\widehat{\\text{zeit_bib}_i} = 302.094 - 0.766 \\cdot \\text{anreise_i}\\]\nDer Index \\(i\\) steht hier f√ºr die unterschiedlichen Studierenden, denn jede(r) hat nat√ºrlich eine eigene Anreise- und Arbeitszeit in der Bibliothek. Wir lernen also, dass mit steigender Anreisezeit, die Arbeitszeit in der Bibliothek sinkt. Und zwar k√∂nnen wir es sogar noch genauer sagen: mit jeder zus√§tzlichen Minute Anreisezeit, sinkt die Arbeitszeit in der Bibliothek um 0.766 Minuten. Auf die √ºbrigen Spalten kommen wir sp√§ter zu sprechen.\nWelche Werte hat das Modell berechnet? Diese nennt man angepasste Werte (fitted) und man kann sie mit der Funktion fitted() abfragen. Wir sehen uns nur die ersten Eintr√§ge an.\n\nhead(fitted(lin_mod))\n\n       1        2        3        4        5        6 \n296.6866 293.4026 220.2491 282.9618 280.5521 284.0451 \n\n\nWir w√ºrden gerne diese angepassten Werte mit den echten gemessenen Werten, n√§mlich der tats√§chlichen Arbeitszeit in der Bibliothek, vergleichen. Daf√ºr f√ºgen wir die gemessenen und die angepassten Werte in einem tibble zusammen. Wir erstellen eine neue Spalte mit angepassten Werten und den Residuen, d.¬†h. den Differenzen zwischen den gemessenen und den angepassten Werten.\n\nmodel_res <- befragung %>%\n  mutate(fitted = fitted(lin_mod), residuals = residuals(lin_mod)) \n\nNun k√∂nnen wir die Werte gegeneinander plotten und uns die Residuen ansehen. Diese sind als graue vertikale Linien zwischen den gemessenen und den angepassten Werten dargestellt. Die angepassten Werte liegen alle auf einer Geraden, das ist ja die Definition eines linearen Modells. Zu jedem gemessenen Wert gibt es einen angepassten, modellierten Wert auf der Geraden. Das geom geom_abline zeichnet unsere Gerade.\n\nggplot(model_res, aes(x = anreise, y = zeit_bib)) +\n  geom_segment(aes(xend = anreise, yend = fitted, lty = 'Residuen'), alpha = 0.2)  + \n  geom_abline(intercept = coef(lin_mod)[1], slope = coef(lin_mod)[2], color = \"lightblue\") +\n  geom_point(aes(col = 'observed')) +\n  geom_point(aes(y = fitted, col = 'fitted'), shape = 1, size = 2) +\n  labs(x = 'Anreisezeit (min)', y = 'Arbeitszeit in der Bibliothek (min)') +\n  scale_color_manual(name = '', values = c(observed = 'black', fitted = 'blue'), breaks = c('observed', 'fitted'), label = c('Gemessene Werte', 'Angepasste Werte')) +\n  scale_linetype_manual(name = '', values = ('Residuen' = 'solid')) +\n  theme(legend.position = 'bottom')\n\n\n\n\n\n\n5.4.3 Modellannahmen √ºberpr√ºfen\nBei der linearen Regression nehmen wir an, dass der Zusammenhang zwischen der Zielvariablen und dem Pr√§diktor linear ist. Das k√∂nnen wir an der oberen Grafik bereits erkennen. Weiterhin nehmen wir an, dass die Residuen im Mittel um die Null schwanken und homoskedastisch sind, d.¬†h. ihre Varianz ist gleich. Diese Annahmen m√ºssen wir √ºberpr√ºfen, bevor es ans Interpretieren der Modellparameter geht. Das macht man haupts√§chlich grafisch. Wir plotten die Residuen gegen die angepassten Werte.\n\nggplot(data = model_res, aes(x = fitted, y = residuals)) + \n  geom_point() +\n  geom_hline(yintercept=0, col = 'red') + \n  labs(x = 'Angepasste Werte', y = 'Residuen')\n\n\n\n\nDiese Darstellung der Residuen gegen angepasste Werte nennt man Residualplot. Darin k√∂nnen wir erkennen, dass unsere Residuen um die Null schwanken. Die erste Annahme ist also schon einmal erf√ºllt. Die Homoskedastizit√§t ist nicht ganz erf√ºllt. Bei gr√∂√üeren angepassten Werten scheinen die Residuen st√§rker zu schwanken. Allerdings gibt es nur sehr wenige Werte < 250 Minuten. Daher ist es schwierig, daraus eine echte Heteroskedastizit√§t abzuleiten. Wichtig ist, dass wir keine systematische Zunahme oder Abnahme der Variabilit√§t beobachten und auch keine sonstigen Muster in den Residuen. Die zweite Modellannahme k√∂nnen wir auch als erf√ºllt abhaken. Wir k√∂nnen plausibel davon ausgehen, dass die Residuen unabh√§ngig sind. Denn wir haben weder eine Zeitreihe gemessen, noch Leute mehrfach befragt.\nDie Zusammenfassung des linearen Modells bietet noch weiter Informationen.\n\nget_regression_table(lin_mod) %>% kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd_error\nstatistic\np_value\nlower_ci\nupper_ci\n\n\n\n\nintercept\n302.094\n2.282\n132.387\n0\n297.594\n306.594\n\n\nanreise\n-0.766\n0.051\n-14.990\n0\n-0.867\n-0.665\n\n\n\n\n\nHier gibt es noch die Spalten\n\nstd_error: Standardfehler der Sch√§tzung des jeweiligen Modellparameters (intercept oder anreise)\nstatistics: Wert der \\(t\\)-Statistik f√ºr einen Hypothesentest, der √ºberpr√ºft, ob der jeweilige Modellparameter null ist. Die Nullhypothese lautet \\(\\beta_0 = 0\\) f√ºr den \\(y\\)-Achsenabschnitt bzw. \\(\\beta_1 = 0\\) f√ºr die Steigung. Die Alternativhypothese lautet, dass der jeweilige Modellparameter ungleich null ist.\np-value: p-Wert des Hypothesentests\nlower_ci, upper_ci: unterer und oberer Wert des Konfidenzintervalls (Standardeinstellung 95%)\n\nF√ºr die Berechnung des Standardfehlers, des Hypothesentests und der Konfidenzintervalle wird, zus√§tzlich zu den oben genannten Annahmen, vorausgesetzt, dass die Residuen normalverteilt sind. Nur wenn sie es tats√§chlich sind, sind diese Berechnungen und der Hypothesentest korrekt, sonst m√∂glicherweise nicht. Deswegen m√ºssen wir, bevor wir diese Spalten interpretieren, √ºberpr√ºfen, ob die Residuen normalverteilt sind. Das machen wir mit einem QQ-Plot. Sie d√ºrfen auch noch einen formalen shapiro.test() machen, wenn Sie m√∂chten.\n\nggplot(model_res, aes(sample = residuals)) + \n  stat_qq() +\n  stat_qq_line(col = 'blue') +\n  labs(x = 'Quantile aus der Normalverteilung',\n       y = 'Qunatile der Daten')\n\n\n\n\nWenn die Residuen normalverteilt sind, dann liegen sie nahe der Geraden im QQ-Plot. Das ist hier der Fall. Die Annahme der Normalverteilung der Residuen ist also erf√ºllt und wir d√ºrfen den Standardfehler, den p-Wert und die Konfidenzintervalle interpretieren.\n\n\n5.4.4 Modell interpretieren\nIn unserem fiktiven Datensatz nimmt die Arbeitszeit in der Bibliothek mit der Anreisezeit ab. Wir haben bereits die Sch√§tzungen des \\(y\\)-Achsenabschnitts (intercept) und der Steigung (anreise) interpretiert. Jetzt k√∂nnen wir zus√§tzlich sagen, wie gut wir gesch√§tzt haben. Der \\(y\\)-Achsenabschnitt gibt die Anreisezeit in der Bibliothek an, wenn die Anreisezeit Null w√§re. Das ist zwar die korrekte Interpretation, aber eine Extrapolation au√üerhalb unseres Messbereichs der Anreisezeit. Daher sollte man den \\(y\\)-Achsenabschnitt nicht √ºberinterpretieren. Er ist erst einmal ein Modellparameter, der gut gesch√§tzt wurde, mit einem Konfidenzintervall von [297.594, 306.594]. Ob die Studierenden tats√§chlich diese Zeit in der Bibliothek verbringen w√ºrden, wenn sie gewisserma√üen auf dem Campus wohnen w√ºrden, ist eine Spekulation.\nEinfacher und sinnvoller ist die Interpretation der Steigung. Ihr Konfidenzintervall lautet [-0.867, -0.665]. Es ist eine gute Sch√§tzung, da das Konfidenzintervall schmal ist. Pro zus√§tzlicher Anreiseminute sinkt die Arbeitszeit in der Bibliothek um einen Wert in diesem Konfidenzintervall.\nDie Hypothesentests k√∂nnen Sie interpretieren, wie gewohnt, m√ºssen Sie aber nicht. Wie in den vorherigen Kapiteln erw√§hnt, kann man auf den Begriff signifikant getrost verzichten. Die Sch√§tzung der Parameter und deren Konfidenzintervalle bringt sehr viel mehr Information.\nZum Schluss noch die wichtigsten Take-Home Messages. :::{.alert} - Regression beinhaltet eine gro√üe Familie an Modellen. - Lineare Regression: linearer Einfluss der Kovariablen auf \\(y\\). - Annahmen: Residuen \\(\\varepsilon_i\\) sind iid mit \\[\\mathrm{E}(\\varepsilon_i) = 0, \\qquad \\mathrm{Var}(\\varepsilon_i)=\\sigma^2.\\] - Normalregression zus√§tzlich: \\(\\varepsilon_i \\sim N(0,\\sigma^2)\\). - √úberpr√ºfung der Annahmen (vor allem) grafisch. - Konfidenzintervalle und Hypothesentests der Normalregression d√ºrfen nur dann interpretiert werden, wenn die Annahmen erf√ºllt sind. :::"
  },
  {
    "objectID": "11-regression.html#lesestoff",
    "href": "11-regression.html#lesestoff",
    "title": "5¬† Lineare Regression",
    "section": "5.5 Lesestoff",
    "text": "5.5 Lesestoff\nKapitel 5 in Ismay and Kim (2021). Arbeiten Sie die Beispiele in diesem Kapitel durch.\n\n\n5.5.1 Kategoriale Variable als Pr√§diktor\nArbeiten Sie selbstst√§ndig das Beispiel in Kapitel 5.2 in Ismay and Kim (2021) durch.\n\n\n\n\n\n\n\n\nFahrmeir, L., T. Kneib, and S. Lang. 2009. Regression. Springer. http://link.springer.com/book/10.1007/978-3-642-01837-4.\n\n\nIsmay, Chester, and Albert Y. Kim. 2021. ModernDive: Statistical Inference via Data Science. https://moderndive.com/."
  },
  {
    "objectID": "12-regression-inferenz.html#zur√ºck-zum-beispiel-anreisezeit-und-arbeitszeit-in-der-bibliothek",
    "href": "12-regression-inferenz.html#zur√ºck-zum-beispiel-anreisezeit-und-arbeitszeit-in-der-bibliothek",
    "title": "6¬† Inferenz in linearer Regression",
    "section": "6.1 Zur√ºck zum Beispiel: Anreisezeit und Arbeitszeit in der Bibliothek",
    "text": "6.1 Zur√ºck zum Beispiel: Anreisezeit und Arbeitszeit in der Bibliothek\n\n6.1.1 Parameter und Konfidenzintervalle sch√§tzen\n\nlibrary(tidyverse)\nlibrary(infer)\nlibrary(knitr)\nlibrary(moderndive)\n\nWoher kommen die Sch√§tzungen der Modellparameter und deren Konfidenzintervalle in unserem Modell? Dieses Kapitel basiert auf den theoretischen Herleitungen aus Fahrmeir, Kneib, and Lang (2009).\n\nlin_mod <- lm(zeit_bib ~ anreise, data = befragung)\n\nget_regression_table(lin_mod) %>% kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd_error\nstatistic\np_value\nlower_ci\nupper_ci\n\n\n\n\nintercept\n302.094\n2.282\n132.387\n0\n297.594\n306.594\n\n\nanreise\n-0.766\n0.051\n-14.990\n0\n-0.867\n-0.665\n\n\n\n\n\nEine h√§ufig verwendete Methode, die Modellparameter zu sch√§tzen, hei√üt Methode der kleinsten Quadrate (KQ). Sie beruht auf der Idee, dass diejenigen Modellparameter, \\(y\\)-Achsenabschnitt und die Steigung, die besten sind, bei denen die Summe der quadrierten Residuen die kleinste ist. Formal schreibt man:\n\nGegeben sei das lineare Regressionsmodell\n\\[y_i=\\beta_0 + \\beta_1 x_i + \\varepsilon_i\\]\nUm die unbekannten Parameter \\(\\beta_0\\) und \\(\\beta_1\\) zu bestimmen, minimiere die Summe der quadrierten Abweichungen\n\\[\\mathrm{KQ}(\\beta_0, \\beta_1)=\\sum_{i=1}^n (y_i - (\\beta_0 + \\beta_1 x_i))^2=\\sum_{i=n}^n \\varepsilon_i^2  \\rightarrow \\operatorname*{min}_{\\beta_0,\\, \\beta_1}\\]\nDann hei√üt \\[ \\boldsymbol{\\hat{\\beta}}=(\\hat{\\beta}_0, \\hat{\\beta}_1)\\]\nder Kleinste-Quadrate-Sch√§tzer f√ºr den Parametervektor \\(\\boldsymbol{\\beta} = (\\beta_0, \\beta_1)\\).\n\nEs geht also darum, die Residuen zu minimieren, d.¬†h. die Abst√§nde zwischen den beobachteten und den im Modell vorhergesagten Werten so klein wie m√∂glich zu machen.\n\n\n\n\n\nMan quadriert die Residuen, damit sowohl die positiven als auch die negativen gleich wichtig sind und sich in der Summe nicht gegenseitig aufheben.\nDie Methode der kleinsten Quadrate ergibt folgende Formeln f√ºr die Sch√§tzung der Modellparameter einer Einfachregression:\n\\[\n\\begin{align*}\n\\hat{\\sigma}^2 &= \\frac{1}{n-2} \\sum_{i=n}^n \\varepsilon_i^2 \\\\\n\\hat{\\beta}_0 &= \\bar{y} - \\hat{\\beta}_1 \\bar{x}\\\\\n\\hat{\\beta}_1 &= \\frac{\\sum^n_{i=1} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum^n_{i=1} (x_i - \\bar{x})^2}\n\\end{align*}\n\\] Die Residuen \\(\\hat{\\varepsilon}_i\\) berechnen sich als die Differenz zwischen den beobachteten und den im Modell berechneten Werten:\n\\[\\hat{\\varepsilon}_i = y_i - \\hat{y}_i\\] und die angepassten Werte als Punkte auf der Regressionsgeraden:\n\\[\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_i\\]\nDie gesch√§tzten Modellparameter sind Zufallsvariablen. Denn wenn die Daten etwas anders ausfallen (Zufallsstichproben!), bekommen wir andere Sch√§tzungen f√ºr den \\(y\\)-Achsenabschnitt und die Steigung. Unter der Annahme, dass die Residuen normalverteilt sind, d.¬†h.:\n\\[\\varepsilon_i \\sim \\mathcal{N}(0,\\sigma^2)\\] gilt f√ºr diese Zufallsvariablen, dass sie selbst normalverteilt sind:\n\\[\\hat{\\beta}_0 \\sim \\mathcal{N}(\\beta_0, \\sigma^2_{\\hat{\\beta}_0}),\n\\qquad \\hat{\\beta}_1 \\sim \\mathcal{N}(\\beta_1, \\sigma^2_{\\hat{\\beta}_1})\\]\nIhre Varianzen \\(\\sigma^2_{\\hat{\\beta}_0}\\) und \\(\\sigma^2_{\\hat{\\beta}_1}\\) m√ºssen gesch√§tzt werden:\n\\[\\hat{\\sigma}_{\\hat{\\beta}_0} = \\hat{\\sigma} \\frac{\\sqrt{\\textstyle \\sum_{i=1}^n x_i^2}}{\\sqrt{n \\textstyle \\sum_{i=1}^n (x_i-\\bar{x})^2}}, \\quad\n\\hat{\\sigma}_{\\hat{\\beta}_1} = \\frac{\\hat{\\sigma}}{\\sqrt{\\textstyle \\sum_{i=1}^n (x_i-\\bar{x})^2}}\\]\nWenn die Residuen normalverteilt sind, kann mann zeigen, dass die sogen. standardisierten Sch√§tzer der \\(t\\)-Verteilung folgen:\n\\[\\frac{\\hat{\\beta}_0 - \\beta_0}{\\hat{\\sigma}_{\\hat{\\beta}_0}} \\sim t_{n-2}, \\quad \\frac{\\hat{\\beta}_1 - \\beta_1}{\\hat{\\sigma}_{\\hat{\\beta}_1}} \\sim t_{n-2}\\] \\(n-2\\) steht hier f√ºr die Anzahl der Freiheitsgrade in der \\(t\\)-Verteilung. \\(n\\) ist die Anzahl der Datenpunkte im Modell.\nSomit wissen wir nun endlich, wie die Sch√§tzungen f√ºr den \\(y\\)-Achsenabschnitt und die Steigung verteilt sind. Mit diesem Wissen k√∂nnen wir Konfidenzintervalle f√ºr diese Modellparameter berechnen:\n\\[\\hat{\\beta}_0 \\pm \\hat{\\sigma}_{\\hat{\\beta}_0} t_{1-\\alpha/2, n-2}, \\qquad \\hat{\\beta}_1 \\pm \\hat{\\sigma}_{\\hat{\\beta}_1} t_{1-\\alpha/2, n-2}\\]\nF√ºr \\(\\alpha\\) setzt man passendes Konfidenzlevel ein, z. B. 5%, um das 95%-Konfidenzintervall zu erhalten.\n\n\n6.1.2 Wie gut ist das Modell?\nWelcher Anteil der Streuung der Daten l√§sst sich durch die Regression erkl√§ren?\nDie Streuung im Modell besteht aus:\n\\[\n\\begin{align*}\n\\mathit{SQT} &= \\mathit{SQE} + \\mathit{SQR}\\\\\n\\sum^{n}_{i = 1} (y_i-\\bar{y})^2 &= \\sum^{n}_{i=1} (\\hat{y}_i - \\bar{y})^2 + \\sum^{n}_{i=1} (y_i - \\hat{y}_i)^2\\\\\n\\end{align*}\n\\]\nmit \\(y_i\\): Messwerte, \\(\\bar{y}\\): Mittelwert, \\(\\hat{y}_i\\): angepasste Werte\n\n\\(\\mathit{SQT}\\) Sum of squares total: Gesamtstreuung der Daten\n\\(\\mathit{SQE}\\) Sum of squares explained: Streuung erkl√§rt vom Modell\n\\(\\mathit{SQR}\\) Sum of sqaures residual: Residualstreuung (vom Modell nicht erkl√§rt)\n\nDie \\(\\mathit{SQE}\\) beschreibt die Variation der angepassten Werte um den Mittelwert der beobachteten Daten und \\(\\mathit{SQR}\\) entspricht dem nicht erkl√§rten Teil der Streuung. Das hei√üt, je kleiner die Residualstreuung, desto besser das Modell, weil es dann einen gr√∂√üeren Anteil der Streuung der Daten erkl√§ren kann. Das Verh√§ltnis der Gesamtstreuung zur Residualstreuung nennt man das Bestimmtheitsma√ü (oder auch Determinationskoeffizient). Dieser wird meistens mit \\(R^2\\) bezeichnet und ist definiert als:\n\\[R^2 = \\frac{\\mathit{SQE}}{\\mathit{SQT}} = 1- \\frac{\\sum^{n}_{i=1} (y_i - \\hat{y}_i)^2}{\\sum^{n}_{i = 1} (y_i - \\bar{y}_i)^2}\\]\n\\(R^2\\) liegt (normalerweise) zwischen 0 (schlechtes Modell) und 1 (perfekter Fit). \\(R^2 < 0\\) zeigt eine falsche Modellwahl (z. B. kein Achsenabschnitt, wenn dieser aber n√∂tig ist).\nDas \\(R^2\\) hat die unangenehme Eigenschaft, bei einer multiplen Regression immer zu steigen, wenn man zus√§tzliche Pr√§diktoren hinzunimmt. Diese Pr√§diktoren k√∂nnen auch ohne jeden Zusammenhang zur abh√§ngigen Variablen stehen. Um dieses Problem zu korrigieren, hat man das adjustierte Bestimmtheitsma√ü \\(R^2_\\text{ajd}\\) eingef√ºhrt. Es ‚Äúbestraft‚Äù f√ºr zus√§tzliche Pr√§diktoren \\[R^2_\\text{ajd} = 1 - (1 - R^2) \\frac{n-1}{n - p - 1}\\]\nmit \\(n\\): Anzahl der Datenpunkte, \\(p\\): Anzahl der Pr√§diktoren (ohne \\(y\\)-Achsenabschnitt). \\(R^2_\\text{ajd}\\) ist aussagekr√§ftiger als \\(R^2\\) bei multipler Regression.\nZur√ºck zu unserem Beispiel. Wie viel Streuung erkl√§rt nun unser Modell? Wir sehen uns die tidy Zusammenfassung an.\n\nget_regression_summaries(lin_mod) %>% kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nr_squared\nadj_r_squared\nmse\nrmse\nsigma\nstatistic\np_value\ndf\nnobs\n\n\n\n\n0.532\n0.529\n430.4021\n20.74614\n20.851\n224.697\n0\n1\n200\n\n\n\n\n\n\nr_squared: Bestimmtheitsma√ü \\(R^2\\)\nadj_r_squared: adjustiertes Bestimmtheitsma√ü \\(R^2_\\text{ajd}\\)\nmse: mittlerer quadratischer Fehler, berechnet als mean(residuals(lin_mod)^2)\nrmse: Wurzel aus mse\nsimga: Standardabweichung (i.e.¬†Standardfehler) des Fehlerterms \\(\\varepsilon\\)\nstatistic: Wert der \\(F\\)-Statistik f√ºr den Hypothesentest mit H\\(_0\\): alle Modellparameter sind Null\np-value: \\(p\\)-Wert zum Hypothesentest\ndf: Freiheitsgrade, hier Anzahl der Pr√§diktoren\nnobst: Anzahl der Datenpunkte\n\nSomit erkl√§rt unser Modell 53% der Varianz der Daten."
  },
  {
    "objectID": "12-regression-inferenz.html#bootstrap-mit-infer-konfidenzintervall-f√ºr-steigung",
    "href": "12-regression-inferenz.html#bootstrap-mit-infer-konfidenzintervall-f√ºr-steigung",
    "title": "6¬† Inferenz in linearer Regression",
    "section": "6.2 Bootstrap mit infer: Konfidenzintervall f√ºr Steigung",
    "text": "6.2 Bootstrap mit infer: Konfidenzintervall f√ºr Steigung\nDie \\(t\\)-Verteilung der Sch√§tzungen gilt asymptotisch, d.¬†h. bei gro√üen Datens√§tzen, auch f√ºr nicht-normalverteilte Residuen (unter bestimmten Bedingungen, s. Fahrmeir, Kneib, and Lang (2009)). Allerdings erfordern nicht-normalverteilte Residuen, gro√üe Stichproben oder aber alternative Methoden zum Berechnen der Konfidenzintervalle. Auch heteroskedastische Residuen f√ºhren zu falschen Konfidenzintervallen und Hypothesentests. Bootstrap ist robust gegen die Verletzung beider Annahmen (Normalverteilung und Homoskedastizit√§t der Residuen). Allerdings m√ºssen die Daten auch hierf√ºr unabh√§ngig sein (keine wiederholten Messungen, keine Zeitreihen!), damit Bootstrap korrekt arbeitet.\nBei einer Einfachregression, d.¬†h., wenn es nur einen Pr√§diktor gibt, ist die Steigung h√§ufig der interessante Parameter. Wenn wir uns also nicht f√ºr den \\(y\\)-Achsenabschnitt interessieren, dann k√∂nnen wir das altbekannte Framework von infer f√ºr das Bootstrap-Konfidenzintervall f√ºr die Steigung verwenden. F√ºr unser Beispiel ginge es so:\nSchritt 1: Bootstrap-Stichproben generieren und Statistik ‚ÄûSteigung‚Äú berechnen\n\nbootstrap_distn_slope <- befragung %>% \n  specify(formula = zeit_bib ~ anreise) %>%\n  generate(reps = 10000, type = \"bootstrap\") %>% \n  calculate(stat = \"slope\")\n\nSchritt 2: Konfidenzintervall berechnen\n\npercentile_ci <- bootstrap_distn_slope %>% \n  get_confidence_interval(type = \"percentile\", level = 0.95)\n\npercentile_ci\n\n\n\n  \n\n\n\nSchritt 3: Ergebnisse darstellen\n\nvisualize(bootstrap_distn_slope) +\n    shade_confidence_interval(endpoints = percentile_ci) \n\n\n\n\nVerglichen mit dem Konfidenzintervall basierend auf der Normalverteilungsannahme, ist Bootstrap hier sehr √§hnlich. Das liegt daran, dass die Normalverteilungsannahme und die Homoskedastizit√§tsannahme ja erf√ºllt sind. In so einem Fall sind die Standardkonfidenzintervalle basierend auf der Normalverteilungsannahme und dem Bootstrap sehr √§hnlich. Wir w√ºrden also im Normalfall einfach die Standardkonfidenzintervalle benutzten.\n\nget_regression_table(lin_mod) %>% \nfilter(term == 'anreise') %>%\n  kable()\n\n\n\n\nterm\nestimate\nstd_error\nstatistic\np_value\nlower_ci\nupper_ci\n\n\n\n\nanreise\n-0.766\n0.051\n-14.99\n0\n-0.867\n-0.665\n\n\n\n\n\nWir k√∂nnen mit infer auch einen Hypothesentest durchf√ºhren, der untersucht, ob die Steigung von null verschieden ist.\n\nH\\(_0\\): \\(\\beta_1 = 0\\)\nH\\(_1\\): \\(\\beta_1 \\neq 0\\)\n\n\nnull_distn_slope <- befragung %>% \n  specify(formula = zeit_bib ~ anreise) %>%\n  hypothesize(null = \"independence\") %>% \n  generate(reps = 10000) %>% \n  calculate(stat = \"slope\")\n\nSetting `type = \"permute\"` in `generate()`.\n\n\nF√ºr die Darstellung ben√∂tigen wir noch die berechnete Steigung:\n\nobserved_slope <- befragung %>% \n  specify(formula = zeit_bib ~ anreise) %>% \n  calculate(stat = \"slope\")\n\nobserved_slope\n\n\n\n  \n\n\n\nUnd nun die Visualisierung:\n\nvisualize(null_distn_slope) +\n  shade_p_value(obs_stat = observed_slope, direction = \"both\")\n\n\n\nnull_distn_slope %>% \n  get_p_value(obs_stat = observed_slope, direction = \"both\")\n\nWarning: Please be cautious in reporting a p-value of 0. This result is an\napproximation based on the number of `reps` chosen in the `generate()` step. See\n`?get_p_value()` for more information."
  },
  {
    "objectID": "12-regression-inferenz.html#bootstrap-mit-rsample-konfidenzintervalle-f√ºr-steigung-und-y-achsenabschnitt",
    "href": "12-regression-inferenz.html#bootstrap-mit-rsample-konfidenzintervalle-f√ºr-steigung-und-y-achsenabschnitt",
    "title": "6¬† Inferenz in linearer Regression",
    "section": "6.3 Bootstrap mit rsample: Konfidenzintervalle f√ºr Steigung und \\(y\\)-Achsenabschnitt",
    "text": "6.3 Bootstrap mit rsample: Konfidenzintervalle f√ºr Steigung und \\(y\\)-Achsenabschnitt\nFalls wir doch Konfidenzintervalle f√ºr beide Modellparameter brauchen (und die Annahmen Normalverteilung und/oder Homoskedastizit√§t verletzt sind) oder aber ein lineares Modell mit mehreren Pr√§diktoren anpassen, k√∂nnen wir nicht mehr mit infer arbeiten. Es gibt aber ein ganzes Modelluniversum, zusammengestellt in der Paketsammlung tidymodels (https://www.tidymodels.org/). Darin gibt es nicht nur alle m√∂glichen Modelle, sondern vor allem eine tidy und einheitliche Herangehensweise ans Modellieren. tidymodels ist jenseits dessen, was wir in diesem Kurs machen werden. Wir werden aber die Bibliothek rsample nutzen, die uns beim Bootstrappen hilft.\n\nlibrary(rsample)\n\nUm Konfidenzintervalle sowohl f√ºr den \\(y\\)-Achsenabschnitt als auch f√ºr die Steigung zu bekommen, generieren wir Bootstrap-Stichproben aus der befragung, passen dann an jede solche Stichprobe unser lineares Modell an. Jedes dieser Modelle liefert uns einen \\(y\\)-Achsenabschnitt und eine Steigung. Dadurch bekommen wir Bootstrapverteilungen dieser Modellparameter, so wie sonst auch, wenn wir Bootstrap benutzt haben. Aus diesen Bootstrapverteilungen berechnen wir dann mit der Methode der Quantile unsere Konfidenzintervalle.\nSchritt 1: Bootstrapstichproben aus befragung generieren\nWir generieren 10000 Bootstrap-Stichproben aus dem Datensatz befragung mithilfe der Funktion bootstraps() aus der Bibliothek rsample.\n\nset.seed(123)\n\nbootstrap_reps <- 10000\n\nmy_bootstraps <- bootstraps(befragung, times = bootstrap_reps)\n\nDas Objekt my_bootstraps ist ein ‚Äúverpacktes‚Äù (nested) Objekt. Jeder split ist eine Bootstrap-Stichprobe.\n\nmy_bootstraps\n\n\n\n  \n\n\nclass(my_bootstraps)\n\n[1] \"bootstraps\" \"rset\"       \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\nWir sehen uns eine solche Bootstrap-Stichprobe mal an. Dazu nutzen wir die Funktion analysis(), die solche splits richtig behandelt. Jede Bootstrap-Stichprobe ist durch Ziehen mit Zur√ºcklegen aus dem Datensatz befragung hervorgegangen, das ist ja beim Bootstrap immer so.\n\nanalysis(my_bootstraps$splits[[1]])\n\n\n\n  \n\n\n\nWie viele Studierende wurden mehrfach gezogen? Wir sehen uns als Beispiel die erste Bootstrap-Stichprobe an.\n\nanalysis(my_bootstraps$splits[[1]]) %>%\n  group_by(student_id) %>%\n  summarise(n = n()) %>% \n  arrange(desc(n))\n\n\n\n  \n\n\n\nSchritt 2: Modell auf den Bootstrap-Stichproben anpassen\nUm unser urspr√ºngliches lineares Modell anzupassen, benutzen wir eine selbst geschriebene Funktion, inspiriert von der Hilfe zu rsample (?int_pctl). Die Funktion lm_est() passt auf einer Bootstrap-Stichprobe das lineare Modell zeit_bib ~ anreise an. Um die Berechnung auf allen Bootstrap-Stichproben effizient zu machen, nutze ich die Funktion map(), die sich eine Bootstrap-Stichprobe nach der anderen vornimmt und das lineare Modell anpasst. Wir kommen in einer sp√§teren Stunde auf solche effizienten Funktionen zur√ºck.\n\nlm_est <- function(split, ...) {\n  lm(zeit_bib ~ anreise, data = analysis(split)) %>%\n    tidy()\n}\n\nmodel_res <- my_bootstraps %>%\n  mutate(results = map(splits, .f = lm_est))\n\nWir sehen uns das entstandene Objekt mit allen angepassten Modellen an. Und \\(\\dots\\) wir sehen nichts üòÑ.\n\nmodel_res\n\n\n\n  \n\n\n\nDie Ergebnisse m√ºssen wir noch ‚Äúauspacken.‚Äù\n\nmodel_coeffs <- model_res %>%\n  # Die Spalte splits los werden.\n  select(-splits) %>%\n  # Und das Ergebnis in ein tibble umwandeln.\n  unnest(results)\n\nmodel_coeffs\n\n\n\n  \n\n\n\nJetzt k√∂nnen wir sehen, dass das Objekt model_coeffs die beiden Modellparameter, \\(y\\)-Achsenabschnitt und die Steigung, enth√§lt und das jeweils so h√§ufig, wie wir eben Bootstrap-Stichproben generiert haben. Somit haben wir jetzt eine Bootstrapverteilung dieser Modellparameter, die wir nun plotten k√∂nnen.\n\nggplot(model_coeffs, aes(x = estimate, group = term)) + \n  geom_histogram(col = \"white\", bins = 30) +\n  facet_wrap(~ term, scales = \"free_x\")\n\n\n\n\nSchritt 3: Konfidenzintervalle berechnen\nDie Verteilungen sind symmetrisch, weil ja die Annahmen der Normalregression erf√ºllt sind. Jetzt fehlen uns noch die Konfidenzintervalle, von denen wir erwarten, dass sie den Standardkonfidenzintervallen √§hnlich sein werden.\n\n# Konfidenzintervalle mit Bootstrap\npercentile_ci <- int_pctl(model_res, results)\n\n# Standard-Konfidenzintervalle mit der Annahme der Normalverteilung und Homoskedastizit√§t der Residuen\nstandard_ci <- tidy(lin_mod, conf.int = TRUE)\n\npercentile_ci %>% kable()\n\n\n\n\n\n\n\n\n\n\n\n\nterm\n.lower\n.estimate\n.upper\n.alpha\n.method\n\n\n\n\n(Intercept)\n297.7116451\n302.0940668\n306.4549805\n0.05\npercentile\n\n\nanreise\n-0.8462787\n-0.7665325\n-0.6867705\n0.05\npercentile\n\n\n\n\nstandard_ci %>% kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n302.0937700\n2.2818977\n132.38708\n0\n297.5938278\n306.5937121\n\n\nanreise\n-0.7662672\n0.0511189\n-14.98989\n0\n-0.8670746\n-0.6654598\n\n\n\n\n\nWir plotten alle Ergebnisse jetzt zusammen. Das m√ºssen wir ‚Äúh√§ndisch‚Äù machen, da uns ja nicht die tolle Funktion visualize() aus infer zur Verf√ºgung steht. Wir f√ºgen die Konfidenzintervalle als vertikale Linien zu den Histogrammen der Bootstrapverteilungen hinzu.\n\nggplot(model_coeffs, aes(x = estimate, group = term)) + \n  geom_histogram(col = \"white\", bins = 30) +\n  geom_vline(data = percentile_ci, aes(xintercept = .lower, group = term, col = 'percentile_ci_lower')) +\n  geom_vline(data = percentile_ci, aes(xintercept = .upper, group = term), col = 'blue') +\n  geom_vline(data = standard_ci, aes(xintercept = conf.low, group = term, col = 'conf.low')) +\n  geom_vline(data = standard_ci, aes(xintercept = conf.high, group = term), col = 'orange') +\n  scale_color_manual(name = \"Confidence intervals\", values = c(percentile_ci_lower = \"blue\", conf.low = 'orange'), labels = c('standard', 'bootstrap')) +\n  facet_wrap(~ term, scales = \"free_x\") +\n  theme(legend.position = 'bottom')\n\n\n\n\nIn diesem Beispiel √§hneln sich die Konfidenzintervalle, da die Annahmen der Normalregression erf√ºllt sind. Das wird in den Aufgaben (s. u.), die Sie selbstst√§ndig bearbeiten werden, nicht mehr der Fall sein. Selbstverst√§ndlich sollen Sie im Falle von erf√ºllten Annahmen einfach die Standardkonfidenzintervalle nutzen und brauchen kein Bootstrap. Sie werden aber sehen, dass beim Modellieren mit richtigen Daten die Annahmen der Normalverteilung und der Homoskedastizit√§t h√§ufig verletzt sind. Mit dem Bootstrap sind Sie jetzt daf√ºr ger√ºstet üòÑ."
  },
  {
    "objectID": "12-regression-inferenz.html#lesestoff",
    "href": "12-regression-inferenz.html#lesestoff",
    "title": "6¬† Inferenz in linearer Regression",
    "section": "6.4 Lesestoff",
    "text": "6.4 Lesestoff\nKapitel 10 in Ismay and Kim (2021)"
  },
  {
    "objectID": "12-regression-inferenz.html#aufgaben",
    "href": "12-regression-inferenz.html#aufgaben",
    "title": "6¬† Inferenz in linearer Regression",
    "section": "6.5 Aufgaben",
    "text": "6.5 Aufgaben\n\n6.5.1 Artenreichtum auf den Galapagosinseln\nWir besch√§ftigen uns mit dem Datensatz gala aus der Bibliothek faraway.\n\nLaden Sie den Datensatz und lesen Sie in der Hilfe nach, worum es sich dabei handelt.\nUntersuchen Sie die Hypothese, dass die Anzahl der endemischen Arten linear von der Gesamtartenzahl abh√§ngt.\n√úberpr√ºfen Sie die Annahmen des linearen Modells.\nVergleichen Sie das Konfidenzintervall, das auf der Normalverteilungsannahme beruht, mit dem Bootstrap-Konfidenzintervall.\nF√ºhren Sie den Hypothesentest analog zum Beispiel oben mit infer durch.\nInterpretieren Sie das Modell.\n\n\n\n6.5.2 Artenreichtum auf den Galapagosinseln, revisited\nWiederholen Sie die obere Aufgabe nun mithilfe der Bibliothek rasample. Tipp: Wandeln Sie die Inselnamen, die nur als Zeilennamen existieren, in eine richtige Spalte um gala <- gala %>% rownames_to_column(var = \"island\")."
  },
  {
    "objectID": "12-regression-inferenz.html#ihre-arbeit-einreichen",
    "href": "12-regression-inferenz.html#ihre-arbeit-einreichen",
    "title": "6¬† Inferenz in linearer Regression",
    "section": "6.6 Ihre Arbeit einreichen",
    "text": "6.6 Ihre Arbeit einreichen\n\nSpeichern Sie Ihr Notebook ab.\nLaden Sie Ihre .Rmd Datei in ILIAS hoch. Beachten Sie die Frist!\nSie erhalten die Musterl√∂sung nach dem Hochladen.\n\n\n\n\n\nFahrmeir, L., T. Kneib, and S. Lang. 2009. Regression. Springer. http://link.springer.com/book/10.1007/978-3-642-01837-4.\n\n\nIsmay, Chester, and Albert Y. Kim. 2021. ModernDive: Statistical Inference via Data Science. https://moderndive.com/."
  },
  {
    "objectID": "06-explorative-datenanalyse.html#grundpakete",
    "href": "06-explorative-datenanalyse.html#grundpakete",
    "title": "4¬† Explorative Datenanalyse mit tidyverse",
    "section": "4.1 Grundpakete",
    "text": "4.1 Grundpakete\ntidyverse enth√§lt folgende Grundpakete, die alle installiert werden, wenn Sie install.packages('tidyverse') ausf√ºhren.\n\n\n\nPaketname\nKurzbeschreibung\n\n\n\n\nggplot2\nVisualisierung\n\n\ndplyr\nDatentransformation\n\n\ntidyr\nDatenbereinigung\n\n\nreadr\nDaten einlesen\n\n\npurrr\nFunktionale Programmierung (Funktionen auf Objekte anwenden)\n\n\ntibble\nErweiterung von data.frame\n\n\nstringr\nFunktionen f√ºr Strings, d.¬†h. Textvariablen\n\n\nforcats\nFunktionen f√ºr factor\n\n\n\nJedes dieser Pakete hat ein Cheat Sheet, eine √ºbersichtliche Zusammenstellung der Funktionen des Pakets. Sie bekommen die Cheet Sheats √ºber die tidyverse-Seite (https://www.tidyverse.org/packages/), indem Sie auf das jeweilige Paket klicken und zum Abschnitt ‚ÄòCheatsheet‚Äô scrollen."
  },
  {
    "objectID": "06-explorative-datenanalyse.html#der-explorative-workflow",
    "href": "06-explorative-datenanalyse.html#der-explorative-workflow",
    "title": "4¬† Explorative Datenanalyse mit tidyverse",
    "section": "4.2 Der explorative Workflow",
    "text": "4.2 Der explorative Workflow\n\n4.2.1 Daten einlesen, revisited\nAls Erstes laden wir die Bibliothek tidyverse.\n\nlibrary(tidyverse)\n\nSie kennen bereits die Funktion read_delim() zum Einlesen von Textdateien. Die Funktion ist die allgemeinste Funktion der read_* Familie aus readr in tidyverse; read_csv() und read_csv2() sind jeweils f√ºr Komma- und Strichpunkt-getrennte Datens√§tze gedacht. In der Basisinstallation von R (also au√üerhalb von tidyverse) gibt die sehr umfangreiche Funktion read.table(), die ebenfalls zum Einlesen von Textdateien verwendet wird. Man k√∂nnte berechtigterweise fragen, warum neue Funktion (read_*) f√ºr etwas erfinden, was es schon gibt. Die Autoren von tidyverse versprechen Konsistenz und Geschwindigkeit. Ersteres war schon immer ein Problem von R, da es nicht von Computerspezialisten, sondern von Anwendern erfunden wurde. Daher ist eine Vereinheitlichung durch tidyverse mehr als willkommen. Und Geschwindigkeit ist sp√§testens bei gr√∂√üeren Datens√§tzen ein wichtiger Punkt.\nWir sehen uns Daten des Deutschen Wetterdienstes an, die ich am 24. Mai 2020 heruntergeladen habe (https://www.dwd.de/DE/leistungen/klimadatendeutschland/klimadatendeutschland.html). Auch das ist eine tolle Datenquelle f√ºr Berichte üòÑ. Der Datensatz enth√§lt Stundenwerte f√ºr relative Luftfeuchte (%) und Lufttemperatur (¬∞C) von drei Wetterstationen, n√§mlich Hof, Frankfurt und K√∂ln-Bonn. Die Daten sind in der Datei Drei_Stationen.csv gespeichert.\nBeim Einlesen zeigt Ihnen read_delim() bereits, welche Spalten und welche Datentypen es erkennt, mit trim_ws = T werden Leerzeichen aus Spalten entfernt.\n\ntemp_humid <- read_delim('Daten/Drei_Stationen.csv', delim = ';', trim_ws = T)\n\nRows: 39600 Columns: 6\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \";\"\nchr (1): eor\ndbl (5): STATIONS_ID, MESS_DATUM, QN_9, TT_TU, RF_TU\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nEine weitere Kontrolle bietet die Funktion print(), die das eingelesene Ergebnis √ºbersichtlich (und im Notebook interaktiv) darstellt. Sie m√ºssen hier nicht head() verwenden, da grunds√§tzlich nur die ersten 10 Zeilen dargestellt werden und die Darstellung in Seiten unterteilt wird.\n\n\n\n\n  \n\n\n\n\nprint(temp_humid)\n\nDas gleiche Ergebnis bekommen Sie auch ohne print(), wenn Sie wie gewohnt den Namen des Objekts tippen.\n\ntemp_humid\n\n\n\n  \n\n\n\nIn diesem Datensatz sind folgende Variablen (Spalten) enthalten (s. Datensatzbeschreibung des DWDs)\n\n\n\nVariablen\nBeschreibung\n\n\n\n\nSTATIONS_ID\nStationsidentifikationsnummer\n\n\nMESS_DATUM\nZeitstempel im Format yyyymmddhh\n\n\nQN_9\nQualit√§tsniveau der nachfolgenden Spalten\n\n\nTT_TU\nLufttemperatur in 2 m H√∂he ¬∞C\n\n\nRF_TU\nrelative Feuchte %\n\n\neor\nEnde data record\n\n\n\n\nclass(temp_humid)\n\n[1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\" \n\n\nDas Objekt temp_humid ist ein tibble, ein data.frame mit ‚Äúmodernem‚Äù Verhalten. Beispielsweise gibt die Funktion print() nur die ersten 10 Zeilen aus, die Datentypen in den Spalten werden in hellgrau zwischen ‚Äò<>‚Äô mit angegeben etc. Mehr zu Tibbles finden Sie in Kapitel 10 ‚ÄúTibbles‚Äù in R4DS."
  },
  {
    "objectID": "06-explorative-datenanalyse.html#geschickter-umgang-mit-zeit-und-datum",
    "href": "06-explorative-datenanalyse.html#geschickter-umgang-mit-zeit-und-datum",
    "title": "4¬† Explorative Datenanalyse mit tidyverse",
    "section": "4.3 Geschickter Umgang mit Zeit und Datum",
    "text": "4.3 Geschickter Umgang mit Zeit und Datum\nEin weiteres Paket, das zwar nicht zum Kern von tidyverse geh√∂rt, jedoch trotzdem extrem n√ºtzlich ist, hei√üt lubridate. Es hilft, Text sehr einfach in richtige Datums-Objekte zu transformieren (in Base-R muss man sich daf√ºr kryptischen Datumsformate merken). Wir transformieren die Spalte temp_humid$MESS_DATUM in ein richtiges Datum mit Uhrzeit. Die Funktion ymd_h() kann character in ein richtiges Datumsformat transformieren, wenn das Datum als year, month, day, hour codiert ist. Es gibt noch weitere Varianten der Codierung, die Sie bei Bedarf in der Hilfe nachschlagen sollten.\n\nlibrary(lubridate)\n\ntemp_humid$MESS_DATUM <- ymd_h(temp_humid$MESS_DATUM)\n\ntemp_humid\n\n\n\n  \n\n\n\n\n4.3.1 Daten zusammenfassen\nDie drei Wetterstationen haben folgende IDs:\n\nstation_ids <-  c('2261' = 'Hof', '1420' = 'Frankfurt', '2667' = 'Koeln')\n\nWir z√§hlen nach, wie viele Messpunkte es pro Station gibt. Dazu m√ºssen wir den Datensatz nach der Variablen STATION_ID gruppieren und dann pro Gruppe die Anzahl der Datenpunkte ermitteln:\n\ntemp_humid %>% \n  group_by(STATIONS_ID) %>% \n  count()\n\n\n\n  \n\n\n\nDie Zeichenkombination %>% hei√üt Pipe-Operator (pipe) und wird als ‚Äòund dann‚Äô gelesen (then). Der Ausdruck temp_humid %>% group_by(STATIONS_ID) %>% count() hei√üt also: nimm das Objekt temp_humid, gruppiere es nach der Variablen STATION_ID und dann z√§hle die Eintr√§ge pro Gruppe zusammen. Der Pipe-Operator ist die Kernphilosophie von tidyverse und wird Ihnen √ºberall begegnen. Der Operator stammt aus dem Paket magrittr (https://magrittr.tidyverse.org/). Seine Hauptaufgabe ist es, den Code √ºbersichtlicher und besser lesbar zu machen (vielleicht nicht gleich zu Beginn der Lernkurve, aber schon bald üòé)."
  },
  {
    "objectID": "06-explorative-datenanalyse.html#die-grammatik-der-datenmanipulation-dplyr",
    "href": "06-explorative-datenanalyse.html#die-grammatik-der-datenmanipulation-dplyr",
    "title": "4¬† Explorative Datenanalyse mit tidyverse",
    "section": "4.4 Die Grammatik der Datenmanipulation ‚Äì dplyr",
    "text": "4.4 Die Grammatik der Datenmanipulation ‚Äì dplyr\nDie Funktion count() geh√∂rt zum Paket dplyr, das f√ºr Datentransformationen zust√§ndig ist. Es ist erneut eine Grammatik. Dieses Paket enth√§lt f√ºnf Grundfunktionen (alle nach Verben benannt, damit man gleich wei√ü, was frau tut üòÑ):\n\n\n\n\n\n\n\nFunktion\nBedeutung\n\n\n\n\nfilter()\nW√§hle Daten anhand ihrer Werte\n\n\narrange()\nSortiere Zeilen\n\n\nselect()\nW√§hle Variablen anhand ihrer Namen\n\n\nmutate()\nErstelle neue Variablen als Funktionen vorhandener Variablen\n\n\nsummarize()\nFasse Daten zusammen\n\n\n\nWenn wir nur von einer bestimmten Station die Anzahl der Messwerte wissen m√∂chten, filtern wir vorher diese Station heraus.\n\ntemp_humid %>% \n  filter(STATIONS_ID == '2667') %>%\n  count()\n\n\n\n  \n\n\n\nBeim Filtern l√§uft eine logische Abfrage. D. h. es wird bei jedem Eintrag in STATION_ID nachgesehen, ob da der Wert 2667 steht. Wenn da 2667 steht, dann gibt == ein TRUE zur√ºck, wenn da etwas anderes steht, dann gibt == ein FALSE zur√ºck. Und die Funktion filter() beh√§lt nur die Zeilen, bei denen == ein TRUE zur√ºckgegeben hat.\nWeiter wichtige logische und relationale Operatoren finden Sie hier in der Hilfe zu filter(). Hier ein paar einfache Beispiele:\n\n\n\n\n\n\n\nOperator\nBedeutung\n\n\n\n\n==/ > / >=\nist die linke Seite gleich / gr√∂√üer / gr√∂√üer-gleich als die rechte Seite\n\n\n!=\nist die linke Seite ungleich der rechten Seite\n\n\n\nZudem kann man bei filter() die Anfragen auch kombinieren. Wir wollen z. B. die Stationen K√∂ln und Hof haben. | ist der logische Operator oder. Wenn man also sowohl K√∂ln als auch Hof haben will, sagt man: finde alles, was entweder gleich K√∂ln oder gleich Hof ist.\n\ntemp_humid %>% \n  filter(STATIONS_ID == '2667' | STATIONS_ID == '2261') %>%\n  group_by(STATIONS_ID) %>% \n  count()\n\n\n\n  \n\n\n\nDas Gleiche erreicht man mit folgendem Code, indem man Frankfurt ausschlie√üt:\n\ntemp_humid %>% \n  filter(STATIONS_ID != '1420') %>%\n  group_by(STATIONS_ID) %>% \n  count()\n\n\n\n  \n\n\n\nAlternative kann man auch den Operator %in% verwenden. Dieser ist sehr n√ºtzlich, wenn man anhand einer einzelnen Variable filtert, aber unterschiedliche Eintr√§ge ausw√§hlen m√∂chte (z. B. zwei Messstationen). Es wird bei jeder Zeile in der Variablen STATIONS_ID nun √ºberpr√ºft, ob hier entweder 2667 oder 2261 stehen.\n\ntemp_humid %>% \n  filter(STATIONS_ID %in% c('2667', '2261')) %>%\n  group_by(STATIONS_ID) %>% \n  count()\n\n\n\n  \n\n\n\n\n4.4.1 Daten plotten\nWir sehen uns die Daten erst mal an, bevor wir weiter machen. Wir plotten die Temperatur. Weil es sich um Zeitreihen handelt, m√∂chten wir sie eher untereinander als nebeneinander haben. Daher setzen wir bei facet_wrap() den Parameter nrow = 3.\n\nggplot(data = temp_humid, aes(x = MESS_DATUM, y = TT_TU)) + \n  geom_line() +\n  facet_wrap(~STATIONS_ID, nrow = 3) +\n  labs(x = 'Zeit', y = 'Temperatur (¬∞C)')\n\n\n\n\n\n\n4.4.2 Neue Variablen erstellen mit mutate()\nWir wollen die Monatsmittelwerte und die Standardabweichungen f√ºr die Temperatur berechnen und diese darstellen. Als Erstes erstellen wir zwei neue Spalten, die jeweils das Jahr und den Monat beinhalten. Die beiden neuen Spalten werden am Ende von temp_humid angeh√§ngt. Um neue Spalten zu erstellen, nutzen wir die Funktion mutate(). Die Funktionen year() und month() geh√∂ren zur Bibliothek lubridate und extrahieren jeweils das Jahr und den Monat aus MESS_DATUM.\n\ntemp_humid <- temp_humid %>% \n  mutate(year = year(MESS_DATUM),\n         month = month(MESS_DATUM))\n\ntemp_humid\n\n\n\n  \n\n\n\nJetzt k√∂nnen wir einen neuen Datensatz mit den Mittelwerten erstellen. Daf√ºr gruppieren wir erst einmal die Daten nach STATIONS_ID, year und month. Die Mittelwerte sollen je Station, Jahr und Monat berechnet werden. Beim Gruppieren gibt man die Variablen ohne Anf√ºhrungszeichen und ohne einen Vektor zu bilden, einfach durch Kommas getrennt an.\n\nmonthly_means <- temp_humid %>%\n  group_by(STATIONS_ID, year, month) %>% \n  summarize(mean_T = mean(TT_TU), mean_RH = mean(RF_TU),\n            sd_T = sd(TT_TU), sd_RH = sd(RF_TU))\n\n`summarise()` has grouped output by 'STATIONS_ID', 'year'. You can override\nusing the `.groups` argument.\n\nmonthly_means\n\n\n\n  \n\n\n\nDie Struktur von monthly_means zeigt uns, dass es sich um gruppierte Daten handelt.\n\nstr(monthly_means)\n\ngropd_df [57 √ó 7] (S3: grouped_df/tbl_df/tbl/data.frame)\n $ STATIONS_ID: num [1:57] 1420 1420 1420 1420 1420 1420 1420 1420 1420 1420 ...\n $ year       : num [1:57] 2018 2018 2019 2019 2019 ...\n $ month      : num [1:57] 11 12 1 2 3 4 5 6 7 8 ...\n $ mean_T     : num [1:57] 4 4.73 2.12 4.48 8.28 ...\n $ mean_RH    : num [1:57] 79.7 83.7 79.3 74.1 68.5 ...\n $ sd_T       : num [1:57] 1.82 4.2 3.76 4.69 4.08 ...\n $ sd_RH      : num [1:57] 9.96 11.68 10.04 17.73 16.1 ...\n - attr(*, \"groups\")= tibble [9 √ó 3] (S3: tbl_df/tbl/data.frame)\n  ..$ STATIONS_ID: num [1:9] 1420 1420 1420 2261 2261 ...\n  ..$ year       : num [1:9] 2018 2019 2020 2018 2019 ...\n  ..$ .rows      : list<int> [1:9] \n  .. ..$ : int [1:2] 1 2\n  .. ..$ : int [1:12] 3 4 5 6 7 8 9 10 11 12 ...\n  .. ..$ : int [1:5] 15 16 17 18 19\n  .. ..$ : int [1:2] 20 21\n  .. ..$ : int [1:12] 22 23 24 25 26 27 28 29 30 31 ...\n  .. ..$ : int [1:5] 34 35 36 37 38\n  .. ..$ : int [1:2] 39 40\n  .. ..$ : int [1:12] 41 42 43 44 45 46 47 48 49 50 ...\n  .. ..$ : int [1:5] 53 54 55 56 57\n  .. ..@ ptype: int(0) \n  ..- attr(*, \".drop\")= logi TRUE\n\n\nDa wir aber mit den Daten weiter rechnen wollen, ist es besser, die Gruppierung wieder aufzugeben. Es k√∂nnte sonst sp√§ter Fehlermeldungen geben.\n\nmonthly_means <- ungroup(monthly_means)\n\nUm die Daten als Zeitreihen zu plotten, erstellen wir noch eine ordentliche Zeit-Spalte. Die Funktion parse_date_time() kann aus character richtige Datums-Zeitobjekte erstellen. Sie ist allgemeiner als die oben verwendete ymd_h() Funktion, da man hier das Format explizit angeben kann. In unserem Fall ist das Format ‚Äòym‚Äô f√ºr Jahr und Monat.\n\nmonthly_means <- monthly_means %>%\n  mutate(year_month = parse_date_time(paste0(year, month), orders = 'ym', tz = 'CET'))\n\nmonthly_means\n\n\n\n  \n\n\n\nDer Code paste0(year, month) ‚Äúklebt‚Äù die Daten aus den Variablen year und month zusammen. Das ist n√∂tig, da die Funktion parse_date_time() einen Charaktervektor als Input erwartet und keine zwei getrennten Spalten. Da das Datum au√üer dem Jahr und dem Monat noch einen Tag ben√∂tigt, hat parse_date_time() den Ersten eines jeden Monats genommen.\n\nggplot(data = monthly_means, aes(x = year_month, y = mean_T, col = factor(STATIONS_ID))) + \n  geom_line() + \n  labs(x = 'Zeit', y = 'Temperatur (¬∞C)', color = 'Messstation')\n\n\n\n\nAlternativ k√∂nnen wir die Mittelwerte mit den Standardabweichungen darstellen.\n\nggplot(monthly_means, aes(x = year_month, y = mean_T, ymin = mean_T - sd_T, ymax = mean_T + sd_T)) +\n  geom_errorbar() +\n  geom_point() +\n  facet_wrap(~STATIONS_ID, nrow = 3) + \n  labs(x = 'Zeti', y = 'Temperatur (¬∞C)')\n\n\n\n\nOder, weil es gerade Spa√ü macht, als halb-transparentes Band. Ich hoffe, Sie haben jetzt Lust, das Kapitel 5 im ggplot2 Buch zu lesen üòé.\n\nggplot(monthly_means, aes(x = year_month, y = mean_T, ymin = mean_T - sd_T, ymax = mean_T + sd_T)) +\n  geom_ribbon(alpha = 0.5) +\n  geom_line() +\n  facet_wrap(~STATIONS_ID, nrow = 3) + \n  labs(x = 'Zeit', y = 'Temperatur (¬∞C)')\n\n\n\n\nEin letzter Trick. Die √úberschriften f√ºr die Teilgrafiken sind ungeschickt, da man die IDs als Mensch einfach nicht zuordnen kann. Weiter oben haben wir einen benannten Vektor definiert, der die Klarnamen enth√§lt.\n\nstation_ids\n\n       2261        1420        2667 \n      \"Hof\" \"Frankfurt\"     \"Koeln\" \n\n\nDiesen Vektor nutzen wir als Titel.\n\nggplot(monthly_means, aes(x = year_month, y = mean_T, ymin = mean_T - sd_T, ymax = mean_T + sd_T)) +\n  geom_ribbon(alpha = 0.5) +\n  geom_line() +\n  facet_wrap(~STATIONS_ID, nrow = 3, labeller = labeller(STATIONS_ID = station_ids)) + \n  labs(x = 'Zeit', y = 'Temperatur (¬∞C)')"
  },
  {
    "objectID": "06-explorative-datenanalyse.html#lesestoff",
    "href": "06-explorative-datenanalyse.html#lesestoff",
    "title": "4¬† Explorative Datenanalyse mit tidyverse",
    "section": "4.5 Lesestoff",
    "text": "4.5 Lesestoff\nKapitel 3 in Ismay and Kim (2021)"
  },
  {
    "objectID": "06-explorative-datenanalyse.html#weiterf√ºhrende-literatur-und-videos",
    "href": "06-explorative-datenanalyse.html#weiterf√ºhrende-literatur-und-videos",
    "title": "4¬† Explorative Datenanalyse mit tidyverse",
    "section": "4.6 Weiterf√ºhrende Literatur und Videos",
    "text": "4.6 Weiterf√ºhrende Literatur und Videos\n\nR4DS Wickham, √áetinkaya-Rundel, and Grolemund (2023): Kapitel 4 ‚ÄúData transformation‚Äù\nEine live Analyse des Hauptautors von tidyverse, Hadley Wickham. Empfehlenswert, auch wenn er viel zu schnell tippt üòÑ.\n\n\n\n\n\nIsmay, Chester, and Albert Y. Kim. 2021. ModernDive: Statistical Inference via Data Science. https://moderndive.com/.\n\n\nWickham, Hadley, Mine √áetinkaya-Rundel, and Garrett Grolemund. 2023. R for Data Science (2e). https://r4ds.hadley.nz/."
  },
  {
    "objectID": "100-aufgabensammlung.html#maschinelles-lernen",
    "href": "100-aufgabensammlung.html#maschinelles-lernen",
    "title": "Appendix A ‚Äî Aufgabensammlung",
    "section": "A.12 Maschinelles Lernen",
    "text": "A.12 Maschinelles Lernen\n\nA.12.1 Klassifikation mit KNN\nEs soll die Gefahr der Einwanderung einer invasiven Art untersucht werden. Dazu wurde der Abstand von bereits besiedelten Parzellen (in km) und die minimale volumetrische Bodenfeuchte (%) aufgenommen. Dazu liegen auch bereits Daten vor, die unten dargestellt sind.\n\nLesen Sie die Daten aus der Datei KNN.csv ein und stellen Sie diese als Streudiagramm dar.\nKlassifizieren Sie die Daten mit \\(K = 3\\). Da die Funktion knn() einen Trainings- und Datensatz erwartet, m√ºssen Sie die Daten erst unterteilen. Nutzen Sie diesen Code und erkl√§ren Sie ihn:\n\n\nlibrary(class)\nx <- knn_data\n\nset.seed(1)\ntrain <- sample(1:nrow(x), nrow(x)/2)\nx.train <- x[train, -1]\ny.train <- unlist(x[train, 1])\n\nx.test <- x[-train, -1]\ny.test <- unlist(x[-train, 1])\n\nKlassifizieren Sie nun die Daten und berechnen Sie die Klassifikationsfehlerrate. Erkl√§ren Sie den Code.\n\nknn.pred <- knn(x.train, x.test,\n               cl = y.train, k = 3)\nstr(knn.pred)\n\n Factor w/ 2 levels \"besiedelt\",\"unbesiedelt\": 2 2 1 2 2 1 2 1 2 2 ...\n\nmean(knn.pred == y.test)\n\n[1] 0.94\n\n\n\nBestimmen Sie das optimale \\(K\\) f√ºr die KNN Klassifikation mit der Methode des Test- und Trainingsdatensatzes. Erkl√§ren Sie den Code.\n\n\nk <- 1:50\nknn_pred_list <- sapply(k, function(x) knn(x.train, x.test,\n               cl = y.train, k = x))\n\nk_error <- tibble(k = k, error = apply(knn_pred_list, 2, function(x) mean(x != y.test)))\n\n\nPlotten Sie die Klassifikationsfehlerrate.\nVariieren Sie den Seed und untersuchen Sie, wie sich die Klassifikationsfehlerrate dadurch ver√§ndert.\nBestimmen Sie jetzt das optimale \\(K\\) durch die Kreuzvalidierung. Erkl√§ren Sie den Code.\n\n\nk <- 1:50\nfind.k <- sapply(k, function(x) knn.cv(x.train, y.train, k = x))\ncv.error <- apply(find.k, 2, function(x) mean(x != y.train))\n\nPlotten Sie den Fehler der Kreuzvalidierung und vergleichen Sie mit dem Fehler aus der Methode des Test- und Trainingsdatensatzes.\n\n\nA.12.2 Regression mit Random Forest\nWir besch√§ftigen uns mit dem Datensatz Boston aus der Bibliothek ISLR2.\n\nLaden Sie die Bibliothek und den Datensatz.\nLesen Sie in der Hilfe nach, welche Daten der Datensatz enth√§lt.\nF√ºhren Sie eine kurze explorative Analyse des Datensatzes durch. Die Zielvariable ist medv. Probieren Sie die Funktion ggpairs() aus dem Paket GGally aus.\nWir wollen mithilfe des Random Forest den Median des Wertes eines Hauses vorhersagen.\n\nZun√§chst teilen wir die Daten in Trainings- und Testdatensatz, damit wir am Ende einen echten Testfehler berechnen k√∂nnen.\n\nset.seed(1)\ntrain <- sample(1:nrow(Boston), nrow(Boston)/2)\nboston.test <- Boston[-train, \"medv\"]\n\nJetzt passen wir den Random Forest an. Erkl√§ren Sie den Code. Was wird hier ab Ende berechnet?\n\nlibrary(randomForest)\n\nset.seed(1)\n\nrf.boston <- randomForest(medv~., data = Boston,\n                         subset = train,\n                         mtry = floor(sqrt(dim(Boston)[2])),\n                         importance = TRUE)\n\nyhat.rf <- predict(rf.boston, newdata = Boston[-train,])\n\nmean((yhat.rf-boston.test)^2)\n\n\nStellen Sie die vorhergesagten gegen die beobachteten Mediane der Hauswerte dar.\nErkl√§ren Sie den nachfolgenden Code. Was wird hier dargestellt? Wie interpretieren Sie das?\n\n\nimportance(rf.boston, scale = F, type = 1)\n\nvarImpPlot(rf.boston, scale = F, type = 1)\n\n\n\n\n\nZuur, A. F., E. Ieno, and E. Meesters. 2009. A Beginner‚Äôs Guide to r. Springer. http://link.springer.com/book/10.1007%2F978-0-387-93837-0."
  }
]